{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import torch\n",
    "import altair as alt\n",
    "\n",
    "df = pd.read_csv('data_preprocessed.csv')\n",
    "\n",
    "df.head(10)\n",
    "df_ex = df[df['Sector'] != 'NaN']\n",
    "df_ex.shape[0]\n",
    "\n",
    "%%capture output\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = AutoModel.from_pretrained(\"roberta-base\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    " \n",
    "model.eval()\n",
    "\n",
    "score_tableau = []\n",
    "\n",
    "vectors = []\n",
    "for i, example in enumerate(df['text_processed'].tolist()):\n",
    "    inputs = tokenizer(example, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    outputs = model(**inputs)\n",
    "    vectors.append(outputs.last_hidden_state[0,0,:].detach().cpu().numpy()[np.newaxis, :])\n",
    "cam_rep = np.concatenate(vectors, axis=0)\n",
    "print(cam_rep.shape)\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "for k in range(2,10):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(cam_rep)\n",
    "    labels = kmeans.labels_\n",
    "    score = silhouette_score(cam_rep, labels)\n",
    "    score_tableau.append(score)\n",
    "    print(f\"{k+1}\")\n",
    "\n",
    "\"\"\"\n",
    "docs_tsne_th = TSNE(n_components=1, learning_rate='auto',\n",
    "                    init='random', metric='cosine',\n",
    "                    perplexity=50.0).fit_transform(cam_rep)\n",
    "print(docs_tsne_th.shape)\n",
    "\"\"\"\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "Tfidf = tfidf_vectorizer.fit_transform(df['text_processed'])\n",
    "tfidf_a = Tfidf.toarray()\n",
    "print(tfidf_a.shape)\n",
    "\n",
    "pca = PCA(n_components=2, whiten=True)\n",
    "docs_pca = pca.fit_transform(tfidf_a)\n",
    "\n",
    "data = pd.DataFrame({'x': docs_pca[:,0],\n",
    "                     'y': docs_pca[:,1],\n",
    "                     'texte': df['text_processed']})\n",
    "                     #'Category': categories_l})\n",
    "\n",
    "plt.figure()\n",
    "alt.Chart(data[:]).mark_circle(size=200).encode(\n",
    "    x=\"x\", y=\"y\",# color='Category',\n",
    "    tooltip=['texte']\n",
    "    ).interactive().properties(\n",
    "    width=500,\n",
    "    height=500\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
