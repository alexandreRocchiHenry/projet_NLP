{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TruncatedSVD\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AgglomerativeClustering\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mapi\u001b[39;00m\n\u001b[1;32m     16\u001b[0m loaded_glove_model \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglove-wiki-gigaword-300\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Preprocessed dataframe\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "import altair as alt\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "import gensim.downloader as api\n",
    "loaded_glove_model = api.load(\"glove-wiki-gigaword-300\")\n",
    "\n",
    "# Preprocessed dataframe\n",
    "data_proprocessed = \"data_preprocessed.csv\"\n",
    "data_df = pd.read_csv(data_proprocessed)\n",
    "\n",
    "# Embeddings functions\n",
    "def tfidf(df):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    Tfidf = tfidf_vectorizer.fit_transform(df['text_processed'])\n",
    "    tfidf_a = Tfidf.toarray()\n",
    "    return tfidf_a\n",
    "\n",
    "# Dimension reduction functions\n",
    "def tsne(embeddings):\n",
    "    docs_tsne = TSNE(n_components=2, learning_rate='auto',\n",
    "                init='pca').fit_transform(embeddings)\n",
    "    return docs_tsne\n",
    "\n",
    "def pca(embeddings):\n",
    "    svd = TruncatedSVD(n_components=2)\n",
    "    embeddings_pca = svd.fit_transform(embeddings)\n",
    "    return embeddings_pca\n",
    "\n",
    "# Clusterings functions\n",
    "def Kmeans_fct(n, embeddings):\n",
    "    kmeans = KMeans(n_clusters=n, random_state=0)\n",
    "    kmeans.fit(embeddings)\n",
    "    labels = kmeans.labels_\n",
    "    return labels\n",
    "\n",
    "\n",
    "def correspondence_analysis(embeddings, n_components=2):\n",
    "    svd = TruncatedSVD(n_components=n_components)\n",
    "    embeddings_ca = svd.fit_transform(embeddings)\n",
    "    return embeddings_ca\n",
    "\n",
    "def hierarchical_clustering(n_clusters, embeddings):\n",
    "    hc = AgglomerativeClustering(n_clusters=n_clusters, metric='euclidean', linkage='ward')\n",
    "    labels = hc.fit_predict(embeddings)\n",
    "    return labels\n",
    "\n",
    "# Validation function\n",
    "def score_function(embeddings, labels):\n",
    "    silhouette_s = silhouette_score(embeddings, labels)\n",
    "    davies_bouldin_s = davies_bouldin_score(embeddings, labels)\n",
    "    calinski_harabasz_s = calinski_harabasz_score(embeddings, labels)\n",
    "    return silhouette_s, davies_bouldin_s, calinski_harabasz_s\n",
    "\n",
    "def display_ca(embeddings, df, labels):\n",
    "    embeddings_ca = correspondence_analysis(embeddings)\n",
    "    data_ca = pd.DataFrame({'x': embeddings_ca[:, 0],\n",
    "                            'y': embeddings_ca[:, 1],\n",
    "                            'institution': df['categorie Institution'],\n",
    "                            'title': df[\"Name of the document\"],\n",
    "                            'labels': df[\"categorie Institution\"]\n",
    "                            })\n",
    "    alt.data_transformers.disable_max_rows()\n",
    "    chart = alt.Chart(data_ca).mark_circle(size=200).encode(\n",
    "        x=\"x\", y=\"y\", color=alt.Color('labels:N', scale=alt.Scale(scheme='category20')),\n",
    "        tooltip=['institution', \"title\"]\n",
    "        ).interactive().properties(\n",
    "        width=500,\n",
    "        height=500\n",
    "    )\n",
    "    chart.save('chart.html')\n",
    "    chart.show()\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "def display_tsne(embeddings, df, labels):\n",
    "    docs_tsne_th = TSNE(n_components=2, learning_rate='auto',\n",
    "                        init='random', metric='cosine',\n",
    "                        perplexity=50.0).fit_transform(embeddings)\n",
    "    print(docs_tsne_th.shape)\n",
    "\n",
    "    data_th = pd.DataFrame({'x': docs_tsne_th[:,0],\n",
    "                            'y': docs_tsne_th[:,1],\n",
    "                            'institution': df['categorie Institution'],\n",
    "                            'title': df[\"Name of the document\"],\n",
    "                            'labels': df[\"categorie Institution\"]\n",
    "                            })\n",
    "    alt.data_transformers.disable_max_rows()\n",
    "    chart = alt.Chart(data_th[:]).mark_circle(size=200).encode(\n",
    "        x=\"x\", y=\"y\", color=alt.Color('labels:N', \n",
    "                                      scale=alt.Scale(scheme='category20')),\n",
    "        tooltip=['institution', \"title\"]\n",
    "        ).interactive().properties(\n",
    "        width=500,\n",
    "        height=500\n",
    "    )\n",
    "    chart.save('chart.html')\n",
    "    chart.show()\n",
    "\n",
    "\n",
    "# Clustering pipeline\n",
    "def pipeline(dataframe, embedding_method, clustering_method, taille_cluster, reduction_method=display_tsne):\n",
    "    print(\"start embedding\")\n",
    "    embeddings = embedding_method(dataframe)\n",
    "    print(\"clustering\")\n",
    "    for i in range(taille_cluster[0], taille_cluster[1]):\n",
    "        labels = clustering_method(i, embeddings)\n",
    "    print(\"scoring\")\n",
    "    scores = score_function(embeddings, labels)\n",
    "    print(f\"silhouette_score: {scores[0]}, davies_bouldin_score: {scores[1]}, calinski_harabasz_score: {scores[2]}\")\n",
    "    reduction_method(embeddings, dataframe, labels)\n",
    "    return scores\n",
    "\n",
    "pipeline(dataframe=data_df, embedding_method=tfidf, clustering_method=Kmeans_fct, taille_cluster=[10,11], reduction_method=display_tsne)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
