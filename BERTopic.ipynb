{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bertopic import BERTopic\n",
    "\n",
    "from nltk import word_tokenize\n",
    "import os.path as op\n",
    "import re \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the preprocess doc\n",
    "\n",
    "df = pd.read_csv('./Data_csv/data_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['doc_id', 'Name of the document', 'Institution', 'URL', 'Authors',\n",
       "       'Affiliates', 'Sector', 'Country', 'Date', 'Keywords',\n",
       "       'Exclusion criteria', 'Status', 'Label', 'MapAIE (ours)', 'Jobin',\n",
       "       'Fjeld', 'Tidjon', 'Hagendorff', 'Floridi', 'Zeng (LAIP)',\n",
       "       'Attard-Frost', 'EP', 'Algorithm watch', 'CE', 'Winfield',\n",
       "       'EthicalML GitHub', 'all sources', 'Checked by', 'Unnamed: 27',\n",
       "       'Unnamed: 28', 'Unnamed: 29', 'text', 'langue', 'text_processed',\n",
       "       'tfidf', 'categorie Institution', 'theme'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doc_id                   457\n",
       "Name of the document     457\n",
       "Institution              457\n",
       "URL                      457\n",
       "Authors                   33\n",
       "Affiliates                29\n",
       "Sector                    42\n",
       "Country                  446\n",
       "Date                      44\n",
       "Keywords                   6\n",
       "Exclusion criteria         0\n",
       "Status                   457\n",
       "Label                    394\n",
       "MapAIE (ours)            457\n",
       "Jobin                     59\n",
       "Fjeld                     21\n",
       "Tidjon                    24\n",
       "Hagendorff                12\n",
       "Floridi                    4\n",
       "Zeng (LAIP)               42\n",
       "Attard-Frost              28\n",
       "EP                         8\n",
       "Algorithm watch          103\n",
       "CE                       377\n",
       "Winfield                  15\n",
       "EthicalML GitHub          13\n",
       "all sources              457\n",
       "Checked by               457\n",
       "Unnamed: 27                2\n",
       "Unnamed: 28                0\n",
       "Unnamed: 29                2\n",
       "text                     457\n",
       "langue                   457\n",
       "text_processed           457\n",
       "tfidf                    457\n",
       "categorie Institution    457\n",
       "theme                    457\n",
       "dtype: int64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df['text_processed'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "Bow = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Calculer la fréquence totale de chaque mot\n",
    "frequency = Bow.toarray().sum(axis=0)\n",
    "\n",
    "# Obtenir les 20 mots les plus fréquents\n",
    "top_indices = np.argsort(frequency)[-20:]  # Indices des 20 mots les plus fréquents\n",
    "vocabulary = np.array(vectorizer.get_feature_names_out())  # Le vocabulaire\n",
    "top_words = vocabulary[top_indices] \n",
    "\n",
    "stopwords_to_remove = set(top_words)\n",
    "\n",
    "dates = set([str(i) for i in range(1990, 2021)])\n",
    "useless_words = set(('may','also','see','system', 'must', 'et', 'al'))\n",
    "\n",
    "html_stopwords = set({'maxwidth', 'px', 'maxheight', 'img', 'src', 'https', 'com', 'www', 'http', 'jpg', 'png', 'gif', 'jpeg', 'pdf', 'html'})\n",
    "css_stopwords = set({'grid','body', ':root', '\\n', 'padding',',button','margintop', 'px', 'margin', 'border', 'width', 'height', 'color', 'font', 'size', 'background', 'position', 'left', 'right', 'top', 'bottom', 'display', 'flex', 'align', 'justify', 'content', 'center', 'float', 'clear', 'overflow', 'hidden', 'zindex', 'cursor', 'pointer', 'hover', 'active', 'focus', 'transition', 'transform', 'rotate', 'scale', 'translate', 'opacity', 'box', 'shadow', 'outline', 'none', 'block', 'inline', 'inlineblock', 'relative', 'absolute', 'fixed', 'static', 'sticky', 'visible', 'hidden'})\n",
    "\n",
    "\n",
    "\n",
    "stopwords_to_remove = stopwords_to_remove.union(dates)\n",
    "stopwords_to_remove = stopwords_to_remove.union(html_stopwords)\n",
    "stopwords_to_remove = stopwords_to_remove.union(css_stopwords)\n",
    "stopwords_to_remove = stopwords_to_remove.union(useless_words)\n",
    "\n",
    "# remove all possible dates day and month from the documents (such as 22 march...)\n",
    "\n",
    "def remove_months_days(doc, dates):\n",
    "    for date in dates:\n",
    "        doc = doc.replace(date, \"\")\n",
    "    return doc\n",
    "\n",
    "dates = set([str(i) for i in range(1990, 2025)])\n",
    "dates = dates.union(set(['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']))\n",
    "dates = dates.union(set(['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']))\n",
    "\n",
    "\n",
    "documents = [remove_months_days(doc, dates) for doc in documents]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def remove_frequent_words(doc, stopwords):\n",
    "    words = doc.split()\n",
    "    cleaned_words = [word for word in words if word not in stopwords]\n",
    "    return \" \".join(cleaned_words)\n",
    "\n",
    "\n",
    "documents = [remove_frequent_words(doc, stopwords_to_remove) for doc in documents]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTopic (sans n-gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "\n",
    "hdbscan_model = hdbscan.HDBSCAN(min_cluster_size=20, min_samples=1, cluster_selection_epsilon=0.1)\n",
    "topic_model = BERTopic(hdbscan_model=hdbscan_model, language=\"english\", nr_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 0\n",
    "while n_topics < 8:\n",
    "    topics, probs = topic_model.fit_transform(documents)\n",
    "    n_topics = len(set(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topic'] = topics\n",
    "df['probs'] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Topic  Count                                          Name  \\\n",
      "0     -1    115         -1_national_policy_based_technologies   \n",
      "1      0     36           0_protection_law_personal_standards   \n",
      "2      1     33           1_government_uk_strategy_innovation   \n",
      "3      2     40  2_algorithmic_algorithms_bias_decisionmaking   \n",
      "4      3     77              3_europe_energy_legal_commission   \n",
      "5      4     65        4_international_policy_work_government   \n",
      "6      5     40                       5_ethics_ethical_ts_wha   \n",
      "7      6     51               6_machine_ethical_ethics_health   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [national, policy, based, technologies, report...   \n",
      "1  [protection, law, personal, standards, technol...   \n",
      "2  [government, uk, strategy, innovation, support...   \n",
      "3  [algorithmic, algorithms, bias, decisionmaking...   \n",
      "4  [europe, energy, legal, commission, technologi...   \n",
      "5  [international, policy, work, government, coop...   \n",
      "6  [ethics, ethical, ts, wha, tion, report, ed, e...   \n",
      "7  [machine, ethical, ethics, health, algorithms,...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [national strategies artiﬁcial perspective edi...  \n",
      "1  [strasbourg 25 t-pd 09rev consultative committ...  \n",
      "2  [roadmapuk council council independent expert ...  \n",
      "3  [david freeman engstrom stanford university da...  \n",
      "4  [en en commission brussels 19.2. 65 final whit...  \n",
      "5  [age interdependence 1 age interdependence rep...  \n",
      "6  [ethics design organizational approach respons...  \n",
      "7  [humans keep upper hand ethical matters raised...  \n"
     ]
    }
   ],
   "source": [
    "# Afficher les topics les plus fréquents\n",
    "print(topic_model.get_topic_info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('national', 0.011850001856304576), ('policy', 0.010559448391368765), ('based', 0.009971611186680534), ('technologies', 0.00973394877093243), ('report', 0.009152244247335677), ('recognition', 0.0086519741431865), ('law', 0.008358261926282138), ('machine', 0.008338212431854291), ('strategy', 0.008237399970469858), ('training', 0.008213251869832794)]\n"
     ]
    }
   ],
   "source": [
    "print(topic_model.get_topic(-1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           0,
           "protection | law | personal | standards | technologies",
           36
          ],
          [
           1,
           "government | uk | strategy | innovation | support",
           33
          ],
          [
           2,
           "algorithmic | algorithms | bias | decisionmaking | algorithm",
           40
          ],
          [
           3,
           "europe | energy | legal | commission | technologies",
           77
          ],
          [
           4,
           "international | policy | work | government | cooperation",
           65
          ],
          [
           5,
           "ethics | ethical | ts | wha | tion",
           40
          ],
          [
           6,
           "machine | ethical | ethics | health | algorithms",
           51
          ]
         ],
         "hovertemplate": "<b>Topic %{customdata[0]}</b><br>%{customdata[1]}<br>Size: %{customdata[2]}",
         "legendgroup": "",
         "marker": {
          "color": "#B0BEC5",
          "line": {
           "color": "DarkSlateGrey",
           "width": 2
          },
          "size": [
           36,
           33,
           40,
           77,
           65,
           40,
           51
          ],
          "sizemode": "area",
          "sizeref": 0.048125,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          13.529288291931152,
          11.996060371398926,
          -28.33983612060547,
          13.11965560913086,
          12.456997871398926,
          -27.69681167602539,
          -28.671293258666992
         ],
         "xaxis": "x",
         "y": [
          -14.878583908081055,
          -15.144798278808594,
          -16.82023811340332,
          -15.23715591430664,
          -14.940155982971191,
          -17.463111877441406,
          -16.488636016845703
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "D1",
          "x": -32.97198724746704,
          "y": -16.364687490463258,
          "yshift": 10
         },
         {
          "showarrow": false,
          "text": "D2",
          "x": -8.706652855873108,
          "xshift": 10,
          "y": -12.646796321868896
         }
        ],
        "height": 650,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "legend": {
         "itemsizing": "constant",
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "shapes": [
         {
          "line": {
           "color": "#CFD8DC",
           "width": 2
          },
          "type": "line",
          "x0": -8.706652855873108,
          "x1": -8.706652855873108,
          "y0": -20.082578659057617,
          "y1": -12.646796321868896
         },
         {
          "line": {
           "color": "#9E9E9E",
           "width": 2
          },
          "type": "line",
          "x0": -32.97198724746704,
          "x1": 15.558681535720826,
          "y0": -16.364687490463258,
          "y1": -16.364687490463258
         }
        ],
        "sliders": [
         {
          "active": 0,
          "pad": {
           "t": 50
          },
          "steps": [
           {
            "args": [
             {
              "marker.color": [
               [
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 0",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 1",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 2",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 3",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 4",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 5",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red"
               ]
              ]
             }
            ],
            "label": "Topic 6",
            "method": "update"
           }
          ]
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Intertopic Distance Map</b>",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 650,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "range": [
          -32.97198724746704,
          15.558681535720826
         ],
         "title": {
          "text": ""
         },
         "visible": false
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          -20.082578659057617,
          -12.646796321868896
         ],
         "title": {
          "text": ""
         },
         "visible": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualisation des topics\n",
    "topic_model.visualize_topics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.20503324513453025,
          0.20503324513453025,
          0
         ],
         "xaxis": "x",
         "y": [
          -15,
          -15,
          -25,
          -25
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.12260679097409155,
          0.12260679097409155,
          0
         ],
         "xaxis": "x",
         "y": [
          -45,
          -45,
          -55,
          -55
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.15844454183081488,
          0.15844454183081488,
          0.12260679097409155
         ],
         "xaxis": "x",
         "y": [
          -35,
          -35,
          -50,
          -50
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.20503324513453025,
          0.2654817597247226,
          0.2654817597247226,
          0.15844454183081488
         ],
         "xaxis": "x",
         "y": [
          -20,
          -20,
          -42.5,
          -42.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.2654817597247226,
          0.36357787563670324,
          0.36357787563670324,
          0
         ],
         "xaxis": "x",
         "y": [
          -31.25,
          -31.25,
          -65,
          -65
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.43806014978031615,
          0.43806014978031615,
          0.36357787563670324
         ],
         "xaxis": "x",
         "y": [
          -5,
          -5,
          -48.125,
          -48.125
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "autosize": false,
        "height": 305,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "hovermode": "closest",
        "plot_bgcolor": "#ECEFF1",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Hierarchical Clustering</b>",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "mirror": "allticks",
         "rangemode": "tozero",
         "showgrid": false,
         "showline": true,
         "showticklabels": true,
         "ticks": "outside",
         "type": "linear",
         "zeroline": false
        },
        "yaxis": {
         "mirror": "allticks",
         "range": [
          -70,
          0
         ],
         "rangemode": "tozero",
         "showgrid": false,
         "showline": true,
         "showticklabels": true,
         "tickmode": "array",
         "ticks": "outside",
         "ticktext": [
          "5_ethics_ethical_ts",
          "6_machine_ethical_ethics",
          "2_algorithmic_algorithms_bias",
          "0_protection_law_personal",
          "3_europe_energy_legal",
          "4_international_policy_work",
          "1_government_uk_strategy"
         ],
         "tickvals": [
          -5,
          -15,
          -25,
          -35,
          -45,
          -55,
          -65
         ],
         "type": "linear",
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Visualisation des hiérarchies entre les topics\n",
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "#D55E00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.010926904327924212,
          0.010957445770120295,
          0.0110199022660256,
          0.011349087341698415,
          0.011371002645494377,
          0.01156761049401881,
          0.011733941980177178,
          0.012312612746646912,
          0.012612451084836837,
          0.014844831543953729
         ],
         "xaxis": "x",
         "y": [
          "example  ",
          "media  ",
          "big  ",
          "impact  ",
          "risk  ",
          "technologies  ",
          "standards  ",
          "personal  ",
          "law  ",
          "protection  "
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "#0072B2"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.015303748841315813,
          0.015573550911063784,
          0.015729481153437516,
          0.016532054574217265,
          0.018071143428823773,
          0.018210679504571576,
          0.020429465857910185,
          0.021452723816604714,
          0.02886175906814234,
          0.028862176723249998
         ],
         "xaxis": "x2",
         "y": [
          "business  ",
          "industrial  ",
          "national  ",
          "work  ",
          "services  ",
          "support  ",
          "innovation  ",
          "strategy  ",
          "uk  ",
          "government  "
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "#CC79A7"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.013121995311205897,
          0.013611385086301215,
          0.014043143519705825,
          0.014528674933591347,
          0.014623907137133773,
          0.014898580659977448,
          0.01707454283541355,
          0.019118835231585633,
          0.01912880118611699,
          0.021954758237092323
         ],
         "xaxis": "x3",
         "y": [
          "decisions  ",
          "automated  ",
          "external  ",
          "law  ",
          "model  ",
          "algorithm  ",
          "decisionmaking  ",
          "bias  ",
          "algorithms  ",
          "algorithmic  "
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "#E69F00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.009918473548215992,
          0.010198810102514005,
          0.010204229698518164,
          0.010475432085573295,
          0.010587235776755364,
          0.010980460459447628,
          0.011338306904219006,
          0.011993622593903939,
          0.013155723184275336,
          0.014917432662226468
         ],
         "xaxis": "x4",
         "y": [
          "could  ",
          "impact  ",
          "market  ",
          "states  ",
          "law  ",
          "technologies  ",
          "commission  ",
          "legal  ",
          "energy  ",
          "europe  "
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "#56B4E9"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.010242913394127626,
          0.010386523171865128,
          0.01057533720951276,
          0.010645218267461813,
          0.010850118832089096,
          0.011902869901651274,
          0.012189366473014303,
          0.01225766997369532,
          0.013750697718099407,
          0.013809338983321916
         ],
         "xaxis": "x5",
         "y": [
          "based  ",
          "privacy  ",
          "governance  ",
          "society  ",
          "technologies  ",
          "cooperation  ",
          "government  ",
          "work  ",
          "policy  ",
          "international  "
         ],
         "yaxis": "y5"
        },
        {
         "marker": {
          "color": "#009E73"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.010803758536609094,
          0.011387515097169716,
          0.01232843439630283,
          0.012642257198368367,
          0.013808951609836612,
          0.015029581172952378,
          0.015463081410943758,
          0.015748542055456723,
          0.025133405261357752,
          0.03538727771507179
         ],
         "xaxis": "x6",
         "y": [
          "ation  ",
          "principles  ",
          "es  ",
          "ed  ",
          "report  ",
          "tion  ",
          "wha  ",
          "ts  ",
          "ethical  ",
          "ethics  "
         ],
         "yaxis": "y6"
        },
        {
         "marker": {
          "color": "#F0E442"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.013653785435239615,
          0.013795059645045866,
          0.013890019778688454,
          0.013946126729015707,
          0.014088440331040264,
          0.016735986943969508,
          0.018243817765288217,
          0.018343562626562743,
          0.018710623263706767,
          0.0278813985431518
         ],
         "xaxis": "x7",
         "y": [
          "work  ",
          "ais  ",
          "could  ",
          "example  ",
          "people  ",
          "algorithms  ",
          "health  ",
          "ethics  ",
          "ethical  ",
          "machine  "
         ],
         "yaxis": "y7"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 0",
          "x": 0.0875,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 1",
          "x": 0.36250000000000004,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 2",
          "x": 0.6375000000000001,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 3",
          "x": 0.9125,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 4",
          "x": 0.0875,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 5",
          "x": 0.36250000000000004,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 6",
          "x": 0.6375000000000001,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 800,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "Topic Word Scores",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1600,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.175
         ],
         "showgrid": true
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.275,
          0.45
         ],
         "showgrid": true
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.55,
          0.7250000000000001
         ],
         "showgrid": true
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.825,
          1
         ],
         "showgrid": true
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0,
          0.175
         ],
         "showgrid": true
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.275,
          0.45
         ],
         "showgrid": true
        },
        "xaxis7": {
         "anchor": "y7",
         "domain": [
          0.55,
          0.7250000000000001
         ],
         "showgrid": true
        },
        "xaxis8": {
         "anchor": "y8",
         "domain": [
          0.825,
          1
         ],
         "showgrid": true
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis7": {
         "anchor": "x7",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis8": {
         "anchor": "x8",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Visualisation des relations entre les topics\n",
    "topic_model.visualize_barchart(n_words=10, height=400, width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Make sure to set `n_clusters` lower than the total number of unique topics.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[229], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualize_heatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Code_Telecom/projet_NLP/.env_projet_NLP/lib/python3.12/site-packages/bertopic/_bertopic.py:3173\u001b[0m, in \u001b[0;36mBERTopic.visualize_heatmap\u001b[0;34m(self, topics, top_n_topics, n_clusters, use_ctfidf, custom_labels, title, width, height)\u001b[0m\n\u001b[1;32m   3136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Visualize a heatmap of the topic's similarity matrix.\u001b[39;00m\n\u001b[1;32m   3137\u001b[0m \n\u001b[1;32m   3138\u001b[0m \u001b[38;5;124;03mBased on the cosine similarity matrix between c-TF-IDFs or semantic embeddings of the topics,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3170\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[1;32m   3171\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3172\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 3173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mplotting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualize_heatmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtopics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtopics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_n_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_n_topics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3178\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_ctfidf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_ctfidf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Code_Telecom/projet_NLP/.env_projet_NLP/lib/python3.12/site-packages/bertopic/plotting/_heatmap.py:80\u001b[0m, in \u001b[0;36mvisualize_heatmap\u001b[0;34m(topic_model, topics, top_n_topics, n_clusters, use_ctfidf, custom_labels, title, width, height)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_clusters:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_clusters \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(topics)):\n\u001b[0;32m---> 80\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure to set `n_clusters` lower than \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe total number of unique topics.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m     distance_matrix \u001b[38;5;241m=\u001b[39m cosine_similarity(embeddings[topics])\n\u001b[1;32m     83\u001b[0m     Z \u001b[38;5;241m=\u001b[39m linkage(distance_matrix, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mward\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Make sure to set `n_clusters` lower than the total number of unique topics."
     ]
    }
   ],
   "source": [
    "topic_model.visualize_heatmap(n_clusters=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"strasbourg 25 t-pd 09rev consultative committee convention protection individuals regard automatic processing personal convention 108 report protection challenges possible remedies directorate general rule law 2 report alessandro mantelero associate professor private law polytechnic university turin department management production engineering document expression author ’ personal viewpoint contents part – state art ................................ ................................ ................................ .............. 3 i.1 introduction ................................ ................................ ................................ ................................ .. 3 i.2 devel opment ................................ ................................ ................................ ............................ 4 i.3 perspective adopted ................................ ................................ ................................ ........... 5 i.4 existing framework principles ................................ ................................ ............................ 6 i.5 individuals ’ self -determination processing ................................ ................................ 7 i.6 minimisation ................................ ................................ ................................ ................................ 8 i.7 bias ................................ ................................ ................................ ................................ ................ 9 part ii challenges possible remedies ................................ ................................ .............. 11 ii.1 limitations ................................ ................................ ................................ ................ 11 ii.2 transparency ................................ ................................ ................................ ............................ 11 ii.3.1 risk assessment ................................ ................................ ................................ ................... 13 ii.3.2 ethics committees ................................ ................................ ................................ ................. 15 ii.3.3 participatory assessment ................................ ................................ ................................ .... 16 ii.4 liability vigilance ................................ ................................ ................................ ............... 17 ii 5 sector -specific issues ................................ ................................ ................................ ............. 17 references ................................ ................................ ................................ ................................ ......... 19 part – state art i.1 troduction defining field report easy matter since boundaries protection rtificial hereinafter ai1 rather uncertain one hand dataintensive technologies including represent challenge application traditional principles protection making blurrier less -cut difficult appl coe hildebrandt barocas nissenbaum citron pasquale mantelero rubinstein boyd crawford tene polonetsky broad field encompassing variety approaches attempt emulat e cognitive skills villani 2 018 4 protection necess ity correlated leaving aside science fiction scenarios rapid evolution applications recent years roots progressive process datafication er‐schönberger cukier 78 lycett result personal increasingly become source target applications e.g personal assistants smart home devices etc. different approaches emerging regulation reality largely unregulated often grounded fundamental relying instead mainly processing regarding pro cessing global framework offers range ways safeguard fundamental particular protection personal europe role field protection lead prominent part play region address ing regulatory challenge adoption perspective focused fundamental mitigate envisioned clash market -oriented inclusive approach perspective convention 108 general ly council europe ’ attitude fundamental solution existing tension provided regulatory framework jurisprudence court terms policy foundational nature fundamental led parties convention 108 favour grounded merely driven market forces high -tech companies moreover historical roots da ta protection lie urging policy makers consider potential ly adverse consequences processing technolog ies rights-based approach necessarily mpact consistent values expressed convention 108 regulations council europe parties convention therefore actively encourage developers towards value -oriented design products services away vague overly optimistic views time governments first manner centred safeguard ing promoti ng protect ion fundamental thereby avoiding technologies con strain individual collective freedoms reason important extend regulatory leadership field protection value -oriented regulation villani 7 based following three precepts 1 term originally coined john mccarthy american computer scientist known father j. mccarthy m. l. minsky n. rochester c.e shannon ‘ proposal dartmouth summer project arti ficial ’ 31 1955. //www -formal.stanford.edu/jmc/history/dartmouth/dartmouth.html accessed 19 definitio n available //www.coe.int/en/web/human -rights -rule-of-law/artificial -intelligence/glossary 4 value s-based approach encompassing social ethical values risk assessment management participation council europe ’ standpoint broader ’ borders encompasses wide variety legal culture regulatory approaches despite council europe ’ legal framework convention 108 provide uniform terms common values co uncil rope one best fora combine attention fundamental flexibility techn ology regulation adopting principle s-based approach principles broader scope interpreted specifically meet challenges changing world whe reas detailed legislative provisions appear able react quickly enough socio -economic technological change moreover principle s-based regulation leave room peculiarities local context even relevant regard application n impact contextual legal ethical social values ieee course protection per se cover aspects require broader approach encompassing rights2 societal issues3 edps mantelero raso al. council europe however protection strengthen complement response questions protection ’ individuals awareness social consequence link personality expand controller ’ approach beyond protection fundamental collective interests regarding complementary role protection helps reveal way purposes processing represent key element better understand ing potential consequences variety freedoms finally raises many different sector -specific issues concerning various fields application labour justice administration crime control contract relationships etc consequences e.g sustainability environment impact political impact etc addressed separately given f convention 108 se issues discussed n report concerns common core se applications i.e processing terms potential impact analysis therefore provide contribution debate around issues concerning general specific application s. i.2 years report scientific works published evolution unnecessary trace uneven trajectory scientific social interest society shown since earl iest studies mcculloch pitts 1943 turing 1950 recent contributions necessary describe increasing variety applications results achieved however historical perspective importan properly understand present near -term future two questions arise regard policy debate last years focuse forms reasonably expect next years answers questions crucial address ing regulation indeed need put context avoid confusin g commercial media narrative surrounding begin mere hype occurred past cloud computing big iot tendency vendors magnify possibilities term become 2 modernised convention prote ction individuals regard processing personal preamble art 1 3 consultative committee convention protection individuals regard automatic processing personal ‘ guidelines protection dividuals regard processing personal world big ’ hereinafter guidelines adopted 23 5 buzzword context strictly involve however basis truth attention concerning peculiar technological environment make possible today achieve results could dreamt past past decade increas ing availab ility bandwidth transfer storage computational resources – paradigm cloud computing – progressive datafication large part life environment created completely context led breakthrough enabling forms management extract create knowledge big analytics machine learning4 represent recent products process norwegian protection authority 5 concrete application technologies make possible envisage kind reasonably expected next years show w e still far -called general bostrom executive office president national science council committee p. 7 norwegian protection authority cummings al. although “ algorithms come represent mythologies time ” cnil report focuses existing near future applications leaving aside challenging questions concerning -like terms machine liability risks humanity bostrom kurzweil convention 108 original text modernised version refers “ automated processing ” “ automatic processing ” autonomous processing implicitly highlighting autonomy key element beings commissio n brief summary state art clearly shows unavoidably based processing algorithms necessarily impact personal pose questions adequacy existing protection regulations address ing issues paradigms raise i.3 perspective adopted ajor threats concern disputed sets value adopted developers users latter including consumers decision -makers support choices emerging tendency towards technocratic market -driven society push es personal moneti sation forms social control “ cheap fast ” decision -making solutions spiekermann 152 -153 large e.g smart cities small e.g precision medicine trend strengthens challenges progressively erodes individual self -determination privacy focused models mindful cautio us decision -making processes bulimia complexity processing extreme data-centred logic undermine democratic supp lanting individuals collective bodies well freedom self -determination kind dictatorship o'neil imposed scientist insensitive societal issues prevent adverse consequences prevailing benefits itu commissioner ’ office 15 -18 world economic forum necessary stress central ity means reaffirm ing predominance fundamental field th sense protection personal become stepping stone wards design ing different society driven pure economic interest dehumanising algorithmic efficiency 4 difference two technologies summarised follows “ patterns connections make difference traditional analytical methods need programmed find connections links learns sees computer therefore respond continuously adjust analyses without tervention thus helps remove technical barriers traditional methods run analysing big ” norwegian protection authority 5 6 broad -ranging debate needed reinforce fundamental -based paradigm need critically assess drive towards extreme datafication aspects lives affirm importance individual collective governments citizens need recognise risks datafication potentially damaging implications data-driven solutions rouvroy industrial product past awareness risk barrier innovation rather enabler innovation developed responsib ly taking safeguard fundamental pre-eminent goal necessarily requires assessment procedures adoption participatory models supervisory authorities -oriented might increase costs force developers business slow current time-to-market impact products services individual society assessed advance time medium long -term approach reduce costs increase efficiency e.g accurate prediction/decision increased trust world economic forum fewer complaints moreove r business es society mature enough view responsibility towards individuals society primary goal alternatively f ollow different path – earlier technologies done early stages – risk develop unregulated environment driven purely technological feasibility market political interests criteria guarantee respect s. data-centric therefore based principles convention 108 foundations flourishing society key element approach proportionality inspired proportionality principle,5 efficiency therefore prevail individuals ’ freedom individuals subordinate automated legislators aim curb applications safeguard individual societal interests responsibility mere ly accountability requires developers decision makers act socially responsible manner entails creation specific bodies support monitor actions risk management accountable means assessing potential ly adverse consequences application taking appropriate measure prevent mitigate consequences participation participatory forms risk assessment essential give voice citizens time citizens ’ participation understood diminish decision -makers ’ accountability transparency despite current limitations affecting transparency certain degree transparency help ensure effective pa rticipation citizens accurately assess consequences applications i.4 existing framework principles exi sting regulatory framework applicable processing mainly grounded convention 108 although legal instruments concerning protection recommendations6 guidelines7 relevant regard specific fields context guidelines big adopted council europe council europe represent first attempt address -intensive solutions decision -making part broader wave documents resolutions adopted several institu tions regulate impact algorithms society council europe -committee experts internet intermediaries 5 modernised convention protection individuals regard processing personal art 5 6 e.g recommendation cm/rec 2 committee ministers member states roles responsibilities internet intermediaries 7 e.g. practical guide personal poli ce sector guidelines protection individuals regard processing personal world big 7 msi -net protection supervisor ethics advisory group parliament union agency fundamental fra scope guidelines adopted big “ contribute protection subjects regarding processing personal big context spelling applicable protection prin ciples corresponding practices view limiting risks subjects ’ risks mainly concern potential bias analysis underestimation legal social ethical implications big de cision -making processes marginalisation effective informed involvement individuals processes ” although focused big analytics guidelines cover variety questions involving dataintensive complicated ap plication decision making reason considerations potential ly positive role risk assessment encompassing ethical societal concerns testing minimi sation expert committees precautionary approach8 f reedom decision -maker equally applied remedies discussed report part ii concrete applications call analysis issues role transparency various values underpin applications suggest remedies e.g broader protection impact assessment potential limitations finally approach adopted existing supervisory bodies e.g protection supervisory autho rities need reconsidered light challenges posed potential consequences society sense – manner analogous9 big data10 – represents challenge application traditional processing principles11 warrant search applicative solutions safeguard personal fundamental i.5 individuals ’ self -determination processing last years privacy scholars repeatedly pointed weakness subjects ’ consent terms self -determination long technical processing notices social technical lock -ins obscure interface design lack awareness part subject reasons weakness moreover ai-based profiling nudging practices challenge idea freedom choice based contract ual agreement notion subjects ’ control finally frequent complexity obscurity algorithms hamper chance obtain ing real informed consent legal scholars addressed issues highlighting role transparency ex multis edwards vale selbst powles wachter mittelstadt floridi burrell rossi risk assessment guidelines mantelero flexible forms 8 commission group ethics science technologies 16 “ potential mi suse ‘ autonomous ’ technologies poses major challenge risk awareness precautionary approach crucial ” 9 sense norwegian protection authority “ report elaborates legal opinions technologies described report « big – protection principles pressure » report provide gr eater technical detail describing taking closer look four relevant challenges associated protection principles embodied gdpr fairness discrimination purpose limitation min imisation transparency ” 10 guidelines section ii “ given nature big uses application traditional principles processing e.g principle minimisation purpose lim itation fairness transparency free specific informed consent challenging technological scenario ” 11 example analytics make hard identify specific purpose processing moment collection machine algorithms hand whose purposes necessarily specified predict explain purpo ses achieved cases therefore transparency purpose manner processing remain limited 8 consent broad consent sheehan dynamic consent kaye although solutions provide definitive answer problem individual consent certain contexts solutions alone combined reinforce self-determination moreover notion self -determination circumscribed given case processing broad sense refer freedom choice nsmart version -equipped devices services office privacy commissioner canada “ smart devices appliances become normalized increasing “ erosion choice ” individuals would preferred “ non -smart ” versions ” .12 “ zero option ” goes b eyond individual dimension relates way community decide role play shaping social dynamics collective behaviour decisions affecting entire groups individuals asilomar principles “ co ntrol humans choose whether delegate decisions accomplish chosen objectives ” i.6 minimi sation big guidelines minimi sation13 poses challenges technologies differ big machine algorithms need large amount produce useful results means certain degree minimi sation possible moreover mentioned previous section “ zero option ” adoption solution help reduc e quantity collected limiting amount informatio n required e.g survey ing sample population rather large proportion addition council europe guidelines big extended guidelines contain principle equally applied collected processed way “ minimise presence redundant marginal ” .14 case primarily concerns training norwegian protection authority pointed “ would natural start restricted amount training monitor model ’ accuracy fed ” norwe gian protection authority moreover studies could examine develop ment algorithms gradually delete using automatic forgetting mechanisms gama 12 -13 although affect ex post explanation based decisions doshi -velez 10 although machine necessarily require large datasets training phase important adopt design paradigm critically assesses nature amount reducing redundant marginal gradually increasing training dataset .15 minimisation achieved training algorithms using synthetic data16 uk department culture originat ing sub -set personal subsequently anonymised barse al. 12 protocol amending convention protection individuals regard automatic processing personal ets 108 explanatory report para 40 13 modernised convention protection individuals regard processing personal art 5 14 guidelines section iv para 4.2 15 guidelines section iv para 4.3 “ wh en technically feasible controllers applicable processors test adequacy -design solutions adopted limited amount means simulations larger ” 16 synthetic generated model built real representative original real definition synthetic oecd ‘ glossary statistical terms ’ . //ec.europa.eu/eurostat/ramon/coded_files/oecd_glossary_stat_terms.pdf “ approach confidentiality instead disseminating real synthetic generated one population models released ” 9 i.7 bias although accurate reduce eliminate bias decision -making possible data-intensive applications affected potential bias deterministic machine uses input extract analytics create train ml models bias concern scientists ’ methods e.g measurement bias bias affecting survey methodolog ies bias cleaning pre -processing tages veale binns object ir investigation e.g social bias due historical bias17 underrepresentation categories world economic forum 8 -9 sources e.g selection bias person responsible analysis e.g confirmation bias uk department culture commissioner ’ office 43 -44 institute biased datasets adversely affect algorithms higher impact case ml bias affect design training algorithm issue already partially addressed council europe guidelines big w hich suggest by-design approach avoid “ potential biases risk discrimination negative impact fundamental freedoms subjects collection analysis stages ” .18 bias due biased datasets institute 4 16 -17 result intentional unintentional decisions developers sense achine predictions performance “ constrained decisions values design develop maintain shape within understanding world ” institute 18 w hy hand designers alone technical mean less aware societal consequences decisions committees experts range fields social scien ce law ethics etc represent best setting discuss address questions impact individuals society section ii.3.1 compensating limited viewpoint developers multidisciplinary committees might able detect potential bias depends identity developers e.g gender bias ideological bias -representation minorities institute 5 another way reduce chances application bias participatory forms risk assessment mantelero focused merely security quality section ii.3.2 engagement groups potentially affected applications contribute detection removal existing bias institute 24 approach focused responsible design guidelines ,19 aims prevent biased condition affect datasets algorithms context necessarily characterised certain degree obscurity complexity prior assessment responsible design effective analys carried discriminatory result discovered selbst 201 7 163 “ even result traced quality problem problems ten quite complicated rectify might easy determine something difficult figure something … even sources bias identified magnitude source ’ effec still likely unknown ” brauneis 131 17 e.g amazon ditched recruiting tool favored men technical jobs guardian 10. //www.theguardian.com/technology//oct/10/amazon -hiring -ai-gender -bias-recruiting -engine “ company realized rating candidates software developer jobs technical posts gender -neutral way amazon ’ computer models trained vet applicants observing patterns résumés submitted company 10 -year period came men reflection male dominance across tech industry ” 18 guidelines section iv para 4.2 19 guidelines section iv.4.2 “ controllers applicable processors carefully consider design processing order minimise presence redundant marginal avoid potential da ta biases risk discrimination negative impact fundamental freedoms subjects collection analysis stages ” 10 attention potential bias ear liest design stage uk department culture entails deeper reflection training datasets training phase general curb negative consequences historical bias pre-existing -sets point suggested tracking “ provenance training datasets throughout life cycle ” institute accurate test ing training phase deployment algorithms large could reveal bias guidelines big highlight role simulations guidelines big 20 institute moreover bias involve machine -generated bias different bias cummings 2 “ machines humans different capabilities equally importantly make different mistakes based fundamentally divergent decision -making architectures ” caruana al. szegedy al. context assessment potential bias become controversial given multiple variables involved classification people groups necessarily correspond traditional discriminatory categories donovan al. 5 questions regarding machine bias deflected argument decisions fallible way reduce error four reasons comparison work first solutions designed applied serial ly product liability poor design i.e bias inevitably affects numerous people similar circumstances whereas error affects individual case second although fields error rates close lower tha n brain image labelling instance index complicated decision making tasks higher error rat es21 cummings al. 13 third socio -cultural dimension error sets apart machine error terms social acceptability exoneration necessarily influences propensity adopt potentially fallible solutions finally comparing adverse ou tcomes decisions e.g federal ministry transport infrastructure 10 “ licensing automated justifiable unless promises produce least diminution harm compared driving words positive balance r isks ” essentially based mere numerical comparison resulting harms e.g number victims -driven cars v s. number full autonomous cars reductive assessing consequences decisions need consider distribution effects i.e individuals adversely affected belonging different categories varying conditions harm occurred severity consequences etc. moreover sort quantitative approach appear odds precautionary approach guidelines require adoption risk prevention policies rather th mere reduction harm 20 guidelines section iv.4.3 “ technically feasible controllers ap plicable processors test adequacy -design solutions adopted limited amount means simulations larger would make possible assess potential bias different param eters analysing provide evidence minimise mitigate potential negative outcomes identified risk -assessment process described section iv.2 ” 21 e.g aletras n tsarapatsanis preoţiuc -pietro la mpos v. . predicting judicial decisions court natural language processing perspective peerj computer science 2 e93 //doi.org/10.7717/peerj -cs.93 part ii challenges possible remedies ii.1 limitations protection regulations well convention 108 provide safeguards equally applied algorithms including algorithms automated decision -making however red line automated decision drawn basis mere existence non -human decision -making process indeed supposedly reliable nature mathematics -based solutions induce taking decisions th e basis algorithms place trust picture individuals society analytics suggest moreover attitude reinforced threat potential sanctions taking decision ignores results produced analytics presence decision -maker per se sufficient algorithms benefit allure mathematical objectivity combined complexity management subordinate taking decision organis ation make harder decision -maker take decision one suggested algorithm.22 distinction made cases decision maker effective freedom guidelines big already highlighted importance protecting effective freedom decision -maker .23 assessing case potential imbalance important role played expert committee section ii.3.1 facilitate stakeholders ’ participation assessment section ii.3.2 decisions delegated -based decision -makers effective oversight decis ions broader question arise whether adopt rather -based methods .24 lead communities groups potentially affected towards participatory discussion adoption solution analysing potent ial risks risk asse ssment adopted mo nitoring ir application vigilance ii.2 transparency context ransparency25 several different meanings consist disclosure applications description logic access structure algorithms – applicable – datasets train algorithms moreover transparency ex ante ex post e.g binns al. requirement -centred decision -making although transparency important scrutiny automated decision -making models reisman al. 5 generic statement little tackle ris k unfair illegitimate hand access ing algorithms ’ structure make possible detect potential bias however ip competition issues sometimes restrict access 22 brauneis robert ellen p goodman ‘ algorithmic tr ansparency smart city ’ yale j. l. tech 20 103 126 -127 “ time deference algorithms weaken decision -making capacity government officials along sense engagement agency ” 23 guidelines section iv 7.4 “ basis reasonable arguments decision -maker allowed freedom rely result recommendations provided using big ” 24 e.g. itu 34 “ dr margaret chan former director -general observed “ medical decisions complex based many factors including care compassion patients doubt machine imitate – act – compassion machines rationalize streamline replace doctors nd nurses interactions patients ” article 5 modernised convention 108 explanatory report point principle “ respected stages processing including initial stage i.e de ciding whether carry processing ” 25 article 8 modernised convention 108 12 case even barriers exist complexity adopted models represent major challenge cognition lipton 13 addition cases transparency prevent bodies carrying duties e.g predictive policing conflict controller ’ security obligations concerning personal subjects requesting access veale al. forthcoming .26 reasons solution focused disclosing logic algorithms better option .27 even disclosure interpreted less narrow ly giving type input expected output,28 explaining variables weight shining light analytics architecture various forms transparen cy regarding logic algorithms complex analysis processes e.g deep -learning challenge notion transparency – terms expla ining logic algorithms goodman flaxman doshi -velez decisions taken using analytics29 – non -deterministic make hard provide detailed logic behind processing furthermore dynamic nature many algorithms contrast nature transparency algorithms continuously update changed whereas transparency disclosure concerns algorithm given moment finally access algorithms enough de tect potential bias resources terms time skills required perform kind analys ananny crawford “ ideal transparency places tremendous burden individuals seek interpre determine significance ” result deterrent effect solutions auditing veale binns intervention decision -maker impaired .30 studies currently trying develop bias detection methods based algorithms ,31 though hard introduc ing algorithmic supervisor algorithms reduce complexity governance points weakens argument increased transparency generally burrell especially sector,32 role safeguarding subject ’ self -determination edwards vale selbst powles wachter mittelstadt floridi rossi transparency difficult achieve regard architecture logic algorithms still helpful clarif ying reasons behind decision complex tool burt al. 2 transparency part solution challenges several limitations fully addressed ananny crawford forget algorithms 26 case algorithms sometimes harder beings read understand mathematical logical notation natural language “ hence isclosure computer code less helpful alternative easier means interpretation ” brauneis robert ellen p goodman ‘ algorithmic transparency smart city ’ yale j. l. tech 20 103 130 27 modernised conve ntion protection individuals regard processing personal article 9.1.c 28 provided ‘ ’ models giving subjects chance test analytics different input values even case however danger misleading identification relevant inputs diakopoulos 18 29 e.g article 10 loi n° 78 -17 du 6 janvier 1978 amended loi n° -493 du 20 juin . cases impossible explain reason decision suggested algorithm burrell moreover solutions explanation focused decisions concerning specific persons collective issues group level remain una ddressed 30 remedies possible many cases auditing process requires significant effort intervention compromised complexity processing 31 e.g lomas natasha . ibm launches cloud tool detect bias explain automated decisions techcrunch blog 19. accessed 21 . //social.techcrunch.com//09/19/ibm launches -cloud -tool-to-detect -ai-bias-and-explain -automated -decisions/ 32 e.g article 10 n. 2 loi n° 78 -17 du 6 janvier 1978 amended loi n° -493 du 20 juin . sector known algorithms great attention principle equal treatment commitment transparency access administrative processes limitations affect algorithmic transparency sector brauneis robert ellen p goodman ‘ algorithmic transparency smart city ’ yale j. l. tech 20 103 –176 “ le arned three principal impediments making government big prediction transparent 1 absence appropriate record generation practices around algorithmic processes 2 insufficient government insistence appropriate disclosure practices 3 assertion trade secrecy confidential privileges government contractors article investigate ” 13 one component application datasets training analys biased datasets automatically produce biased results finally data-intensive applications de-contextuali sed ignoring contextual often vital understand apply solution pro posed application decontextuali sation danger choice algorithmic model – models originally one purpose -used different context different purpose donovan al. 7 cite case predpol algorithm originally designed predict earthquakes later identify crime hotspots assign police – using models trained historical different population institute ii.3.1 risk assessment given limits transparency individual self -determination section i.5 protection regulations increasingly stressing role risk assessment .33 risk assessment controller safe environment greatly enhance individuals ’ trust willingness applications users ’ preferences based effective risk analysis measures mitigate risks norwegian protection authority 4 rather merely relying marketing campaign bran reputation algorithms modern processing techniques council europe -committee experts internet intermediaries msi -net well trend towards data-intensive technologi es edps encouraged take wider view possible adverse outcomes processing asilomar principles “ risks risks posed especially catastrophic existential risks subject planning mitigation efforts commensurate expected impact ” groups experts scholars gone beyond traditional sphere protection taylor floridi van der sloot consider impact fundamental collective social ethical values mantelero access assessment compliance ethical social values complicated traditional protection assessment whereas example values e.g integrity underlying security management technologically -based th us generalised across various social contexts social ethical values situation different necessarily context -specific differ one community another world economic forum 12 making harder identify benchmark kind risk assessment point clearly addressed first section guidelines big council europe urges controllers processors “ adequately take account likely impact intended big processing broader ethical social implications ” order safeguard hum fundamental freedoms light convention 108.34 element risk-assessment concerns range interests safeguarded protected assessment addresses go beyond traditional protection like non-discrimination35 barocas selbsr 36 well respect social ethical values economic social committee institute 34 -35 “ order achieve 33 modernised convention protection individuals regard processing personal art 10.2 34 guidelines section iv para 1.1 35 modernised convention protection individuals regard proce ssing personal article 6.2 36 regarding self -driving cars federal ministry transport infrastructure . federal government ‘ action plan report ethics commission automated connected driv ing ethical rules self -driving computers //www.bmvi.de/shareddocs/en/publications/action -plan-on-thereport -ethics -commission -acd.pdf __blob=publicationfile “ case “ dilemmatic ” situations injury persons ruled commission states distinction based personal features age gender etc. ” 14 ethical wider implications addressed institutional changes hold power accountable ” access guidelines recognise nature social ethical values insist uses conflict “ ethical values commonly accepted relevant community communities prejudice societal interests values norms ” .37 guidelines acknowledge difficulties identifying values considered broader assessment propos e practical steps wards end following view privacy scholars examined issue wright suggest “ common guiding ethical values found international charters fundamental freedom convention ” given context -dependent nature social ethical assessment fact international charters provide high -level guidance guidelines combine general suggestion tailored option represented “ ad hoc ethics committees ” .38 assessment detects “ high impact big ethical values ” committees cases already exist practice identify specific ethical valu es safeguarded regard given providing detailed context -based guidance risk assessment.39 “ architecture values ” defined guidelines based three layers first general level represented “ common guiding ethical values ” international charters fundamental freedoms second layer takes account context -dependent nature social ethical assessment focuses values social interests given communities finally third layer consists specific set ethical values identified ethics committees relation given complexity assessment entails continuous evolution potential risks measures tackle respect protection supervisory authorities play significant role supporting controllers informing security measures providing detailed guidelines risk -assessment process.40 guidelines therefore leave assessment exclusively hands controllers line approach adopted regulation /679 big “ sig nificantly impact ” fundamental freedoms subjects controllers consult supervisory authorities seek advice mitigate risks outlined impact assessment 41 guidelines big reach number conclusions extended focussing automation decision -making core challenging applications finally increased burden consequent broader assessment justified nature freedoms potentially affected application represents opportunity achieve competitive advantage fostering trust42 products services give companies chance better respond increasing consumers ’ concern similarly increasing government agencies ’ accountability increase citizens ’ trust administrati prevent unfair decisions perspective significant role 37 guidelin es section iv para 1.2 38 guidelines section iv para 1.3 “ assessment likely impact intended processing described section iv.2 highlights high impact big ethical values controllers could establish n ad hoc ethics committee rely existing ones identify specific ethical values safeguarded ” 39 two -layer model based general guidelines tailored guidance provided ad hoc committee already adop ted clinical trials big context specific application poses context -related questions necessarily addressed depending conflicting interes ts case result ‘ context ’ asses sment conflicting interests 40 guidelines section iv para 2.8 41 guidelines section iv para 2.8 42 modernised convention protection individuals regard processing personal explanatory report “ innovative technologies respect help build trust innovation technologies enable ” 15 played certifications ieee 46 “ additionally need develop certification scheme ai/as ensures technologies independently assessed safe ethically sound ” brundage al. 56 93 codes conduct standards different tool contribute increas e accountability provide guidance integrity,43 encompass ing procedures race decision -making process prevent form manipulation generated results ii.3.2 ethics committees respect data-intensive applications ethics committee attracting increasing attention circles though unanimous consensus nature function theoretical studies policy document corporate initiatives offer differ ing solutions regard first difference approach emerges concerns level committees work polonetsky tene jerome calo white house ieee proposals describe national committees villani provide general guidelines issues development.44 completely idea resembles existing national bioethical committees however case -intensive applications personal interplay national committees n ational protection authorities needs examined carefully mantelero interplay national bodies antitrust national security authorities many countries already independent watchdogs supervising specific sector applications operate operate regulatory perspective therefore important collaborate authorities reconsider role strengthen ir mutual cooperation p rotection supervisor 3 15 conseil national du numérique 74 different approach would introduce ethics committees company level supporting controllers specific applications focusing controllers ’ operati ons might assume broader role act expert committees ethical issues lso broad range societal issues relating including contextual application fundamental mantelero several companies45 already set internal external committees advise critical projects second solution based corporate ethics committees creates fewer difficulties terms overlap exi sting regulator supervising bodies require c learly defined relationship committees supervisory authorities national legislators might empower supervisory authorities scrutini se committees shortcomings abilities decisions affect processing conseil national du numérique types advisory boards creating ethics committees r aises questions independency internal external status best practice avoid conflict interest 43 article 7 modernised convention 108 44 uk consultation centre ethics innovation //www.gov.uk/gov ernment/consultations/consultation -on-the-centre -for-data-ethics -and-innovation/centre for-data-ethics -and-innovation -consultation 45 sense increasing propensity big -intensive high -tech companies set ethic committees advisory boards e.g. natasha lomas ‘ deepmind ethics unit questions it… ’ techcrunch 4 //social.techcrunch.com//10/04/deepmind -now-has-an-ai-ethics -research -unit-we-have-a-few-questions for-it/ accessed axon ethics board //it.axon.com/info/ai -ethics accessed 9 dna web team ‘ google drafting ethical guidelines guide tech employees protest defence project ’ dna india 15 //www.dnaindia.com/technology/report -google -drafting -ethical -guidelines -to-guide -use-oftech-after-employees -protest -defence -project -2605149 accessed 7 . united nations . guiding principles business impleme nting united nations “ protect respect remedy ” framework united nations council un doc hr/pub/11/04 16 make committees depend complexity tools applications societal issues significant legal ethical sociological expertise well domain specific knowledge essential .46 committees play even important role areas transparency stakeholders ’ engagement difficult achieve predictive justice crime detection predictive policing ethics committees provide valuable support developers design ing s-based socially -oriented algorithms moreover dialogue developers committee47 favour creation transparent processing procedures facilitate clearer definition rationale section ii.2 ii.3.3 participatory assessment experts e.g ethics committees play important role detecti ng potential ly adverse consequences applications help controllers address critical issue however cases analysis impossible without engaging target communities groups social impact assessment societal consequences arouse interest participation individual group empowerment assessment process non discrimination equal participation assessment participatory approach48 helpful gaining better understanding various competing interests ethical social values.49 46 lower level technical complexity terms consequences applications committee could repl aced expert ethics society similar dpo ’ role protection mandatory requirement regarding appointment quality members ethics committee appointments guided type potential impact fundamental taking ethical societal issues key criteria sense ieee 41 -42 recommends “ create roles senior level marketers ethicists lawyers pragmatically im plement ethically aligned design … precedent type leader found idea chief values officer created kay firth -butterfield ” cser cambridge kay firth -butterfield lucid ’ ethics advisory panel. . //www.y outube.com/watch v=w3 -wygbnzu4 47 uk department culture media sport ‘ ethics framework gov.uk ’ section 3 proportionate user need accessed 4 . //www.gov.uk/guidance/3 -use-datathat-is-proportionate -to-the-user-need 48 role participatory approaches stakeholders ’ engagement specifically recognised context fundamental danish institute 24 paul de hert ‘ perspecti privacy protection impact assessments david wright paul de hert eds privacy impact assessment springer dordrecht 72 “ case law required clarify scope duty study impact certain technologies nitiatives outside context environmental health regardless terms one safely adduce current framework requires states organise solid decision -making procedures involve persons affected tech nologies ” 49 participation various stakeholders e.g engagement civil society business community defining sectoral guidelines values effective mere transparency despite emphasis latter recent processing debate danish institute 10 `` engagement -holders stakeholders essential hria … stakeholder engagement therefore situated core cross -cutting component ” wa lker 41 “ participation end – – means empowering communities influence policies projects affect well building capacity decision -makers take account righ ts individuals communities formulating implementing projects policies ” limited form engagement based awareness suggested council europe committee experts internet intermediaries council europe -commit tee experts internet intermediaries msi -net 45 “ awareness discourse crucially important available means inform engage general users empowered critically understand deal logic operation algorithms include limited media literacy campaigns institutions using algorithmic processes encouraged provide easily accessible explanations respect proced ures followed algorithms decisions made industries develop analytical algorithmic decision -making collection processes particular responsibility create awareness 17 stakeholder engagement represents goal assessment united nations office high commissioner since reduces risk representing certain groups flag critical issu es underestimated ignored controller wright mordini 402 however stakeholder engagement seen way decision makers controllers case evade responsibilities leaders entire process palm hansson decision -makers remain committed achieving best results terms minimising negative impact processing individuals society finally p articipatory assessment far-reaching effects algorithmic decision -making cnil 30 drive controllers adopt co-design solutions developing applications actively engaging groups potentially affected ii.4 liability vigilance liability around applications remains open issue various reasons product liability whose principles focused risk management uncertainty broadly extended number applicable regulatory models strict liability liability based fault etc strategies state intervention mandatory insurance etc. one valuable solution appears extension product liability logic algorithms channelling liability producer would seems workable alternative protection officer algorithms cnil 56 “ identifying within company authority team responsible algorithm ’ operation moment processes humans ” pervasive ness applications different parts involved role user make difficult disentangle different aspects liability moreover l iability serves sort closing rule valuable various ex ante remedies transparency work ed asilomar principles “ failure transparency causes harm possible ascertain ” however since tort liability normally regulated national legislators report needs discuss different available solutions.50 nevertheless worth pointing risk management transparency liability combined applications phase following stage algorithms access acm 2.5 c ould lead supervisory authorities controllers adopt forms algorithm vigilance analogous pharmacovigilance react quickly event unexpected dangerous outcomes e.g microsoft ’ chatbot tay51 commission nationale de l ’ informatique des libertés linc 52. ii 5 sector -specifi c issues significant impact many sectors society economy e.g predictive policing justice precision medicine marketing political propaganda sector -specific applications characterised different challenges properly discussed report provides understanding includin g respect possible biases induced design algorithms ” 50 liability assumes different forms different fields application e.g ip liability decision -making cars etc since liability quite conte xt specific 51 vincent james ‘ twitter taught microsoft ’ friendly chatbot racist asshole less day ’ verge 24 . //www.theverge.com//3/24/11297050/tay -microsoft -chatbot -racist 52 voice . universal guidelines //thepublicvoice.org/ai universal -guidelines/ “ termination obligation institution established affirmative obligation terminate control longer possible ” 18 general overview main issues concerning interplay protection last section theref ore briefly shed light two main areas sector workplace applications r aise number specific questions sector reisman al. largely due imbalance power citizen administration essential services provided moreover adoption complex obscure solutions governments agencies make difficult comply accountability obligations concerning proce ssing reisman al. state affairs would seem warrant adoption tighter safeguards beyond remit ad hoc committees auditing afeguards contemplate evaluation process critically assess need proposed solutions suitability delivery services agencies private companies acting behalf process requires “ minimum applications available auditing testing review subject accountability standards ” institute achieve goal procurement procedures impose specific duties transparency prior assessment providers moreover procurement procedures address issues concerning trade secrets ip protection introducing specific contractual exceptions increase transparency make auditing possible regarding effects future work leaving aside impact labour market solutions e ffect relationships within workplace.53 first place increase employer ’ control employees situation often characterised imbalance power moreover unregulated forms processing might workplace vivo social experiment raising additional important questions role transparency ethics committees voluntary participation dat processing finally devices given employees employers dual instance wearable well devices worn workplace gather biological intended safeguard employe e ’ health employees outside work track sport fitness unless repercussions protection individual freedom properly examined twin uses blur boundaries work private life institute 10 raising issues pervasive control disconnect 53 eur court hr bărbulescu v. romania judgment 5 sept ember application 61496/08 eur court hr libert v. france judgment 22 application 588/13 19 references \\uf0b7 access . toronto declaration protecting equality non discrimination machine //www.accessnow.org/the -toronto declaration -protecting -the-rights -to-equality -and-non-discrimination -inmachine -learning systems/ \\uf0b7 acm . acm code ethics professional conduct //www.acm.org/code -ofethics \\uf0b7 institute . report social economic implications technologies near -term //ainowinstitute.org/ai_now__report.pdf \\uf0b7 institute . report accessed 26 . //assets.contentful.com/8wprhhvnpfc0/1a9c3ztcza2keym64wsc2a/8636557c5fb14f2b 74b2be64c3ce0c78/_ai_now_institute__report_.pdf \\uf0b7 institute . litigating algorithms challenging government algorithmic decision //ainowinstitute.org/litigatingalgorithms.pdf \\uf0b7 ananny m. crawford k. . seeing without knowing limitations transparency ideal application algorithmic accountability media society //doi.org/10.1177/1461444816676645 \\uf0b7 intel ligence index annual report . //aiindex.org/ -report.pdf accessed 5 \\uf0b7 asilomar principles //futureoflife.org/ai -principles/ \\uf0b7 axon ethics board //it.axon.com/info/ai -ethics \\uf0b7 barocas s. nissenbaum h. . big ’ end run around anonymity consent lane j. stodden v. bender s. nissenbaum h. eds privacy big good frameworks engagement cambridge university press \\uf0b7 barocas s. selbst r a.d. . big ’ disparate impact 104 3 california law review 671 -732 \\uf0b7 barse e. l. h. kvarnstrom e. jonsson ‘ synthesizing test fraud detection ’ 19th annual computer security applications conference . proceedings 384–94 //doi.org/10.1109/csac..1254343 \\uf0b7 binns r. “ ’ reducing percentage ” perceptions justice algorithmic decisions arxiv:1801.10408 cs 1 –14 //doi.org/10.1145/3173574.3173951 \\uf0b7 bostrom n. . superintelligence paths dangers strategies oxford oxford university press \\uf0b7 boyd d. crawford k. . critical questions big provocations cultural technological scholarly phenomenon 15 5 communication society 662–679 \\uf0b7 brauneis r. goodman e.p . algorithmic transparency smart city yale j. l. tech 20 103 –76 \\uf0b7 bray p. international differences ethical standards interpretation legal frameworks satori deliverable d3.2 //satoriproject.eu/work_packages/l egalaspects -and-impacts -of-globalization/ \\uf0b7 brundage m. ‘ malicious forecasting prevention mitigation ’ . //maliciousaireport.com/ 56 93 \\uf0b7 burrell j . machine ‘ thinks ’ understanding machine algorithms 3 1 big society //doi.org/10.1177/2053951715622512 \\uf0b7 burt a. leong b. shirrell s. . beyond explainability practical guide managing risk machine models future privacy forum \\uf0b7 calo ryan . consumer subject review boards thought experiment 66 stan l. rev online 97 //www.stanfordlawreview.org/online/privacy -and-big-data/consumer -subject review -boards accessed 23 \\uf0b7 caruana r. lou y. gehrke j. koch p. sturm m. elhadad n. . intelligible models healthcare predicting pneumonia risk hospital 30 -day readmission proceedings 20 21st annual sigkdd international conference knowledge discovery mining 1721 -1730 \\uf0b7 citron d.k pasquale f. . scored society due process automated predictions 89 wash. l. rev 1 –33 \\uf0b7 cnil linc . la plateforme ’ une ville les données personnelles au coeur de la fabrique de la smart city //www.cnil.fr/sites/default/files/atoms/files/cnil_cahiers_ip5.pdf \\uf0b7 cnil . humans keep upper hand ethical matters raised algorithms port debate led french protection authority cnil part ethical discussion assignment set republic bill ’ p. 14. //www.cnil.fr/sites/default/files/atoms/files/cnil_rapport_ai_gb_web.pdf \\uf0b7 cnil . humans keep upper hand ethical matters raised algorithms report debate led french protection authority cnil part ethical discussion assignment set dig ital republic bill //www.cnil.fr/sites/default/files/atoms/files/cnil_rapport_ai_gb_web.pdf \\uf0b7 commission group ethics science echnologies . statement robotics ‘ autonomous ’ retrieved //ec.europa.eu/research/ege/pdf/ege_ai_statement_.pdf \\uf0b7 conseil national du numérique . ambition numérique pour une politique francaise europeéenne de la numérique //www.cil.cnrs.fr/cil/img/pdf/cnnum -- rapport ambition -numerique.pdf \\uf0b7 council europe . guidelines protection individuals regard processing personal world big //rm.coe.int/coermpubliccommonsearchservices/displaydctmcontent documentid= 09000016806ebe7a \\uf0b7 council europe -committee experts internet intermediaries msi -net . study dimensions au tomated processing techniques particular algorithms possible regulatory implications //rm.coe.int/algorithms -and-human -en-rev/16807956b5 \\uf0b7 cummings m. l roff heather m. cukier kenneth parakilas jacob bryce hannah . chatham house report international affairs disruption anticipated london chatham house royal institute international affairs //www.chathamhouse.org/sites/default/files/publications/resear ch/ -06-14-artificial -international -affairs -cummings -roff-cukier -parakilas -bryce.pdf \\uf0b7 diakopoulos n. . algorithmic accountability reporting investigation black boxes tow journalism \\uf0b7 dna web team ‘ google drafting ethical guidelines guide tech employees protest defence project ’ dna india 15 //www.dnaindia.com/technology/report google -drafting -ethical -guidelines -to-guide -use-of-tech-after-employees -protest -defence project -2605149 \\uf0b7 donovan j. matthews j. caplan r. hanson l. . algorithmic accountability primer //datasociety.net/output/algorithmic -accountability -a-primer/ \\uf0b7 doshi -velez f. . accountability law role explanation //cyber.harvard.edu/publications//11/aiexplanation \\uf0b7 edwards l. vale m. slave algorithm 'right explanation probably remedy lo oking 16 1 duke law review 18 -84 \\uf0b7 commission group ethics science technologies . statement robotics ‘ autonomous ’ //ec.europa.eu/research/ege/pdf/ege_ai_statement_.pdf \\uf0b7 commission . landscape //ec.europa.eu/digital -single -market/en/news/european -artificial -intelligence -landscape \\uf0b7 protection supervisor ethics advisory group . towards ethics //edps.europa.eu/si tes/edp/files/publication/18 -01-25 eag report en.pdf \\uf0b7 protection supervisor . opinion 8/ edps opinion coherent enforcement fundamental age big 21 \\uf0b7 economic social committee . ethics big balancing economic benefits ethical questions big policy context //www.eesc.europa.eu/en/our -work/publications -other -work/publications/ethics -big-data \\uf0b7 parliament . parliament resolution 14 fundamental implications big privacy protection non -discrimin ation security law -enforcement /2225 ini //www.europarl.europa.eu/sides/getdoc.do pubref= -//ep//text+ta+p8 -ta- 0076+0+doc+xml+v0//en language=en \\uf0b7 union agency fundamental fra bigdata discrimination -supported decision making //fra.europa .eu/en/publication//big -datadiscrimination \\uf0b7 executive office president national science council committee . preparing future washington d.c. //obamawhitehouse.archives.gov/sites/default/files/whitehouse_files/microsites/ostp/nst c/preparing_for_the_future_of_ai.pdf \\uf0b7 federal ministry transport infrastructure ethics commission automated connected driving accessed 17 . //www.bm vi.de/shareddocs/en/publications/report -ethics commission.pdf __blob=publicationfile \\uf0b7 gama j. . survey concept drift adaptation acm computing surveys 1 1 //www.win.tue.nl/~mpechen/publications/pubs/gama_acmcs_adaptationcd_accepted.p df \\uf0b7 goodman b flaxman s. . regulations algorithmic decision -making “ explanation ” arxiv:1606.08813 cs stat //arxiv.org/abs/1606.08813 \\uf0b7 hildebrandt m. . smart technologies end law novel entanglements law edward elgar publishing \\uf0b7 ieee global initiative ethical considera tions autonomous . ethically aligned design vision prioritizing wellbeing autonomous version 1. ieee . //standards.ieee.org/develop/indconn/ec/autonomous_systems.html.ieee \\uf0b7 commissioner ’ office ‘ big machine protection ’ . //ico.org.uk/media/for -organisations/documents/559/big data-ai-ml-and-data-protection.pdf \\uf0b7 itu . good global summit rep ort //www.itu.int/en/itu t/ai/documents/report/ai_for_good_global_summit_report_.pdf \\uf0b7 kaye j. . dynamic consent patient interface twenty -first century networks 23 2 journal genetics 141 \\uf0b7 kurzweil r. . singularity near humans transcend biology london duckworth \\uf0b7 linnet t. floridi l. van der sloot b eds . group privacy challenges technologies springer international publishing \\uf0b7 lipton z.c . mythos model interpretability machine concept interpretability important slippery acmqueue 16 3 //queue.acm.org/detail.cfm id=3241340 \\uf0b7 lomas n. ‘ deepmind ethics unit questions it… ’ techcrunch 4 //social.techcrunch.com//10/04/deepmind -now-hasan-ai-ethics -research -unit-we-have -a-few-questions -for-it/ accessed 3 \\uf0b7 lycett m. . dataf ication making sense big complex world 22 4 journal 381 –386 \\uf0b7 mantelero . big blueprint social ethical impact assessment assessment computer law security review //doi.org/10.1016/j.clsr..05.017 \\uf0b7 mantelero . future consumer protection e.u rethinking “ notice consent ” paradigm era predictive analytics computer law security review 30 6 643 -660 22 \\uf0b7 mantelero . regulating big guidelines council europe context protection framework ’ 33 5 computer law sec rev 584-602 \\uf0b7 er‐schönberger v. cukier k. . big revolution live work think london john murray \\uf0b7 mcculloch w.s pitts w.h 1943. logical calculus ideas immanent nervous activity bulletin mathematical biophysics 5:115 -133 1943 \\uf0b7 office privacy commissioner canada . internet things introduction privacy issues retail home environments //www.priv.gc.ca/en/opc -actions -and-decisions/research/explore -privacy research//iot_02/ heading -0-0-2-15 \\uf0b7 o'neil c. . weapons math destruction london penguin books \\uf0b7 palm e. hansson s.o . case ethical assessment eta 73 5 technological forecasting social change 543 550 –551 \\uf0b7 polonetsky j. tene o. jerome j . beyond common rule ethical structures non -academic settings colorado law journal 13 333-367 \\uf0b7 raso f. . opportunities risks //cyber.harvard.edu/sites/default/files/ -09/ 09_aihumanrightssmall.pdf subscribe=download+the+report \\uf0b7 reisman d. schultz j. crawford k. whittaker m. . algorithmic impact assessments practical framework agency accountability //ainowinstitute.org/aiareport.pdf \\uf0b7 rossi f. . potential benefits ethical considerations ’ parliament policy department c citizens ’ constitutional affairs briefing pe 571.380 //www.europarl.europa.eu/regdata/etudes/brie//571380/ipol_bri 571380_ en.pdf \\uf0b7 rouvroy “ men ” fundamental liberties world big ’ //rm.coe.int/coermpubliccommonsearchservices/displaydctmcontent documentid= 09000016806a6020 \\uf0b7 rubinstein i.s . big end privacy beginning 3 2 international privacy law 74 –87 \\uf0b7 selbst a.d. . disparate impact big policing georgia law review 52 1 109 – 195 \\uf0b7 selbst andrew d. powles julia . meaningful explanation 7 4 international privacy law 233 –242 \\uf0b7 sheehan m. . broad consent informed consent 3 health ethics 226 – 235 \\uf0b7 spiekermann s. . ethical innovation value -based design approach boca raton crc press \\uf0b7 szegedy c. zaremba w. sutske ver i. bruna j. erhan d. goodfellow i. fergus r. . intriguing properties neural networks //arxiv.org/abs/1312.6199 \\uf0b7 tene o. polonetsky j . privacy age big ime big decisions 64 stan l. rev online 63 –69 \\uf0b7 danish institute . impact assessment guidance toolbox danish institute //www.humanrights.dk/business/tools/human -rights -impact -assessment -guidance -andtoolbox \\uf0b7 ieee global initiative ethical considerations autonomous . ethically aligned design vision prioritizing wellbeing autonomous version 1. ieee . //standards.ieee.org/develop/indconn/ec/autonomous_systems.html \\uf0b7 norwegian protection authority . privacy report //www.datatilsynet.no/globalassets/global/english/ai -and-privacy.pdf \\uf0b7 turing a. m. 1950. computing machinery 49 mind 433 –460 23 \\uf0b7 uk department culture media sport ‘ ethics framework gov.uk ’ //www.gov.uk/government/publications/data -ethics -framework/data -ethics -framework \\uf0b7 united nations office f high commissioner . frequently asked questions -based approach cooperation ’ york geneva united nations \\uf0b7 united nations . guiding principles business implementi ng united nations “ protect respect remedy ” framework united nations council un doc hr/pub/11/04 \\uf0b7 veale m. binns r. . fairer machine real world mitigating discrimination without collecting sensitive big society 4 2 :2053951717743530 //doi.org/10.1177/2053951717743530 \\uf0b7 veale m. binns r. edwards l. . algorithms remember model inversion attacks protection law philosophical transactions royal society forthcoming //doi.org/10.1098/rsta..0083 \\uf0b7 villani c. . meaningful towards french strategy //www.aiforhumanity.fr/pdfs/missionvillani_report_eng -vf.pdf \\uf0b7 wachter s. mittelstadt b. floridi l. . explanation automated decision making exist general protection regulation 7 2 international privacy law 76 –99 \\uf0b7 walker s.m . future impact assessments trade agreements utrecht g.j wiarda institute legal //dspace.library.uu.nl/bitstream/handle/1874/36620/walker.pdf sequence=2 \\uf0b7 white house . consumer privacy bill §103 c administration discussion draft . //www.whitehouse.gov/sites /default/files/omb/legislative/letters/cpbr -act-of- discussion -draft.pdf \\uf0b7 wight d. mordini e. . privacy ethical impact assessment wright d. de hert p. eds privacy impact assessment springer dordrecht 397 –418 \\uf0b7 world economic forum . prevent discriminatory outcomes machine //www3.weforum.org/docs/wef_40065_white_paper_ho w_to_prevent_discriminatory_ outcomes_in_machine_learning.pdf \\uf0b7 wright d. de hert p. eds . privacy impact assessment springer dordrecht \\uf0b7 wright d. . framework ethical impact assessment 13 ethics inf technol 199 201 –202\",\n",
       " \"guidance auditing framework draft guidance consultation ico commissioner 's office auditing framework draft guidance consultation contents guidance ................................................................................... 4 produced guidance ................................................ 5 mean ‘ ’ ................................................................ 6 guidance relate ico work ......................... 7 guidance ................................................................... 8 ico focusing risk -based approach ........................ 8 guidance set principles ................................................. 9 legislation applies ................................................................... 10 guidance structured ........................................................ 11 accountability governance implications ofai ........... 12 approach governance risk management ............. 13 set meaningful risk appetite .................................... 13 need consider undertaking protection impact assessments ....................................................................... .. 15 understand controller/processor relationships ........ 21 -related trade -offs manage .......... 26 need ensure lawfulness fairness transparency ......................................................................................... 36 principle lawfulness fairness transparency apply ................................................................................................ 36 identify purposes lawful basis using .......... 37 need statistical accuracy ............................... 46 address risks bias discrimination ....................... 53 assess security minimisation ................ 64 security risks introduce ................................................ 64 case study security risks introduced externally maintained software steps take manage risks privacy attacks minimisation privacy -preserving techniques available case study losing track training ............................................. 66 build ................................................................... 67 types privacy attacks apply models ............................... 69 models ........................................................................................ .73 .................................................................................... 77 enable individual ........................ 86 individu apply different stages lifecycle ....... 86 version 1.0 2 auditing framework draft guidance consultation individual relate contained model ...... 91 enable individual relating solely automated decisions legal similar effect ............................................................... 92 role oversight .................................................. 97 version 1.0 3 auditing framework draft guidance consultation guidance glance applications incr easingly permeate many aspects lives understand distinct benefits bring risks pose freedoms individuals developed framework auditing focusing best practi ces protection compliance – whether design implement one third party provides solid methodology audit applications ensure process personal fairly comprises • auditing tools procedures audits investigations • detailed guidance protection includes indicative risk control measures deploy process personal guidance aimed two audiences • compliance protection officers dpos general counsel risk managers ico 's auditors • specialists including machine experts scientists software developers engineers cybersecurity risk managers guidance clarifies assess risks freedoms pose appropriate measures implement mitigate protection ‘ ethics ’ overlap guid ance provide generic ethical design principles corresponds different protection principles structured follows • part one addresses accountability governance including protection impact sessments dpias • part two covers fair lawful transparent processing including lawful bases assessing improving performance mitigating potential discrimination • part three addresses minimisation security • part four facilitate exercise individual including related automated decision -making version 1.0 4 audi ting framework -draft guidance consultation detail • produced guidance • mean ‘ ’ • guidance relate ico work • guidance • ico focusing risk -based approach • guidance set principles • legislation applies • guidance structured produced guidance uses everyday healthcare recruitment commerce beyond understand nefits bring organisations individuals risks ’ one three strategic priorities decided develop framework auditing compliance protection obligations framework • gives us solid methodology audit applications ensure process personal fairly lawfully transparently • ensures necessary measures place assess manage risks freedoms arise • supports work ur investigation assurance teams assessing compliance organisations using well using framework guide activity wanted share thinking behind framework therefore two distinct outputs 1. auditing tools procedures investigation assurance teams assessing compliance organisations using 2. detailed guidance protection organisations outlines thinking incl udes indicative risk control tables end section help organisations audit compliance guidance aims inform think constitutes best practice protection- compliant version 1.0 5 auditing framework -draft guidance consultation guidance statutory code contains advice interpret relevant law applies recommendations good practice organisational technical measures mitigate risks individuals cause exacerb ate penalty fail adopt good practice recommendations long find another way comply law reading – ico guidance strategy - mean ‘ ’ term ‘ ’ variety meanings within community refers various methods ‘ using non -human learn experience imitate intelligent behaviour ’ whilst context protection referred ‘ theory computer able perform tasks normally requiring visual perception speech recognition decision -making translation languages ’ however large amounts make predictions classifications individuals existed sectors like insurance since 19 th century long term ‘ ’ coined 1950s traditional forms statistical analysis statistical models calculated using pen paper later calculator modern machine techniques much easier create statistical models using computationally intensive techniques much larger multi-dimensional datasets increase complexity models combined decreasing costs creating heightened concerns risks freedoms individuals one prominent area ‘ machine ’ ml computational techniques create often complex statistical models using typically large quantities models make classifications predictions points involves ml recent interest driven ml way whether context image recognition speech -to-text classifying credit risk guidance therefore focuses protection challenges ml -based present acknowledging kinds differ processing large amounts personal purpose protection law applies processing context statistical models using models make predictions people guidance relevant regardless whether classify activities ml version 1.0 6 auditing framework -draft guidance consultation umbrella term ‘ ’ becom e mainstream way organisations refer range technologies mimic thought similar technologies similar sources risk likely benefit set risk measures whether call machine complex processing something else risks controls identified helpful important differences different types example simple regression models deep neural networks refer explicitly resources international working group protection telecommunications ’ working paper privacy external link gu idance relate ico work guidance designed complement existing ico resources including • big achine report published updated • guidance explaining decisions made produced collaboration alan turing institute explain guidance bi g report provide stron g foundatio n understanding protectio n implications f technologies note commissioner ’ foreword edition thi complicated fast -developing area considerations h ave arise n las three years n terms f risks pose individuals organisational technical measures taken address risks engageme nt stakeholders gaine additional insights nto org anisations using ground go beyo nd presented n report another significant challenge raise explainability par government ’ sector deal n collaboration turing institute produced guidance organisations best explain individuals resulted explain guidance published draft form consultation last year process finalising explain guidance light feedback stakeholders update links guidance c ompleted exp lain guidance already covers challenge explainability individuals substantia l detail guidance includes additional considerations explainability within organisation eg internal oversight compliance two pieces guidance complementary recommend reading tandem version 1.0 7 auditing framework -draft guidance consultation reading – ico guidance big machine protection ico turing consultation explaining decisions guidance guidance guidance covers best practices protection- compliant two broad intended audiences first compliance including • protection officers • general counsel • risk managers • ico ’ auditors – words utilise guidance exercise audit functions protection legislation second specialists including • machine developers scientists • software developers engineers • cybersecurity risk managers guidance written accessible audiences parts aimed primarily either compliance roles signposted accordingly ico focusing risk -based approach taking risk -based approach means • assessing risks freedoms individuals arise • implementing appropriate proportionate technical organisational measures mitigate risks general requirements protection law mean ignore law risks low mean stop planned project sufficiently mitigate risks help integrate guidan ce existing risk management process organised several major risk areas risk area describe version 1.0 8 auditing framework -draft guidance consultation • risks involved • increase likelihood and/or impact • possible measures could identify evaluate minimise monitor control risks technical organisational measures included consider good practice wide variety contexts however since many risk controls need adopt context- specific include exhaustive definitive list guidance covers -and-data-protection -specific risks implications risks governance accountability regardless whether using accountability measures place however adopting applications require r e-assess existing governance risk management practices applications exacerbate existing risks introduce ones generally make risks difficult assess manage decision -makers organisation therefore reconsider organisation ’ risk appetite light existing proposed applications sections guidance deep -dives one challenge areas explores associated risks processes controls guidance set principles guidance provide generic ethical and/or design principles overlaps ‘ ethics ’ protection proposed ethics principles already reflected protection law guidance focused protection compliance although protection dictate designers jobs process personal need comply principles protection design default direct application developers ’ go play role processing – however note • responsibility put place appropriate technical organisational measures designed im plement protection principles effective manner • developer personal train models controller processing protection law applies certain design choices lik ely result infringe protection one way guidance help designers engineers understand choices better design high performing whilst still protecting freedoms individuals version 1.0 9 auditing framework -draft guidance consultatio n worth noting work focuses exclusively protection challenges introduced heightened general protection considerations addressed except far relate challenged resources read global privacy assembly ’ ‘ declaration ethics protection ’ external link ethics protection intersect context legislation applies guidance deals challenges raises protection relevant piece uk legislation protection act . dpa sets uk ’ protection framework alongside general protection regu lation gdpr comprises following protection regimes • part 2 – supplements tailors gdpr uk • part 3 – sets separate regime law enforcement authorities • part 4 – sets separate regime three services guidance apply regardless part dpa applies processing however relevant differences requirements different regimes explicitly addressed text shou ld review guidance brexit impacts protection law impacts areas ico competence protection notably freedom considered reading – ico guidance different regimes read guide protection nee detail protection brexit faqs 10 version 1.0 auditing framework -draft guidance consultation guidance structured guidance divided several parts corresponding different protection principles part one addresses issues primarily relate accountability principle requires responsible complying protection principles demonstrating compliance sections part deal -specific implications accountability including da ta protection impact assessments dpias controller processor responsibilities assessing justifying trade -offs part two covers lawfulness fairness transparency processing personal sections covering lawful bases processing personal assessing improving performance mitigating potential discrimination ensure fair processing part three covers principle security minimisation part four co vers facilitate exercise individuals ’ personal relating solely automated decisions particular part four covers ensure meaningful input non -automated p artly-automated decisions meaningful review solely automated decisions 11 version 1.0 auditing framework -draft guidance consultation accountability governance implications glance accountability principle makes responsible complying protection demonstrating compliance context accountability requires • responsible complian ce • assess mitigate risks • document demonstrate compliant choices made consider issues part dpia intend note legally required complete dpia process personal dpias offer opportunity consider using process personal potential risks could due complex ity mutual dependency various kinds processing typically involved supply chains need take care understand identify controller processor relationships additionally depending designed deployed inevitably involve making trade -offs privacy competing interests need know trade -offs manage otherwise risk fail adequately assess strike balance however note always comply fundamental protection principles ‘ trade ’ requirement away detail • approach governa nce risk management • set meaningful risk appetite • need consider undertaking protection impac assessments • understand controller/processor relationships • -related trade -offs manage 12 version 1.0 auditi ng framework -draft guidance consultation approach governance risk management well potential make organisations efficient effective innovative however raises significant risks freedoms individuals well compliance challenges organisations different technological approaches either exacerbate mitigate issues many others much broader specific rest guidance suggests protection implications heavily dependent specific cases population deployed overla pping regulatory requirements well social cultural political considerations increases importance embedding protection design default organisation ’ culture processes technical complexities sys tems make difficult demonstrating addressed complexities important element accountability delegate issues scientists engineering teams senior management including protectio n officers dpos accountable understanding addressing appropriately promptly addition upskilling need diverse well resourced teams support discharging responsibilities need internal structures roles responsibilities maps training requirements policies incentives overall governance risk management strategy important underestimate initial ongoing level investment resources effort required governance risk management capabilities need proportionate particularly true adoption still initial stages associated laws regulations governance risk management best practices still developing quickly currently developing general accountability toolkit specific provides baseline demonstratin g accountability gdpr could build approach accountability update final version guidance refer final version accountability toolkit published set meaningful risk appetite risk -based approach protection law requires comply obligations implement appropriate measures context particular circumstances – nature scope context purposes 13 version 1.0 auditing framework -draft guidan ce consultation processin g inten risks poses individuals ’ freedoms compliance consideration therefore involve assessing risks nd freedoms f individuals takin g judgements wha appropriate circumstances cases need ensure comply protection requirements applie technologie proce ss personal n conte xt specific n ature f risks pose circumstances r processing require strike appropriate balance betwee n competin g interests yo u go ensuri ng protec tion compliance turn impact outcome processing unrealistic adop ‘ zero tolerance ’ approac h risks nd freedoms indee law n ot require – ensuring risks identified managed mitigated ‘ trade-o ffs manage ’ manage risks individuals tha arise processi ng personal n importan yo u develop mature understanding articulatio n fundamental risks nd balance othe r interests ultimately necessary fo r • assess risks individuals ’ poses • determine need address • establish impact ensure approach fits organisation circumstances processing appropriate risk assessment frameworks complex task take time get ultimately however give well ico fuller meaningful view risk positions adequacy compliance risk management approaches following sections deal -specific implications accountability including • undertake protection impact assessments • identify whether controller processor specific processing operations involved deployment resulting implications responsibilities • assess risks freedoms individuals address design decide 14 version 1.0 auditing framework -draft guidance consultati • document demonstrate approach take including decision processing question need consider undertaking protection impact assessments dpias key part protection law ’ accountability protection design dpias mere ticking compliance exercise effectively act roadmaps identify control risks freedoms pose perfect opportunity consider demonstrate accountability decisions make design procurement need carry dpias protection law using process personal likely result high risk individuals ’ freedoms therefore triggers legal requirement undertake dpia result assessment indicates residual high risk individuals sufficiently reduce consult ico prior starting processing addition conducting dpia required undertake kinds impact assessments voluntarily instance sector organisations required undertake equality impact assessments organisations voluntarily undertake ‘ algorithm impact assessments ’ reason combine exercises long assessment encompasses requirements dpia ico produced detailed guidance dpias explains required complete section sets things think carrying dpia processing person relevant provisions legislation articles 35 36 recitals 74 -77 84 89 -92 94 95 gdp r external link sections 64 65 dpa external link decide whether dpia list types processing likely result high risk process personal carry dpia case major project involves personal good practice dpia 15 version 1.0 auditing framework -draft guidance consultation read list processing operations ‘ likely result high risk ’ examples operations require dpia detail criteria high risk combination others reading – ico guidance ‘ decide whether dpia ’ guid ance dpias assess dpia dpia needs describe nature scope context purposes processing personal -it needs make going process need detail • collect store • volume variety sensitivity • nature relationship individuals • intended outcomes individuals wider society well context lifecyc le dpia best serve purpose undertake earliest stages project feature minimum following key components describe processing dpia include • systematic description processing activity including flows stages processes automated decisions ay produce effects individuals • explanation relevant variation margins error performance affect fairness personal processing ‘ statistical accuracy ’ • description scope context processing including process number subjects involved source far individuals likely expect processing dpia identify record degree involvement decision -making process stage takes place automated decisions subject intervention view implement processes ensure meaningful detail fact decisions overturned 16 version 1.0 auditing framework -draft guidance consultation difficult describe processing activity complex appropriate maintain two versions assessment • first presenting thorough technical description specialist audiences • second containing high -level description processing explaining logic personal inputs relate outputs affecting individuals dpia set roles obligations controller include processors involved partly wholly outsourced external providers organisations involved assess whether joint controllership exists article 26 gdpr collaborate dpia pro cess appropriate processor illustrate technical elements processing activity dpia reproducing processor example flow diagram processor ’ manual however generally avoid copying large sections processor ’ literature assessment relevant provisions legislation article 35 7 recitals 84 90 94 gdpr external link need consult anyone • seek document views individuals representatives unless good reason • consult relevant internal stakeholders • consult processor one • consider seeking legal advice expertise appropriate unless good reason seek document views individuals representatives intended processing operation dpia therefore important describe processing way consu lted understand relevant provisions legislation article 28 3 f article 35 9 gdpr external link assess necessity proportionality deployment process personal needs driven proven ability fulfil specific legitimate purpose 17 version 1.0 auditing framework -draft guidance consultation availability assessing necessity dpia evidence ’ accomplish purposes less intrusive way dpia allows demonstrate processing personal proportionate activity assessing proportionality need weigh interests using risks pose freedoms individuals ystems need think detriment individuals could follow bias inaccuracy algorithms sets within proportionality element dpia need assess whether individuals would reasonably expect conduct processing complement replace decision -making document dpia project might compare algorithmic accuracy side- by-side better describe trade -offs made example statistical accuracy minimisation document methodology rationale identify assess risks dpia process help objectively identify relevant risks assign score level risk measured likelihood severity impact individuals personal deployment pose risks individuals ’ considering sources risk dpia consider potential impact material non-material damage harm individuals instance machine reproduce discrimination historic patterns could fall foul equalities legislation similarly stop published based analysis creator ’ personal could impact freedom expression contexts consider relevant legal frameworks beyond protection relevant provisions legislation articles 35 7 c recitals 76 90 gdpr e xternal link identify mitigating measures identified risk consider options reduce level assessed risk examples could minimisation providing opportunities individuals opt processing 18 version 1.0 auditing framework -draft guidance consultation ask dpo advice considering ways reduce avoid risk record dpia whether chosen measure reduces eliminates risk question important dpos governance professionals involved projects earliest stages open channels communicat ion project teams ensure identify address risks early lifecycle protection afterthought dpo ’ professional opinion come surprise eleventh hour dpia document safeguards put place ensure individuals responsible testing validation deployment monitoring adequately trained appreciation protection implications processing dpia evidence organisational measures put place appropriate training mitigate risks associated error document technical measures designed reduce risks security accuracy personal processed measures introduced mitigate risks identified dpia document residual levels risk posed processing required eliminate every risk identified however assessment indicates high risk unable sufficiently reduce required consult ico go ahead processing conclude dpia record • additional measures plan take • whether risk eliminated reduced accepted • overall level ‘ residual risk ’ taking additional measures • opinion dpo one • whether need consult ico happens next although carry dpia processing personal begins consider ‘ live ’ document means reviewing dpia regularly undertaking reassessment appropriate eg nature scope context purpose processing risks posed individuals alter reason 19 version 1.0 auditing framework -draft guidance consultation instance depending deployment could demographics target population shift people adjust behaviour time response processing relevant provisions legislation articles 35 11 36 1 39 1 c recital 84 gdpr external link reading – ico guidance read guidance dpias guide gdpr including list processing operations likely result high risk dpias legally required read detailed guidance dpia including step described want read relevant sections guide • lawfulness fairness transparency • lawful basis processing • minimisation • accuracy reading – protection board protection boar edpb replaced article 29 working party wp29 includes representatives protection authorities member state adopts guidelines complying requirements gdpr wp29 produced guidelines protection impact assessments wp248 rev.01 en endorsed edpb relevant guidelines include • guidelines protection officers ‘ dpos ’ wp243 rev.01 • guidelines automated individual decision -making profiling wp251 rev.01 20 version 1.0 auditing framework -draft guidance consultation understand controller/processor relationships controllership important many cases various processing operations involved undertaken number different organisations therefore crucial determine controller joint controller processor involves multiple orga nisations first step understanding relationships identify distinct sets processing operations purposes ‘ assess dpia organisations work need assess whether controller processor joint controller consult guidance controller/processor assista nce assessment essence • decide purposes means processing controller • process personal instruction another organisation processor • jointly determine purposes means processing another organisation joint controllers usually involves processing personal several different phases possible controller joint controller phases processor others means processing decided controllers processors discretion decide non-essential details means possible generalise every context following examples show kinds decisions means -related processing indicate controller decisions non-essential details could taken processor type decisions make us controller type decisions likely make controller include deciding • collect personal first place • purpose processing • individuals collect tell processing • long retain • respond requests made line individuals ’ 21 version 1.0 auditing framework -draft guidance consultation specifics circumstances make controller read guidance controllers processors context type decisions made controllers include • source nature train model • target output model ie predicted classified • broad kinds ml algorithms create models eg regression models decision trees random forests neural networks • feature selection – features model • key model parameters eg complex decision tree many models included ensemble • key evaluation metrics loss functions trade -off false positives false negatives • models continuously tested updated often using kinds ongoing performance assessed whilst non -exhaustive list constitutes decisions purpose means make decisions likely controller another organisation jointly determine joint controllers decisions processors take conversely ’ make decisions process basis agreed terms likely processor processors different obligations depending terms contract controller able take certain decisions • methods process personal • store • security measures protect • retrieve transfer delete dispose context processors able decide depending terms contract • spe cific implementation generic ml algorithms programming language code libraries written • models stored formats serialised stored local caching 22 version 1.0 auditing framework -draft guidance consultation • measures optimise algorithms models minimise consumption computing resources eg implementing parallel processes • architectural details models deployed choice virtual machines microservices apis make kinds decisions processor rather controller practice means provide variety services without necessarily considered controller however key remember overarching decisions processed purposes taken controller providing tools stance might provide cloud- based service consisting dedicated cloud computing environment processing storage suite common tools ml services enable clients build run models chosen process using tools infrastructure provide cloud example clients likely controllers whilst processor could therefore decide processor programming languages code libraries tools written configuration storage solutions graphical user interface cloud architecture clients controllers long take overarching decisions models want key model parameters processes evaluating testing updating models clients ’ purposes decided become controller processing providing prediction service companies provide live prediction classification services customers instance might develop models allow customers send queries via api eg ‘ objects image ’ get responses eg classification objects image case prediction service provider likely controller least processing first processing necessary create improve models po wer services means purposes processing principally decided service provider likely controller processing second processing necessary make predictions classi fications particular examples behalf 23 version 1.0 auditing framework -draft guidan ce consultation clients kind processing client likely controller processor however even considered controller joint controller latter kind processing design services su ch way customers sufficient influence essential elements purposes processing involved prediction instance enable customers set balance false positives negatives according requirements add remove certain features model practice joint controller exerting sufficiently strong influence essential means processing furthermore initially process behalf client part providing service process clients improve models controller processing decided undertake purposes instance recruitment consultant might process job applicants ’ behalf clients using ml provides scores applicant retaining improve ml cases explicitly state purposes outset seek lawful basis section purposes lawful bases additionally protection legislation states tha anyone acting authority controller processor shall process personal except instructions controller unless required law need consider applies particular circumstances example processor permitted process instructions controller – processes personal due role processor processing still infringe gdpr even purposes fair compatible original controller needs agree disclose third -party controller ie sharing operation needs comply protection law relevant provisions legislation article 29 gdpr external link sections 60 106 dpa external link responsibilities procuring models local deployment companies sell provide free pre -trained models standalone pieces software customers install run order develop market robust organisations would purchase third parties likely processed personal form eg train however 24 version 1.0 auditing framework -draft guidance consulta tion integrate processing environment developer play part processing providers make decisions processing personal purposes training models sell controller processing however third party developers intend process personal da ta controllers behalf processors procured models deploy model provider process personal controller processing undertake using model provider services identify processing operations controller processor ensure clients procuring services different responsibilities part considerations selecting process personal • remember compliance protection law remains responsibility whether procure build • check developer des igned including whether line protection principles • result assess whether using service going help meet processing objectives well protection obligations controller writing contracts service level agreements need remember contract might stipulate status controller processor matters protection perspective practice decides purposes essential means processing similarly provider services identify processing operations controller processor ensure clients relevant provisions legislation articles 4 7 4 8 5 1 5 2 25 28 recital 78 gdpr external link reading – ico guidance read guidance controller/processor contracts/liabilities guide gdpr 25 version 1.0 auditing framework -draft guidance consultation resources court justice union ’ cjeu judgment case unabhängiges landeszentrum für datens chutz uld schleswig -holstein wirtschaftsakademie schleswig- holstein gmbh cjeu ’ judgment case fashion id gmbh co. kg verbraucherzentrale nrw ev -related trade -offs manage comply requirements protection law however number different values interests times pull different directions risk -based approach protection law help navigate potential ‘ trade -offs ’ privacy one hand competing values interest using therefore need iden tify assess interests strike appropriate balance given context whilst continuing meet obligations law balance particular trade -off depends specific sectoral social context operate impact individuals however methods assess mitigate trade -offs relevant many cases following sections provide short overview notable trade -offs likely face designing procuring privacy vs statistical accuracy fairness protection context generally means handle personal ways people would reasonably expect ways unjustified adverse effects improving ‘ statistical accuracy ’ ’ outputs one considerations ensure compliance fairness principle important note word ‘ accuracy ’ different meaning contexts protection accuracy protection one fundamental principles requiring ensure personal accurate necessary kept date accuracy generally statistical modelling refers often guesses correct answer – many cases answers personal ‘ accuracy principle ’ applies personal process need 100 ‘ statistically accurate ’ order comply principle however statistically accurate 26 version 1.0 auditing framework -draft guidance consultation likely processing line fairness principle clarity guidance • term ‘ accuracy ’ refer accuracy principle protection law • term ‘ statistical accuracy ’ refer accuracy differences ‘ protection ’ accuracy statistical accuracy section ‘ need statistical accuracy ’ general learns case ml models trained statistically accurate likely capture underlying statistically useful relationships features datasets example model predicting future purchases based customers ’ purchase history would tend statistically accurate customers includ ed training features added existing dataset relevant model trying predict instance purchase histories augmented additional demographic might improve statistical accuracy model however generally speaking points collected person people whose included set greater risks individuals reading – ico guidance read guidance minimisation guide gdpr statistical accuracy discrimination discussed ‘ address risks bias discrimination ’ section lead biased discriminatory outcomes turn pose compliance risks terms fairness princip le need implement appropriate technical measures mitigate risk considerations include impact techniques statistical accuracy ’ performance example reduce potential discrimination might modify credit risk model proportion positive predictions people different protected characteristics eg men women equalised help prevent discriminatory outcomes could resul higher number statistical errors overall need manage 27 version 1.0 auditing framework -draft guidance consultation practice always tension statistical accuracy avoiding discrimination example discriminatory outcomes model driven lack minority population statistical accuracy th e model could increased collecting whilst equalising proportions correct predictions however case would face different choice -between collecting minority population interests reducing disproportionate number statistical errors face collecting due risks posed freedoms individuals explainability statistical accuracy part fairness considerations include trade -off explainability statistical accuracy complex based deep hard follow logic therefore difficult adequately explain work sometimes characterised ‘ black problem ’ depending circumstances view complex statistically accurate effective especially comes problems like image recognition therefore think face trade -off explainability statistical accuracy however many applications simpler models perform well trade -offs explainability statistical accuracy actually relatively small issues considered greater depth explain project guidance general point ‘ black ’ models • thoroughly considered potential impacts risks advance members team determined case organisational capacities/resources support responsible design implementation • includes supplemental interpretability tools provide domain -appropriate level explainability explainability exposure personal commercial security providing individuals meaningful logic driven decision potentially increase risk inadvertently disclosing nee keep private – including personal proprietary logic –in process recent demonstrated proposed methods make ml models explainable unintentionally make easier infer personal individuals whose train model 28 version 1.0 auditing framework -draft guidance consultation sections ‘ model inversion attacks ’ ‘ membership inference attacks ’ highlights risk course providing explanation individuals accidentally reveal proprietary model works however take care conflate commercial interests protection requirements eg commercial security protection security nd instead consider extent trade -off genuinely exists stakeholder engagement far indicate risk quite low however theory least cases need consider individuals receive explanation example interests businesses maintain trade secrets noting protection compliance ‘ traded away ’ risks areas likelihood severity subject debate investigation continue monitor review risks update guidance accordingly manage trade- offs cases striking balance multiple trade -offs matter judgement specific case context meant deployed whatever choices make need accountable efforts proportional risks considering deploy poses individuals .. • identify assess existing potential trade -offs designing procuring assess impact individuals • consider available technical approaches minimise need trade -offs • consider techniques implement reasonable level investment effort • criteria lines accountability final trade -off decisions include robust risk -based independent approval process • appropriate take steps explain trade -offs individuals tasked reviewing outputs • review trade -offs regular basis taking account among things views individuals representatives emerging techniques best practices reduce 29 version 1.0 auditing framework -draft guidance consultation document processes outcomes auditable standard capture dpia appropriate level detail document • considered risks individuals personal processed • methodology identifying assessing trade -offs scope reasons adopting rejecting particular technical approaches relevant • prio ritisation criteria rationale final decision • final decision fits within overall risk appetite ready halt deployment possible achieve appropriate trade -off betw een two multiple protection requirements outsourcing third -party either buy solution third party outsource altogether need conduct independent evaluation trade -offs part due diligence process required specify requirements procurement stage rather addressing trade -offs ex post recital 78 gdpr says producers solutions encouraged • take account protection developing designing • make sure controllers processors able fulfil protection obligations ensure authority modify deployment either directly via third party provider consider appropriate trade -offs outset risks considerations arise instance vendor offer cv screening tool effectively scor es promising job candidates ostensibly require lot candidate order make assessment procuring need consider whether collecting much personal candida tes request provider modify seek another provider section minimisation 30 version 1.0 auditing framework -draft guidance consultation culture diversity engagement stakeholders need make significant judgement calls determining appropriate trade -offs effective risk management processes essential culture organisation plays fundamental role undertaking kind exercise require collaboration different teams within organisation diversity incentives work collaboratively well environment staff feel encouraged voice concerns propose alternative approaches important social acceptability different contexts best practices relation trade -offs subject ongoing societal debates consultation stakeholders outside organisation including affected trade -off help understand value place different criteria assessing trade- offs worked example many cases trade -offs precisely quantifiable lead arbitrary decisions perform contextual assessments documenting justifying assumptions value different requirements specific cases one possible approach help identi fy best possible trade -offs visually represent choices different designs graph plot possible choices could designed graph two criteria balanced – example statistical accuracy privacy – x axis statistical accuracy given precise measurement ways described section ‘ need statistical accuracy ’ privacy measures likely less exact indicative nature could include • amount personal required • sensitivity • extent might uniquely identify individual • nature scope context purpose processing • risks freedoms processing present individuals • number individuals applied graph reveal known ‘ production -possibility frontier ’ one way help decision makers understand design decisions impact balance different values 31 version 1.0 auditing framework -draft guidance consultation method figure 1 visualise trade -off privacy statistical accuracy might look like presented senior decision maker responsible approving choice particular help understand trade -offs figure 1 points graph represent different possible technical configurations resulting different design choices ml models amount types point represents possible end result particular trade -off statistical accuracy privacy scenario figure 1 proposed achieve high statistical accuracy high privacy trade -off privacy statistical accuracy significant different case trade -offs look different visualised figure 2 32 version 1.0 auditing framework -draft guidance consultation figure 2 scenario easier achieve reasonable trade -off statistical accuracy privacy graph shows cost sacrificing either privacy statistical accuracy lower middle curve c edge b example diminishing returns statistical accuracy possible intend choose b would placing higher value statistical accuracy warranted circumstances need take account impact freedoms individuals able demonstrate processing still fair proportionate overall visual representati trade -offs include lower limits either variable willing go figure 3 33 version 1.0 auditing framework -draft guidance consultation figure 3 scenario figure 3 possible meets lower limits statistical accuracy privacy suggesting pursue deployment mean looking methods dat sources reformulating problem abandoning attempt solve problem mathematical approaches minimise trade -offs cases precisely quantify elements trade -offs number mathematical co mputer science techniques known ‘ constrained optimisation ’ aim find optimal solutions minimising trade -offs technical specialist ml engineer assess viability techniques particular context instance theory differential privacy provides framework quantifying minimising trade -offs knowledge gained dataset statistical model privacy people similarly various methods exist create ml models optimise statistical accuracy minimising mathematically defined measures discrimination 34 version 1.0 auditing framework -draft guidance consultation approaches provide theoretical guarantees hard meaningfully put practice many cases values like privacy fairness difficult meaningfully quantify example differential privacy able measure likelihood individual uniquely identified particular dataset sensitivity identification therefore always supplement methods qualitative holistic approach inability preci sely quantify values stake mean avoid assessing justifying trade -off altogether still need choices example controls risk statement inadequate inappropriate trade -off analysis decisions lea incorrectly prioritise one criterion another important criteria preventative • clearly document purpose model important criteria model specification • ensure specification signed ppropriate management • senior management review various models trade -off analysis approve particular model • systematically review trade -off options provide justification specific model selected • ensure reviews completed action taken result • complete training ensure designers date latest techniques detective • periodic review trade -off given available since date deployment • periodically re- analyse trade-offs corrective • select appropriate model include thorough justification change • retrain developers 35 version 1.0 auditing framework -draft guidance consultation need ensure lawfulness fairness transparency glance process personal ensure lawful fair transparent compliance principle challenging context process personal various stages variety purposes risk fail appropriately distinguish distinct processing operation identify appropriate lawful basi could lead failure comply protection principle lawfulness section presents considerations help find appropriate lawful basis various kinds personal processing involved creatin g using ensure processing fair detail • principles lawfulness fairness transparency apply • identify purposes lawful basis using • need statistical accuracy • address risks bias discrimination principle lawfulness fairness transparency apply first deployment involve processing personal different ways different purposes identify purposes appropriate lawful basis order comply w ith principle lawfulness second infer people order processing fair need ensure • sufficiently statistically accurate avoids discrimination • consider impact individuals ’ reasonable expectations 36 version 1.0 auditing framework -draft guidance consu ltation finally need transparent process personal comply principle transparency core issues regarding transparency principle addressed explain guidance discussed n detail identify purposes lawful basis using consider deciding lawful bases whenever processing personal – whether train make predictions using existing one – appropriate lawful basis different lawful bases apply depending particular circumstances however lawful bases likely appropriate training deployment others sa time remember • responsibility decide lawful basis applies processing • always choose lawful basis closely reflects true nature relationship individual purpose processing • make determination start processing • document decision • swap lawful bases later date without good reason • include lawful basis privacy notice along purposes • processing special categories need lawful basis additional condition processing reading – ico guidance read guidance lawful basis processing guide gdpr distinguish p urposes deployment many cases determining purpose lawful basis make sense separate training deployment distinct separate purposes different circumstances risks therefore consider whether different lawful bases apply deployment example need 37 version 1.0 auditing framework -draft guidance consu ltation • trained general -purpose task deploy different contexts different purposes instance facial recognition could trained recognise faces functionality could multiple purposes preventing crime authentication tagging friends social network applications might require different lawful basis • cases implement third party processing personal undertaken developer different purpose th intend therefore need identify different lawful basis • processing personal purposes training model directly affect individuals model deployed aut omatically make decisions legal significant effects means provisions automated decision making apply result different range available lawful bases apply training deployment stages following sections -related considerations gdpr ’ lawful bases consider part 3 dpa stage rely consent consent appropriate lawful basis cases direct relationship individuals whose want process training deploying model however ensure consent freely given specific informed unambiguous involves affirmative act part individuals advan tage consent lead trust buy -in individuals using service providing individuals control factor dpias however consent apply individuals genuine choice abo ut whether implications depending intend – difficult ensure collect valid consent complicated processing operations example things want difficult ensure consent genuinely specific informed key individuals understand using personal consented instance want collect wide range features explore different models predict variety outcomes consent appropriate lawful basis provided inform individuals activities obtain valid consent 38 version 1.0 auditing framework -draft guidance consultation consent appropriate lawful basis individual ’ deployment eg purposes personalising service making prediction recommendation however aware consent valid individuals able withdraw consent easily gave relying consent basis processing wi th deployment eg drive personalised ready accommodate withdrawal consent processing relevant provisions gdpr articles 4 11 6 1 7 8 9 2 recitals 32 38 40 42 43 171 external link reading – ico guidance read guid ance consent guide gdpr reading -european protection b oard protection board edpb replaced article 29 working party wp29 includes representatives protection authorities member state adopts guidelines complying requirements gdpr wp29 adopted guidelines consent edpb endorsed . rely performance contract lawful basis applies processi ng using objectively necessary deliver contractual service relevant individual take steps prior entering contract individual ’ request eg provide -derived quote service less intrusive way processing provide service processing practice objectively necessary performance contract rely lawful basis processing furthermore even appropriate ground appropriate ground processing personal train perform well enough without trained individual ’ personal performance f contract depend processing 39 version 1.0 auditing framework -draft guidance consultation similarly even performance contract lawful basis processing personal provide quote prior contract mean using train note unlikely able rely basis processing personal purposes ‘ service improvement ’ cases collection personal service details users engage service functions within hat service objectively necessary provision contract service delivered without processing conversely process personal purposes personalising regarded necessa ry performance contract – cases whether processing regarded ‘ intrinsic ’ service depends • nature service • expectations individuals • whether provide service without processing ie personalisation means integral service consider alternative lawful basis relevant provisions legislation article 6 1 b recital 44 gdpr external link reading – ico guidance read guidance contracts guide gdpr rea ding – protection board protection board edpb replaced article 29 working party wp29 includes representatives protection authorities member state adopts guidelines complyi ng requirements gdpr edpb published guidelines 2/ processing personal article 6 1 b context online services 40 version 1.0 auditing framework -draft guidance consultation rely legal obligation task vital interests examples process personal legal obligation purposes detecting anti -money laundering part 7 proceeds crime act similarly organis ation uses part exercise official authority perform task interest set law necessary processing personal involved based grounds limited number cases processing p ersonal might based protecting vital interests individuals example emergency medical diagnosis patients otherwise incapable providing consent eg processing fmri scan unconscious patien diagnostic however unlikely vital interests could provide basis training would rarely directly immediately result protecting vital interests individuals even mo dels eventually built might later save lives training potentially life -saving would better rely lawful bases relevant provisions legislation article 6 1 c recitals 41 45 gdpr provisions using legal obligation external link article 6 1 e 6 3 recitals 41 45 50 gdpr provisions using interests article 6 1 article 9 2 c recital 46 gdpr provisions using vital interests external link sections 7 8 schedule 1 paras 6 7 protection act external link reading – ico guidance read guidance legal obligation vital interests task guide gdpr rely legitimate interests depending circumstances could base processing personal training ongoing legitimate interests lawful basis 41 version 1.0 auditing framework -draft guidance consultation important note legitimate interests flexible lawful basis processing always appropriate example way intend people ’ would unexpected cause unnecessary harm means taking additional responsibility considering protecting people ’ interests additionally authority rely legitimate interests processing legitimate reason performing tasks authority three elements legitimate interests lawful basis help think ‘ three -part test ’ need • identify legitimate interest ‘ pur pose test ’ • show processing necessary achieve ‘ necessity test ’ • balance individual ’ interests freedoms ‘ balancing test ’ wide range interests constitute ‘ legitimate inter ests ’ protection law third parties well commercial societal interests however key understanding legitimate interests flexible comes additional responsibilities requires assess impact processing individuals able demonstrate compelling benefit processing address document considerations part legitimate interests assessment li example organisation seeks rely legitimate interests processing personal purposes training machine model legitimate interests allow organisation room experiment different variables model however part legitimate interests assessment organisation demonstrate range variables models intends reasonable approach achieving outcome best achieve properly defining purposes justifying type collected – allow organisation work necessity balancing aspects lia example mere p ossibility might useful prediction sufficient organisation demonstrate processing necessary building model 42 version 1.0 auditing framework -draft guidance consultation relevant provisions legislation gdpr article 6 1 f recitals 47 -49 external link reading – ico guidance read guidance legitimate interests guide gdpr published lawful basis assessment tool help decide basis appropriate well legitimate interests template word special category criminal offences intend proces special category criminal offences need ensure comply requirements articles 9 10 gdpr well dpa . special category personal needs protection sensitive order process need lawful basis article 6 well separate condition article 9 although linked number conditions require meet additional requirements safeguards set schedule 1 dpa . • determine document condition processing start • ensure appropriate policy document place required • complete dpia processing likely high risk criminal offences need lawful basis article 6 gdpr either lawful official authority article 10. dpa sets specific conditions provide lawful authority process type official authority ie processing official capacity special category determine condition processing identify official authority start document 43 version 1.0 auditing framework -draft guidance consultation relevant provisions legislation articles 9 10 gdpr external link reading – ico guida nce read guidance special category criminal offence guide gdpr impact article 22 gdpr protection law applies automated individual decision making profiling article 22 gdpr additional rules protect individuals carrying solely automated decision- making legal similarly significant effects application context eg using make kinds decisions however carry type decision- making decision • necessary entry performance contract • authorised law applies • based individual ’ explicit consent therefore identify processing falls article 22 make sure • give individuals informatio n processing • introduce simple ways request intervention challenge decision • carry regular checks make sure working intended reading – ico guidance read guidance related automated decision maki ng including profiling guide gdpr 44 version 1.0 auditing framework -draft guidan ce consultation example controls risk statement reliance inappropriate lawful basis processing results potential failure fulfil necessary requirements non -compliance dp legislation preventative • ensure developers completed training associated competency assessments • document training key stakeholders relevant personnel identified eg senior management risk managers audit • thoroughly assess lawful basis processing dpia • consult dp specialists within model design workforce • ensure requirement dpia documented developers provided guidance assessment criteria • complete legitimate interests assessment reliance legitimate interests lawful basis detective • monitor individual requests complaints indiv iduals including action taken result individual level boarder analysis • conduct periodic dpia review ensure remains accurate date • periodically assess model usage ensure purpose remains necessit legitimate interests li still valid • conduct periodic review records processing ensure validity lawful basis corrective • implement corrective measures order satisfy original lawful basis • select lawful basis associated actions example carrying legitimate interests assessment obtaining consent • retrain developers individuals involved assessment lawful bases 45 version 1.0 auditing framework -draft guidance consultation need statistical accuracy statistical accuracy refers proportion answers gets correct incorrect section explains controls implement ensure sufficiently statistically accurate ensure personal process complies fairness principle difference ‘ accuracy ’ protection law nd ‘ statistical accuracy ’ said section ‘ trade -offs manage ’ accuracy slightly different meanings protection contexts protection accuracy one fundamental principles requires take reasonable steps make sure personal process ‘ incorrect misleading matter fact ’ necessary corrected deleted without undue delay accuracy refers often sys tem guesses correct answer many contexts answers provides personal instance might infer someone ’ demographic interests behaviour social network protectio n ’ accuracy principle applies personal whether individual input output however mean needs 100 statistically accurate order comply accuracy principle many cases outputs intended treated factual individual instead intended represent statistically informed guess something b e true individual future order avoid personal misinterpreted factual ensure records indicate statistically informed guesses rather facts records clude provenance generate inference record becomes inference based inaccurate generate statistically flawed way affected quality inference similarly processing incorrect inference impact individual request inclusion additional record countering incorrect infe rence helps ensure decisions taken basis potentially incorrect inference informed evidence wrong 46 version 1.0 auditing framework -draft guidance consultation gdpr mentions statistical accuracy context profiling automated decision making recital 71. states organisations put place ‘ appropriate mathematical statistical procedures ’ profiling individuals part technical measures ensure factors result inaccuracies personal corrected risk errors minimised make inferences people need ensur e sufficiently statistically accurate purposes mean every inference correct need factor possibility incorrect impact decisions take basis failure could mean processing compliant fairness principle impact compliance minimisation principle personal – including inferences – adequate relevant purpose therefore needs sufficiently statistically accurate ensure personal generated processed lawfully fairly however overall statistical accuracy particularly useful measure usually needs broken different measures important measure prioritise ones next section relevant provisions legislation gdpr articles 5 1 22 recital 71 external link reading – ico guidance read guidance accuracy guide gdpr well guidance rectification erasure reading – protection board protection board edpb replaced article 29 working party wp29 includes representatives protection authorities member state adopts guidelines complying requirements gdpr wp29 published guidelines automated decision making profiling . edpb endorse guidelines 47 version 1.0 auditing framework -draft guidance consultation define prioritise different statistical accuracy measures statistical accuracy general measure closely ’ predictions match correct labels defined test example classify emails spam spam simple measure statistical accuracy number emails correctly classified spam spam proportion emails analysed however measure could misleading instance 90 emails received inbox spam could create 90 ccurate classifier simply labelling everything spam would defeat purpose classifier genuine email would get reason alternative measures assess good measures shoul reflect balance two different kinds errors • false positive ‘ type ’ error cases incorrectly labels positive eg emails classified spam genuine • false negative ‘ type ii ’ error cases incorrectly labels negative actually positive eg emails classified genuine actually spam important strike balance two types errors mor e useful measures reflect two types errors including • precision percentage cases identified positive fact positive called ‘ positive predictive value ’ instance nine 10 emails classified spam actually spam precision 90 • recall sensitivity percentage cases fact positive identified instance 10 100 emails actually spam identifies seven recall 70 trade -offs precision recall assessed using measures ‘ f -1 ’ statistic -see link place importance finding many positive cases possible maximising recall come cost false positives lowering precision addition important differences consequences false positives false negatives individuals 48 version 1.0 auditing framework -draft guidance consultation example cv filtering selecting qualified candidates interview produces false positive unqualified candidate invited interview wasting employer applicant ’ time unnecessarily produces false negative qualified candidate miss employment opportunity organisation miss good candidate prioritise avoiding certain kinds error based severity nature risks general statistical accuracy measure depends possible compare performance ’ outputs ‘ ground truth ’ ie checking results real world instance medical diagnostic tool designed detect malignant tumours could evaluated high quality test containing known patient outcomes areas ground truth unattainable could high -quality test exists trying predict classify subjective eg whether social media post offensive risk statistica l accuracy misconstrued situations seen highly statistically accurate even though reflecting average set labellers thought rather objective truth avoid record indicate outputs intended reflect objective facts decisions taken basis personal reflect limitations example take account accuracy principle – guidance accuracy principle refers accuracy opinions finally statistical accuracy measure usually measured test real life situations applie changing populations statistically accurate existing population ’ eg customers last year continue perform well change characteristics population population applied future behaviours change either accord adapting response become less statistically accurate time phenomenon ref erred machine ‘ concept model drift ’ various methods exist detecting instance measure distance classification errors time increasingly frequent errors suggest drift regularly assess drift retrain model necessary part accountability decide document 49 version 1.0 auditing framework -draft guidance consultation appropriate thresholds determining whether model needs retrained based nature scope context purposes processing risks poses example model scoring cvs part recruitment exercise kinds skills candidates need particular job likely change every two years anticipate assessing need re- train fresh least often application domains main features ’ change often eg recognising handwritten digits anticipate less drift need assess based circumstances reading – ico guidance guidance accuracy principle guide gdpr resources ‘ define prioritise different statistical accuracy measures ’ ‘ concept drift overview ’ explanation concept drift always think carefully start whether appropriate automate prediction decision- making process include assessing effectiveness making statistically accurate predictions individuals whose personal processes assess merits using particular light consideration effectiveness making accurate therefore valuable predictions demonstrate sufficient level statistical accuracy decide adopt comply protection principles • ensure functions individuals responsible testing validation deployment monitoring adequately trained understand associated statistical accuracy requirements measures • make sure clearly labelled inferences predictions claimed factual • ensure managed trade -offs nd reasonable expectations 50 version 1.0 auditing framework -draft guidance consultation • adopt common terminology staff discuss statistical accuracy performance measures including limitations adverse impact individuals else part obligation implement protection design default consider statistical accuracy appropriate measures evaluate design phase test measures throughout lifecycle deployment implement monitoring frequency proportional impact incorrect output individuals higher impact frequently monitor report review statistical accuracy measures regularly mitigate risk concept drift change policy procedures take account outset statistical accuracy important consideration outsource third party either fully partially purchase solution external vendor cases examine test claims made third parties part procurement process similarly agree regular updates reviews statistical accuracy guard changing population concept model drift provider services ensure designed way allow organisations fulfil protection obligations finally vast quantity personal hold process part likely put pressure pre -existing non-ai processes identify necessary rectify/delete inaccurate personal whether input training/test therefore need rev iew governance practices ensure remain fit purpose example controls risk statement inaccurate output decisions made could lead unfair negative outcomes individuals failure meet fairness principle preventative • put place governance framework describes personal ongoing training testing evaluation service correct accurate relevant representative complete up-to-date possible 51 version 1.0 auditing framework -draft guidance consultation • provide training key stakeholders document relevant personnel identified eg senior management risk managers audit • document access management controls segregation duties deployment ensure changes affecting statistical accuracy made signed authorised persons maintain evidence controls monitored • document levels approval authority development/use maintain evi dence appropriate approval • dpia include thorough assessment impact/importance different errors • maintain documented policies processes dealing third parties evidence due diligence completed particular procuring services ensure meet statistical accuracy requirements allow regular re-testing • maintain document policy process performing pre implementation testing changes prior go -live maintain ev idence testing completed prior deployment results test detective • post -implementation testing document results testing action taken result • monitor output reports/performa nce expectations • conduct review sample decisions statistical accuracy including sample selected criteria • document individual requests complaints regarding statistically inaccurate outputs individuals particular relating article 22 including action taken result individual level broader analysis • ensure continuous oversight third -party suppliers/processors including regularl reviewing performance expectations adherence contractual requirements • test set confirm outcome reached corrective • retrain eg improving input different balance false p ositives negatives using different algorithm • retrain developers relation discriminatory model performance • change decision made assess whether individuals could impacted inaccu racy 52 version 1.0 auditing fr amework draft guidance consultation ddress risk bias discrimination learn unbalanced and/o r reflect discrimination produce output discriminatory effects people based gender race age health religion disability sexual orientation r characteristics fact learn guarant ee outputs lead discriminatory effects trai n test w ell w ay designed ight lead treat certain groups less favourably protectio n law ntended balance righ protection personal function society processing personal leads discrimination bias impact fairne ss processing poses compliance issues fairness principle wel l risks individuals ’ freedoms – including non-d iscrimination furthermore gdpr specificall notes organisations hould take measure prevent ‘ discriminatory effect natural persons ’ additionally uk ’ ant i-discrimination legal framework notably uk equality act sits longside protection law app lies range organisations thi include government departments service providers employers education providers transport providers association membership bodies well providers publi c functions gives individuals protection fr om discrimination whether generated automate decision- making combination two section w e explor e means practice context focusing machine ml cl assify r make prediction abo ut individuals ay lead discrimination explore f technical nd organisational measures hat yo u ado pt manage r isk ight n lead discrimination let ’ take hypothetical scenario example bank develops calculate credit risk potential customers bank approve reject loan applications trained large dataset containing range previous borrowers occupation income age whether repaid loan testing bank wants check possible gender bias finds tends give women lower credit scores 53 version 1.0 auditing framework -draft guidance consultation two main reasons might one imbalanced training proportion different genders training balanced example training include greater proportion male borrowers past fewer women applied loans therefore bank ’ enough women algorithm generate statistical model designed best fit trained tested men -represented training model pay attention statistical relationships predict repayment rates men less statistical patterns predict repayment rates women might different put another way statistically ‘ less important ’ model systematically predict lower loan repayment rates women even women training dataset average likely repay loans men issues apply population under- represented training example facial recognition model trained disproportionate number faces belonging particular ethnicity gender eg white men perform better recognising individuals group worse others another reason training reflect past discrimination instance past loan applications wome n rejected frequently men due prejudice model based training likely reproduce pattern discrimination certain domains discrimination historically significant problem likely experience problem acutely police stop -and-search young black men recruitment traditionally male roles issues occur even training contain protected characteristics like gender race variety features training often closely correlated protected characteristics eg occupation ‘ proxy variables ’ enable model reproduce patterns discrimination associated characteristics ev en designers intend problems occur statistical model however likely occur include greater number features identify complex combinations features proxies protected characteristics many modern ml methods powerful traditional statistical approaches better 54 version 1.0 auditing framework -draft guidance consultation uncovering non -linear patterns high dimensional however include patterns reflect discrimination technical approaches mitigate discrimination risk ml models discrimination b roader problem realistically ‘ ’ various approaches mitigate -driven discrimination computer scientists others developing different mathematical techniques measure ml models treat individuals different groups potentially discriminatory ways field often referred algorithmic ‘ fairness ’ many techniques early stages market- ready basic approac hes developers take measure mitigate potential discrimination resulting cases imbalanced training possible balance adding removing under/overrepresented subsets population eg adding points loan applications women alternatively could train separate models example one men another women design perform well possible sub-group however cases creating different models different protected classes could violation non -discrimination law eg different car insurance premiums men women cases training reflects past discrimination could either modify change process modify model training order techniques effective need choose one mathematical ‘ fairness ’ measures measure results measur es grouped three broad categories • anti-classification • outcome error parity • equal calibration anti-classification model fair excludes protected characteristics making classification prediction anti classification approaches try identify exclude proxies protected characteristics eg attendance single -sex school impractical removing possible proxies leave predictively useful features ften hard know whether particular variable combination variables proxy protected characteristic without collection analysis 55 version 1.0 auditing framework -draft guidance consultation outcome error parity compares members different protected groups treated model outcome parity model fair gives equal numbers positive negative outcomes different groups error parity model fair gives equal numbers errors different groups error parity broken parity false positives false negatives section 2.3 statistical accuracy details equal calibration – calibration measures closely model ’ estimation likelihood something happening matches actual frequency event happening according ‘ equal calibration ’ model fair equally calibrated members different pro tected groups instance classification model sorts loan applicants low medium high chance repayment equal proportions male female applicants actually repay within risk category ’ mean equal proportions men women across different risk categories instance women actually higher repayment rates men women men low risk category unfortunately different measures often incompatible therefore need consider conflicts carefully selecting particular approach es example • equal calibration incompatible outcome error parity except rare cases actual distribution outcomes equal different protected groups • attempting achieve outcome parity removing protected characteristics required anti -classification measures result algorithm finding using irrelevant proxies order create model equalises outcomes unfair process special category assess address discrimination techniques discussed require access dataset containing personal representative sample population person represented need labels protected characteristics interest outlined equality act . cou ld dataset containing protected characteristics test performs protected group potentially -train model performs fairly kind analysis need ensure appropriate lawful basis process purposes different protection considerations depending kinds discrimination testing testing discriminatory impact age sex gender special protection conditions processing protected characteristics 56 version 1.0 auditing framework -draft guidance consultation classifi ed ‘ special category ’ protection law still need consider • broader questions lawfulness fairness risks processing poses whole • possibility either special category anyway becoming processing ie processing involves analysing inferring health genetic status note dealing personal results specific technical processing physical physiological behavioural characteristics individual allows confirms individual ’ unique identificat ion biometric biometric purpose uniquely identifying individual special category uses biometric testing mitigating discrimination pur pose confirming identity individuals within dataset making kind decision relation biometric come article 9. still regarded biometric gdpr special category similarly personal allow confirm individual ’ unique identification biometric special category however protected characteristics outlined equality act classified special category include race religion belief sexual orientation include disability pregnancy gender reassignment far reveal person ’ health similarly civil partnerships recently available -sex couples indicates someone civil partnership indirectly reveal sexual orientation testing discriminatory impact basis characteri stics likely need process special category order lawfully addition lawful basis article 6 need meet one conditions article 9 gdpr require additional basis authorisation uk law found schedule 1 dpa . conditions processing special category appropriate depends individual circumstances example using special category ssess discrimination identify promote maintain equality opportunity organisation using cv scoring assist recruitment decisions needs test whether discriminating religious philosophical belie fs 57 version 1.0 auditing framewor k -draft guidance consultation collects religious beliefs sample job applicants order assess whether indeed producing disproportionately negative outcomes erroneous predictions organisation relies substantial interest condition article 9 2 g equality opportunity treatment condition schedule 1 8 dpa 20 18. provision identify keep review existence absence equality opportunity treatment certain protected groups view enabling equality promoted maintained example using special category assess discrimination purposes university researcher investigating whether facial recognition available market perform differently faces people different racial ethnic origin part project order researcher assigns racial labels existing dataset faces tested thereby processing special category dat a. rely archiving statistics condition article 9 2 j read schedule 1 paragraph 4 dpa . finally protected characteristics using assess improve potentially discriminatory origin ally processed different purpose consider • whether purpose compatible original purpose • obtain fresh consent required example initially collected basis consent even purpose compatible still need collect fresh consent purpose • purpose incompatible ask consent relevant provisions legislation article 9 recitals 51 56 gdpr external link schedule 1 dpa exte rnal link reading – ico guidance read guidance purpose limitation special category guide gdpr 58 version 1.0 auditing framework -draft guidance con sultation special category discrimination automated decision -making using special category assess potential discriminatory impacts usually constitute automated decision- making protection law involve directly making decisions individuals similarly -training discriminatory model diverse population order reduce discriminatory effects involve directly making decisions individuals therefore classed decision legal similarly significant effect however cases simply -training model diverse training set enough sufficiently mitigate discriminatory impact rather trying make model fair ignoring protected characteristics making prediction approaches directly include characteristics making classification order ensure members potentially disadvantaged groups protected instance using sort job applicants rather attempting create model ignores pers ’ disability effective include disability status order ensure discriminate including disability status input automated decision could mean likely discriminate people disability factor effect condition features make prediction approach amounts making decisions individuals solely automated way significant effects using special category prohibited gdpr unless explicit consent individual meet one substantial interest conditions laid schedule 1 dpa need carefully assess whi ch conditions schedule 1 apply example equality opportunity monitoring provision mentioned relied contexts processing carried purposes decisions particular individual therefore approaches lawful based different substantial interest condition schedule 1. accidentally infer special category many contexts non -protected characteris tics postcode live proxies protected characteristic like race recent advances machine ‘ deep ’ made even easier detect patterns world reflected seemi ngly unrelated unfortunately includes detecting patterns discrimination using complex combinations features might correlated protected characteristics non -obvious ways 59 version 1.0 auditing framework -draft guidance consultation instance score job applications assist decision maker recruitment decisions might trained examples previously successful candidates contained application include protected characteristics like race disability mental health however examples employees train model discriminated grounds eg systematically rated performance reviews algorithm learn reproduce discrimination inferring characteristics proxy contained job application despite designer never intending eve n ’ protected characteristics model possible inadvertently model detected patterns discrimination based protected characteristics reproducing outputs described protected characteristics special category special category defined personal ‘ reveals concerns ’ special categories model learns particular combinations features ufficiently revealing special category model processing special category stated guidance special category profiling intention inferring special category special catego ry irrespective whether inferences incorrect furthermore reasons stated situations model infers special category intermediate step another non-special -category inference able tell model looking went model outputs produces high accuracy even though intend using machine personal proactively assess chances model might inferring protected characteristics and/or special category order make predictions actively monitor possibility throughout lifecycle potentially inferred characteristics special category ensure appropriate article 9 condition processing noted model make legal similarly significant decisions solely automated way lawful person ’ consent meet substantial interest condition appropriate provision schedule 1 reading – ico guidance read guidance special category 60 version 1.0 auditing framework -draft guidance consultation mitigate risks appropriate approach managing risk discriminatory outcomes ml depend particular domain context operating determine document approach bias discrimination mitigation beginning application lifecycle take account put place appropriate safeguards technical measures design build phase establishing policies good practices procurement lawful processing high -quality training test important especially enough internally whether procured internally externally satisfy representative population apply ml although reasons stated sufficient ensure fairness example high street bank operating uk training could compared recent census senior management responsible signing -off chosen approach manage discrimination risk accountable compliance protection law able leverage expertise leads internal external subject matter experts accountable senior leaders still need sufficient understanding limitations advantages different approaches true dpos senior staff oversight functions expected provide ongoing advice guidance appropriateness measures safeguards put place mitigate discrimination risk many cases choosing betwe en different risk management approaches requires trade- offs section ‘ -related trade-offs manage ’ includes choosing safeguards different protected characteristics groups need document approach choose trade- offs driven technical approaches always obvious non technical staff scientists highlight explain proacti vely business owners well staff responsibility risk management protection compliance technical leads proactive seeking domain -specific knowledge including known proxies protected characteristics inform algorithmic ‘ fairness ’ approaches undertake robust testing anti -discrimination measures monitor ml ’ performance ongoing basis risk management policies clearly set process person responsible final validation ml deployment appropriate update 61 version 1.0 auditing framework -draft guidance consultation discrimination monitoring purposes organisational policies set variance tolerances selected key performance metrics well escalation variance investigation procedures clearly set variance limits ml stop replacing traditional decision -making consider running concurrently period time investigate significant difference type de cisions eg loan acceptance rejection different protected groups two differences predicted perform practice beyond requirements protection law diverse workforce powerful tool identifying managing bias discrimination organisation generally finally area best practice technical approaches continue develop invest time res ources ensure continue follow best practice staff remain appropriately trained ongoing basis cases actually provide opportunity uncover address existing discrimination traditional decision -making proce sses allow address underlying discriminatory practices resources equality act external link charter fundamental external link example controls risk statement discriminatory output decisions made could lead statistically inaccurate /unfair decisions individuals certain groups preventative • put place governance framework describes personal ongoing training testing evaluation correct accura te relevant representative complete -todate possible • ensure developers completed training associated competency assessments identify address bias discrimination • provide training key stakeholders document relevant personnel identified eg senior management risk managers audit 62 version 1.0 auditing framework -draft guidance consultation • document access management controls segregation duties deployment ensure changes affecting statistical accuracy made signed authorised persons maintain evidence controls monitored • document levels approval authority development/use maintain evidence appropriate approval • dpia include thorough assessment risk f discrimination mitigants controls place prevent • maintain documented policies processes dealing third parties evidence due diligence completed • maintain documented process cross- section peer review design maintain evidence review completed • maintain documented policy process performing pre implementation testing changes prior go -live maintain evidence testing completed results test • document levels approval attestation diversity representation training test prior within maintain evidence appropriate approval detective • regularly monitor algorithmic fairness using appropriate measures • document levels approval attestation diversity representation training test prior within maintain evidence appropriate approval • regularly review model performance recent corrective • add remove overrepresented groups including thorough analysis justification • retrain model fairness constraints • retrain model designers relation discriminatory model performance 63 version 1.0 auditing framework -draft guidance consultation assess security minimisation glance exacerbate known security risks make difficult manage present challenges compliance minimisation principle exacerbate known security risks make difficult manage two secu rity risks increase • potential loss misuse large amounts personal often required train • potential software vulnerabilities introduced result introduction -relate code infrastructure default standard practices developing deploying involve processing large amounts risk fails comply minimisation principle number techniques exist enable minimisation effective deployment detail • security risks introduce • types privacy attacks apply models • steps take manage risks privacy attacks models • minimisation privacy -preserving techniques available security risks introduce process personal manner ensures appropriate levels security unauthorised unlawful processing accidental loss destruction damage section way adversely affect security making known risks worse challenging control security requirements “ one -size-fits-all ” approach security appropriate security measures adopt depend level type risks arise specific processing activities 64 version 1.0 auditing framework -draft guidance consultation using process personal important implications security risk profile need assess manage carefully implications triggered introduction types risks eg adversarial attacks machine models section x reading – ico guidance read guidance security guide gdpr ico/ncsc security outcomes general security protection law security key component auditing framework central work regulator ico planning expand general security guidance take account additional requirements set gdpr guidance ai- specific cover range topics relevant organisations using including software supply chain security increasing open-source software ’ different security compared ‘ traditional ’ technologies unique characteristics mean compliance protection law ’ security requirements challenging established technologies technological perspective technological perspective introduce kinds complexity found traditional using depending circumstances likely rely heavily third party code and/or relationships suppliers existing need integrated several existing components intricately connected complexity make difficult identify manage security risks increase others risk outages perspective people involved building deploying likely wider range backgrounds usual including traditional software engineering administration scientists statisticians well domain experts security practices expectations vary significantly less understanding broader security compliance requirements well protection law specifically security personal always key priority especially someone previously building applications non -personal capacity 65 version 1.0 auditing framework -draft guidance consultation complications arise common practices process personal securely science engineering still part compliance security principle ensure actively monitor take account state -ofthe-art security practices using personal context possible list known security risks might exacerbated process personal impact security depends • way built deployed • complexity organisation deployin g • strength maturity existing risk management capabilities • nature scope context purposes processing personal risks posed individuals result following hypothetical scenar ios intended raise awareness known security risks challenges exacerbate key message review risk management practices ensuring personal secure context case study losing track training ml require large sets training testing copied imported original context processing shared stored variety formats places including third parties make difficult keep track manage example organisation decides offered third -party recruiter part hiring process effective organisation needs share imilar previous hiring decisions eg sales manager recruiter previously organisation entirely manual cv scanning process led sharing personal eg candidates ’ cvs involve transfer large q uantities personal organisation recruiter organisation ensure appropriate lawful basis processing beyond sharing additional could involve creating multiple copies different formats stored different locations require important security governance considerations 66 version 1.0 auditing framework -draft guidance consultation • organisation need copy hr recruitment separate database examine select relevant vacancies recruitment firm working • selected subsets need saved exported files transferred recruiter compressed form • upon receipt recruiter could upload files remote location eg cloud • cloud files loaded programming environment cleaned building • ready likely saved file later time • organisation recruiter time copied stored different places increased risk personal breach including unauthorised processing loss destruction damage example copies training need shared managed necessary deleted line security policies many recruitment firms already governance security policies place longer fit -for-purpose adopted reviewed necessary updated circumstance technical teams record document movements storing personal one location another help apply appropriate security risk controls monitor effectiveness audit trails necessary satisfy accountability documentation requirements addition delete intermediate files containing personal soon longer required eg compressed versions files created transfer depending likelihood severity risk individuals need apply de -identification techniq ues training extracted source shared internally externally example need remove certain features apply privacy enhancing technologies pets sharing another organisation case study security risks introduced externally maintained software build organisations build entirely in- house cases design building running provided least part third parties organisation always contractual relationship 67 version 1.0 auditing framework -draft guidance consultation even hire ml engineers still rely significantly third-party frameworks code libraries many popular ml frameworks open source using third- party open source code valid option developing software components scratch requires large investment time resources many organisations afford especially compared open source tools would n ot benefit rich ecosystem contributors services built around existing frameworks however one important drawback standard ml frameworks often depend pieces software already installed give sense risks involved recent study found popular ml frameworks include 887,000 lines code rely 137 external dependencies therefore implementing require changes organisation ’ software stack possibly hardware introduce additional security risks example recruiter hires ml engineer build automated cv filtering using python- based ml framework ml framework depends number specialist open- source programming libraries needed downloaded recruiter ’ one libraries contains software function convert raw training format required train ml model later discovered function security vulnerability due unsafe default configuration attacker introduced executed malicious code remotely disguising training far -fetched example vulnerability discovered ‘ numpy ’ popular library python programming language many machine develo pers circumstance whether built house externally combination need assess security risks well ensuring security code developed in- house need assess security externally maintained code frameworks many respects standard requirements maintaining code managing security risks apply applications example • external code security measures inclu de subscribing security advisories notified vulnerabilities • internal code security measures include adhering coding standards instituting source code review processes 68 version 1.0 auditing framework -draft guidance consultation whatever approach need ensure staff appropriate skills knowledge address security risks additionally develop ml mitigate security risks associated third party code separating ml environment rest infrastructure possible two ways achieve • using ‘ virtual machines ’ ‘ containers ’ -emulations computer run inside isolated rest pre- configured specifically ml tasks recruitment example ml engineer virtual machine vulnerability could contained • many ml developed using programming languages well -developed scientific machine uses like python necessarily secure however possible train ml model using one programming language eg python deployment convert model another language eg java makes making insecure coding less likely return recruitment example another way ml engineer could mitigated risk malicious attack cv filtering model would convert model different programming language prior deployment reading – ico guidance read report protecting personal online services mistakes others although written report ’ area still assist ico developing security guidance include additional recommendations oversight review externally maintained source code protection perspective well implications security protection design resources guidance national cyber security centre ncsc maintaining code repositories assist types privacy attacks apply models personal people trained might inadvertently revealed outputs 69 version 1.0 auditing framework -draft guidance consultation normally assumed personal individuals whose train inferred simply observing predictions returns response inputs however types privacy attacks ml models suggest sometimes possible update two kinds privacy attacks – ‘ model inversion ’ ‘ membership inference ’ model inversion attacks model inversion attack attackers already access personal belonging specific individuals included training infer personal individuals observing inputs outputs ml model attackers learn goes beyond generic inferences individuals similar characteristics figure 1. illustration model inversion membership inference attacks reproduced veale 'algorithms remember model inversion attacks protection law example one – model inversion attack early demonstration kind attack concerned medical model designed predict correct dosage anticoagulant using patient including genetic biomarkers proved attacker access demographic individuals included training could infer genetic biomarkers model despite access underlying training 70 version 1.0 auditing framework -draft guidance consultation example two – model inversion attack another recent example demonstrates attackers could reconstruct images faces facial recognition frt trained recognise frt often designed allow third parties query model model given image person whose face recognises model returns best guess name person associated c onfidence rate attackers could probe model submitting many different randomly generated face images observing names confidence scores returned model could reconstruct face images associated individuals inc luded training reconstructed face images imperfect researchers found could matched reviewers individuals training 95 accuracy figure 2 figure 2. face image recovered using model inversion attack corresponding training set image fredriksen al. 'model inversion attacks exploit conﬁdence ’ resources ‘ algorithms remember model inversion attacks protection law ’ simple demographics often identify people uniquely ‘ model inversion attacks exploit confidence informatio n basic countermeasures ’ membership inference attacks membership inference attacks allow malicious actors deduce whether given individual present training ml model however 71 version 1.0 auditing framework -draft guidance consultation unlike model inversion ’ necessarily learn additional personal individual instance hospital records train model predicts patient discharged attackers could model combination particular individual already work part training would reveal individual ’ training set practice would reveal visited one hospitals generated training period collected similar earlier frt example membership inference attacks exploit confidence scores provided alongside model ’ prediction individual training model disproportionately confident prediction tha person seen allows attacker infer person training gravity consequences models ’ vulnerability membership inference depend sensitive revealing membership migh model trained large number people drawn general population membership inference attacks pose less risk model trained vulnerable sensitive population eg patients dementia hiv merel revealing someone part population serious privacy risk black white attacks important distinction ‘ black ’ ‘ white ’ attacks models two approaches correspond differe nt operational models white attacks attacker complete access model inspect underlying code properties although training example providers give third parties entire pre trained model allow run locally white attacks enable additional gathered – type model parameters – could help attacker inferring personal model black attacks atta cker ability query model observe relationships inputs outputs example many providers enable third parties access functionality ml model online send queries containing input receive model ’ response examples highlighted black attacks white black attacks performed providers ’ customers anyone else either authorised unauthorised access either model que ry response functionality respectively 72 version 1.0 auditing framework -draft guidance consultation models include training design model inversion membership inferences show models inadvertently contain personal note certain kinds ml models actually contain parts training raw form within design instance ‘ support vector machines ’ svms ‘ k-nearest neighbours ’ knn models contain training model cases training personal access model means organisation purchasing model already access subset personal contained training without exert efforts providers ml models third parties procuring aware co ntain personal way unlike model inversion membership inference personal contained models like attack vector personal contained models would design easily retrievable third party storing using models therefore constitutes processing personal standard protection provisions apply steps take manage risks privacy attacks models train models provide others assess whether models contain personal risk revealing attacked take appropriate steps mitigate risks assess whether training contains identified identifiabl e personal individuals either directly access model assess means reasonably likely light vulnerabilities described rapidly developing area hould stay up- to-date state art methods attack mitigation security ml researchers still working understand factors make ml models less vulnerable kinds attacks design effective protections mitigation strategies one possible cause ml models vulnerable privacy attacks known ‘ overfitting ’ model pays much attention details training effectively almost remembering parti cular examples training rather general patterns model inversion membership inference attacks exploit avoiding overfitting help mitigating risk privacy attacks ensuring model able make good inferences examples ’ seen however avoiding overfitting 73 version 1.0 auditing framework -draft guidance consultation completely eliminate risks even models overfitted training still vulnerable privacy attacks cases confidence provided ml exploited frt example risk could mitigated providing end user would need balanced need genuine end users know whether rely output depend particular case context going provide whole model others via application programming interface api would subject white -box attacks way api ’ users would direct access model however might still subjected black attacks mit igate risk could monitor queries api ’ users order detect whether suspiciously indicate privacy attack would require prompt investigation potential suspension blocking particular user account measures become part common real- time monitoring techniques protect security threats ‘ rate -limiting ’ reducing number queries performed particular user given time limit model going provided whole third party rather merely accessible via api need consider risk ‘ white ’ attacks model provider less easily able monitor model deployment thereby assess mitigate risk privacy attacks however remain responsible ensuring personal train models exposed result way clients deployed model able fully assess risk without collaborating clients understand particular deployment contexts associated threat models part procurement policy sufficient sharing party perform respective assessments necessary cases ml model providers clients joint controllers therefore need perform joint risk assessment cases model actually contains examples training default svms knns mentioned transfer personal treat adversarial examples main protection concerns involve accidentally revealing personal potential novel security risks ‘ adversarial examples ’ examples fed ml model deliberately modified reliably misclassified images 74 version 1.0 auditing framework -draft guidance consultation manipulated even real -world modifications stickers placed surface item examples include pictures turtles classi fied guns road signs stickers would instantly recognise ‘ stop ’ image recognition model adversarial examples concerning security perspective might themselve raise protection concerns ’ involve personal security principle refers security personal – protecting unauthorised processing however adversarial attacks ’ necessarily involve unauthorised processing personal compromise however cases adversarial examples risk freedoms individuals instance attacks demonstrated facial recognition slightly distorting face image one individual adversary trick facial recognition misclassifying another even though would still recognise distorted image correct individual would raise concern ’ statistical accuracy especially make legal similarly significant decisions individuals need consider risk adversarial examples part obligations nis directive . ico competent authority ‘ relevant service providers ’ nis include online search engines online marketplaces cloud computing services ‘ nis incident ’ includes incidents compromise stored network related services provide likely include cloud computing services even adversarial attack involve personal still nis incident therefore within ico ’ remit reading – ico guidance nis regulations including whether qualify relevant service provider read guide nis example controls risk statement infrastructure architecture increases likelihood unauthorised access alteration destruction personal preventative • subscribe security advisories receive alerts vulnerabilities • comply assess external security certifications schemes 75 version 1.0 auditing framework -draft guidance consultation • subject software quality review one individuals view read parts source code least one reviewers author code • document policy process separation environment rest network infrastructure evidence separation adhered happened • approach asset management ensure coordinate approach optimisation costs risks service/performance sustainability • document contracts third parties role responsibilities third parties • document policies processes dealing third parties evidence due diligence security completed • document policy processes breach reporting escalation • adhere policy process • model governance policy • assess secure implementations trained model mplement appropriate post pre-deployment • processes place review latest privacy enhancing techniques assess technique 's applicability context implement appropriate • document dpia including thorough assessment security risks mitigants controls reduce likelihood impact attack • api access policy place monitors volume patterns requests identify report sus picious activity • ensure staff trained understand breach reporting policy procedures follow detective • monitor api requests detect suspicious requests take action result • regularly test assess evaluate effectiveness security measures put place eg techniques penetration testing • monitor complaints monitoring take action result including broader analysis identify individuals impacted corrective • evidence changes made design including analysis justification reduce risk future attacks 76 version 1.0 auditing framework -draft guidance consultation minimisation privacy -preserving techniques available considerations minimisation principle need make minimisation principle requires identify minimum amount personal ou need fulfil purpose process example article 5 1 c gdpr says quote ‘ 1 personal shall adequate relevant limited necessary relation purposes hey processed minimisation ’ however generally require large amounts first glance therefore difficult comply minimisation principle – yet using part processing still required whilst appear challenging practice case minimisation principle mean either ‘ process personal ’ ‘ process ’ going break law ’ key process personal need purpose go determining ‘ adequate relevant limited ’ therefore going specific circumstances existing guidance minimisation deta ils steps take context ‘ adequate relevant limited ’ therefore case specific however number techniques adopt order develop process need still remaining functional section explore relevant techniques supervised machine ml currently common type within organisations individuals acc ountable risk management compliance need aware techniques exist able discuss assess different approaches technical staff example default approach scientists designing nd building might involve collecting using much possible without thinking ways could achieve purposes less therefore implement risk management practices designed ensure minimis ation relevant minimisation techniques 77 version 1.0 auditing framework -draft guidance consultation fully considered design phase similarly buy and/or implement operated third parties considerations form part procurement process due diligence aware help comply principle minimisation techniques described eliminate kinds risk techniques require compromise comply minim isation requirements others need balance minimisation compliance utility objectives eg making statistically accurate non -discriminatory ml models trade -offs section detail first step take towards compliance minimisation understand map ml processes personal might relevant provisions legislation article 5 1 c recital 39 article 16 rectification article 17 erasure gdpr external link reading – ico guidance read guidance minimisation principle guide gdpr process personal supervised ml models supervised ml algorithms trained identify patterns create models datasets ‘ training ’ include past examples type instances model asked classify predict specifically training contains ‘ target ’ variable ie thing model aiming predict classify several ‘ predictor ’ variables ie input make prediction instance training bank ’ credit risk ml model predictor variables might include age income occupation location previous customers target variable whether customers repaid loan trained ml classify make predictions based containing examples never seen query sent ml model containing predictor variables instance e g customer ’ age income occupation etc. model responds best guess target variable instance eg whether customer default loan 78 version 1.0 auditing framework -draft guidance consultation supervised ml approaches therefore two main phases 1. training phase training develop models based past examples 2. inference phase model make prediction classification instances model make predictions classifications individual people likely personal training inference phases techniques minimise personal designing ml applications designing building ml applications scientists generally assume training testing operating aggregated centralised way held full original form single entity multiple places throughout ’ lifecycle however personal need consider whether necessary process purpose achieve outcome processing less personal definition minimisation principle requires number techniques exist help minimise amount personal need process minimise personal training stage explained training phase involves applying algorithm dataset containing set features individual generate prediction classificati however features included dataset necessarily relevant purpose example financial demographic features useful predict credit risk therefore need assess features – therefore wh – relevant purpose process variety standard feature selection methods scientists select features usefu l inclusion model methods good practice science go way towards meeting minimisation principle discussed ico ’ previous report big fact might later process found useful making predictions enough establish need keep purpose retroactively collection retention collect personal -chance might useful 79 version 1.0 auditing framework -draft guidance consultation future although able hold foreseeable event occur – able reading – ico guidance read report big machine protection privacy -enhancing methods consider range techniques enhancing privacy minimise personal processed training phase including • perturbation adding ‘ noise ’ • federated techniques involve modifying training reduce extent traced back specific individuals retaining purposes training well -performing models apply types privacy- enhancing techniques training already collected possible however apply collecting personal part mitigating risks individuals large datasets pose measure effectiveness privacy -enhancing techniques balancing privacy individuals utility ml mathematically using methods differential privacy differential privacy way measure whe ther model created ml algorithm significantly depends particular individual train mathematically rigorous theory meaningfully implementing differential privacy practice still challenging monitor developments methods assess whether provide meaningful minimisation particular context attempting implement • perturbation modification could involve changing values points belonging individuals random – known ‘ perturbing ’ adding ‘ noise ’ – way preserves statistical properties features generally speaking choose much noise inject obvious consequences much still learn ‘ noisy ’ instance smartphone predictive text based words users previously typed rather always collecting user ’ actual keystrokes could designed create ‘ noisy ’ ie false 80 version 1.0 auditing framework -draft guidance consultation words random means makes substantially less certain words ‘ noise ’ words actually typed specific user although would less accurate individual level provided enough users could still observe patterns train ml model aggregate level noise inject less learn cases able inject sufficient noise render pseudonymous way provides meaningful level protection • federated related privacy- preserving technique federated allows multiple different parties train models ‘ local ’ models combine patterns models identified known ‘ gradients ’ single mo accurate ‘ global ’ model without share training federated relatively several large -scale applications include auto correction predictive text models across smartphones medical involving analysis across multiple patient databases sharing gradient derived locally trained model presents lower privacy risk sharing training gradient still reveal personal informatio n individuals derived especially model complex lot fine -grained variables therefore still need assess risk -identification case federated participating organisations co nsidered joint controllers even though ’ access ’ reading controllership read section controller/processo r rela tionships ‘ rappor randomised aggregatable privacy preserving ordinal responses ’ example perturbation minimise personal inference sta ge make prediction classification individual ml models usually require full set predictor variables person included query training phase number techniques minimise personal and/or mitigate risks posed inference stage including • converting personal less ‘ readable ’ formats • making inferences locally • privacy- preserving query approaches 81 version 1.0 auditing framework -draft guidance consultation consider approaches • converting personal less “ readable ” formats many cases process converting format allows classified model go way towards minimising raw personal usually first converted abstract format purposes prediction instance -readable words normally translated series numbers called ‘ feature vector ’ means deploy model need process -interpretable version personal contained query example conversion happens user ’ device however fact longer easily human- interpretable imply converted longer personal consider facial recognition frt example order facial recognition model work images faces classified converted ‘ faceprints ’ mathematical representations geometric properties underlying faces – eg distance person ’ nose upper lip rather sending facial images servers photos could converted faceprints directly individuals ’ device captures sending model querying faceprints would less easily identifiable humans face photos however faceprints still personal indeed biometric therefore much identifiable within context facial recognition models – purposes uniquely identifying individual would special category protection law • making inferences locally another way mitigate risks involved sharing predictor variables host ml model device query generated already collects stores individual ’ personal example ml model could installed user ’ device make inferences ‘ locally ’ rather hosted cloud server instance models predicting news co ntent user might interested could run locally smartphone user opens news app day ’ news sent phone local model would select relevant stories show user based user personal ha bits profile tracked stored device shared provider app store constraint ml models need sufficiently small computationally efficient run user ’ hardware however recent advances purpose -built hardware smartphones embedded devices mean increasingly viable option 82 version 1.0 auditing framework -draft guidance consultation important note local processing necessarily scope protection law even personal involved training processed user ’ device organisation creates distributes model still controller far determines means purposes processing similarly personal user ’ device subsequently accessed third party activity would constitute ‘ processing ’ • privacy-preserving query approaches feasible deploy model locally privacy- enhancing techniques exist minimise revealed query sent ml model allow one party retrieve prediction classificat ion without revealing party running model simple terms allow get answer without fully reveal question reading ‘ privad practical privacy online advertising ’ external link ‘ targeted advertising handset privacy security challenges ’ external link proof concept examples making inferences locally ‘ tapas trustworthy privacy -aware participatory sensing ’ example privacy -preserving query approaches anonymisation role conceptual technical similarities minimisation anonymisation cases applying privacy- preserving techniques means certain ml rendered ps eudonymous anonymous however note pseudonymisation essentially security risk reduction technique protection law still applies personal undergone pseudonymisation contrast ‘ anonymous ’ means question longer personal protection law apply reading ico currently developing guidance anonymisation take account recent developments technique field storing limiting training sometimes necessary retain training order -train model instance modelling approaches become available debugging however whe model established unlikely re-trained modified training longer needed 83 version 1.0 auditing framework -draft guidance consu ltation model designed last 12 months ’ worth retention policy specify older 12 months deleted reading union agency network security enisa number publications pets including reports external link example controls risk statement developers properly assess adequacy necessity relevance personal resulting noncompliance minimisation principle preventative • document levels approval authority development/use including personal sets included within model evidence appropriate approval • review personal relevance stage model includ ing detailed justification retention confirmation irrelevant removed deleted • separate different stages lifecycle based conditions minimisation principle • document retention policy schedule evidence schedule adhered personal deleted line schedule retention outside schedule justified approved • carry independent review model input output specifically regarding relevance personal inputs • document dpia including thorough assessment pets considered considered appropriate detective • periodic review features within model check ar e still relevant eg testing fewer features results achieved view reducing amount personal processed • monitor individual requests complaints individuals including action taken result individual level boarder analysis • periodically assess whether model remains compliant minimization processes third parties corrective 84 version 1.0 auditing framework -draft guidance consultation • remove delete non -required features • select less invasive model including thorough justification change • remove erase training longer required eg longer predictively useful • implement appropriate pets 85 version 1.0 auditing framework -draft guidance consultation enable individual glance way developed deployed means personal often managed processed unusual ways make harder understand individual apply challenging implement effective mechanisms individuals exercise detail • individual apply different stages lifecycle • individual relate personal contained model • enable individual relating solely automated decisions legal similar effect • role oversight individual apply different stages lifecycle protection law individuals number relating personal within apply wherever personal various points deployment lifecycle therefore covers personal • contained training • make prediction deployment result prediction • might contained model section describes considerations encounter developing deploying attempti ng comply individual access rectification erasure restriction processing portability object referred articles 13 -21 gdpr cover detail discusses general challenges facilitating context appropriate mentions challenges specific individuals solely automated decisions affect legal similarly significant ways discussed detail 86 version 1.0 auditing framework -draft guidance consultation ‘ role oversight ’ raise particular challenges using enable individual requests training creating using ml models invariably need obtain train models instance retailer creating model predict consumer purchases based past transactions needs large dataset customer transactions train model identifying individuals training potential challenge enabling typically training includes relevant predictions past transactions demographics location contact details unique customer identifiers training typically subjected various measures make amena ble ml algorithms however detailed timeline customer ’ purchases might transformed summary peaks troughs transaction history process transforming prior using training statistical model nstance transforming numbers values 0 1 often referred ‘ pre -processing ’ create confusion regarding terminology protection ‘ processing ’ refers operation set operations performed personal ‘ pre -processing ’ machine terminology still ‘ processing ’ protection terminology therefore protection still applies processes involve converting personal one form another pot entially less detailed form make training potentially much harder link particular named individual however protection law necessarily considered sufficient take scope therefore still nee consider responding individuals ’ requests exercise even lacks associated identifiers contact details transformed pre -processing training still considered personal ‘ single ’ individual relates combination process even associated customer ’ name instance training purchase pre diction model might include pattern purchases unique one customer example customer provide list recent purchases part request organisation able identify portion training hat relates individual 87 version 1.0 auditing framework draft guidance consultation kinds circumstances obliged respond individual ’ request assuming taken reasonable measures verify identity exceptions apply consult guidance determining personal identifiability • access regard requests access rectification erasure training manifestly unfounded excessive harder fulfil motivation requesting unclear comparison access requests might typically receive collect maintain additional personal enable identify individuals within training sole purposes complying gdpr per article 11 times therefore able identify individual training individual provide additional would enable identification therefore fulfil request • rectification rectification apply f personal train steps take respect rectification depend process well nature scope context purpose processing case training one purpose processing find general patterns large datasets context individual inaccuracies training likely affect performance model since one point among many compared personal might take action individual example think important rectify incorrectly recorded customer delivery address rectify incorrect address training rationale likely tha former could result failed delivery latter would barely affect overall accuracy model however practice rectification allow disregard requests think less important fo r purposes • erasure receive requests erasure personal contained within training note whilst erasure still need consider erasure request receive u nless processing basis legal obligation task unlikely lawful bases training – section lawful bases 88 version 1.0 auditing framework -draft guidance consultation erasure individual ’ personal training unlikely affect ability fulfil purposes training therefore unlikely justification fulfilling request erase personal training dataset complying request erase training entail erasing ml models based unless models contain infer situations cover section • portability individuals portability ‘ provided ’ controller lawful basis processing consent contract ‘ provided ’ includes individual consciously input form behavioural observational gathered process using service cases traini ng model eg demographic spending habits counts ‘ provided ’ individual portability would therefore apply cases processing based consent contract however discussed pre -processing methods usually applied significantly change original form something effectively analysed machine algorithms transformation significant resulting longer count ‘ provided ’ case would subject portability although still constitute personal protection still apply eg access however original form pre -processed derived still subject portability provided individual consent contract processed automated means • informed inform individuals personal going train cases obtained training individual therefore opportunity inform time cases provide individual wi th specified article 14 within reasonable period one month latest since using individual ’ purposes training normally constitute making solely automated decision legal similar ly significant effects need provide decisions taking however still need comply main transparency requirements 89 version 1.0 auditing framework -draft guidance consulta tion reasons stated difficult identify communicate individuals whose personal contained training instance training stripped personal identifiers contact addresses still remaining personal cases impossible involve disproportionate effort provide directly individual therefore instead take appropriate measures protect individual ’ freedoms legitimate interests instance could provide explaining obtained train enable individ ual requests outputs typically deployed outputs stored profile individual take action instance product offers customer sees website might driven output predictive model stored profile constitutes personal subject access rectification erasure whereas individual inaccuracies training negligible effect inaccur ate output model could directly affect individual requests rectification model outputs personal inputs based therefore likely made requests rectification training however said predictions inaccurate intended prediction scores opposed statements fact personal inaccurate rectification apply personal resulting analysis provided subject portability means outputs models predictions classifications individuals scope portability cases features tra model result previous analysis personal instance credit score result statistical analysis based individual ’ financial might feature ml model cases credit score included within scope portability even features reading – ico guidance read guidance individual guide gdpr including • informed • access • erasure • rectification 90 version 1.0 auditing framework -draft guidance consultation • portability individual relate contained model addition inputs outputs model cases personal might contained model explained section 3.2 could happen two reasons design accident fulfil requests regarding models contain design personal included models design certain types models support vector machines svms contain key examples training order help distinguish examples deployment cases small set individual examples contained somewhere internal logic model training set typ ically contains hundreds thousands examples small percentage ends directly model therefore chances one relevant individuals makes request small remains possible dependin g particular programming library ml model implemented built -in function easily retrieve examples cases might practically possible respond individual ’ request enable using models contain personal design implement way allows easy retrieval examples request access could fulfil without altering model request rectification erasure possible without -training model either rectified without erased deleting model altogether well -organised model management deployment pipeline accommodating requests -training redeploying models accordingly prohibitively costly fulfil requests regarding contained models accident aside svms models hat contain examples training design models might ‘ leak ’ personal accident cases unauthorised parties able recover elements training infer analysing way model behaves access rectification erasure difficult impossible exercise fulfil scenarios unless individual presents evidence personal could inferred model 91 version 1.0 auditing framework -draft guidance consultation able determine whether personal inferred therefore whether request basis regularly proactively evaluate possibility personal inferred models light state -of-the-art minimise risk accidental disclosure enable individual relating olely automated decisions legal similar effect protection requires implement suitable safeguards processing personal make solely automated decisions legal similarly significant impact individuals afeguards include individuals • obtain intervention • express point view • contest decision made • obtain explanation logic decision processing involving solely automated decision making falls part 2 dpa safeguards differ gdpr lawful basis processing requirement authorisation law processing involving solel automated decision making falls part 3 dpa applicable safeguards depend regulations provided particular law authorising automated decision- making although individual request consider decision take decision based solely automated processing safeguards token gestures guidance published protection board edpb states intervention involve review decision quote “ carried someone appropriate authority capability change decision ” review include quote “ thorough assessment relevant including additional provided subject. ” 92 version 1.0 auditing framework -draft guidance consultation conditions intervention qualifies meaningful similar apply render decision non- solely automated previous section however key difference solely automated contexts intervention required case -by-case basis safeguard individual ’ whereas qualify solely automated meaningful intervention required every decision could relating automated decisions particular issue type complexity involved making solely automated decisions affect nature severity risk people ’ protection raise different considerations well compliance risk management challenges basic automate relatively small number explicitly written rules unlikely considered eg set clearly expressed ‘ -then ’ rules determine customer ’ eligibility product however resulting decisions could still constitute automated decision -making within meaning protection law relatively easy reviewer identify rectify mistake decision challenged individual ’ high interpretability however based ml complex present challenges meaningful review ml make predictions classifications people based patterns even highly statistically accurate occasionally reach wrong decision individual case errors easy reviewer identify understand fix every challenge fro individual result decision overturned expect many could two particular reasons case ml • individual ‘ outlier ’ ie circumstances substantially different considered training build ml model trained enough similar individuals make incorrect predictions classifications • assumptions design challe nged eg continuous variable age might broken ‘ binned ’ discrete age ranges like 20 -39 part modelling process finer-grained ‘ bins ’ result different model substantially different predictions peopl e different ages validity pre -processing design choices come question result individual ’ challenge 93 version 1.0 auditing framework -draft guidance consultation steps take fulfil related automated decision making • consider requirements necessary support meaningful review design phase particularly interpretabilit requirements effective user- interface design support reviews interventions • design deliver appropriate training support reviewers • give staff appropriate authority incentives support address escalate individuals ’ concerns necessary override ’ decision however additional requirements considerations aware ico ’ explain guidance looks extent complex might affect ability provide meaningful explanations individuals however complex impact effectiveness mandatory safeguards comp lex explain complex meaningfully contest intervene review put alternative point view instance uses hundreds features complex nonlinear model make prediction difficult individual determine variables correlations object therefore safeguards around solely automated mutually supportive designed holistically individual mind logic explanations decisions give individuals necessary context decide whether grounds would like request intervention cases insufficient explanations prompt ndividuals resort unnecessarily requests intervention expression views contests likely happen individuals ’ feel sufficient understanding decision reached process indivi duals exercise simple user friendly example communicate result solely automated decision communicated website page contain link allowing individual contact member staff intervene without undue delays complications required keep record decisions made part accountability documentation obligations include whe ther individual requested intervention expressed 94 version 1.0 auditing framework -draft guidance consultation views contested decision whether changed decision result monitor analyse decisions regularly changed response individuals exercising consider amend accordingly based ml might involve including corrected decisions fresh training similar mistakes less likely happen future substantially identify need collect better training fill gaps led erroneous decision modify model -building process ie changing feature selection addition compliance requirement opportunity improve performance turn build individuals ’ trust however grave frequent mistakes identified need take immediate steps understand rectify underlying issues necessary suspend automated trade- offs -in-the-loop entail either terms erosion privacy reviewers need consider additional personal order validate reject generated output possible reintroduction biases end automated process reading – ico guidance read guidance documentation guide gdpr reading – protection board protection board edpb replaced article 29 working party wp29 includes representatives f rom protection authorities member state adopts guidelines complying requirements gdpr wp29 published guidelines automated decision making profiling . edpb endorsed guidelines . explain logic involved ai- driven automated decision individuals meaningful logic involved -driven automated decision detail comply please recent explain guidance produced collaboration alan turing institute turing 95 version 1.0 auditing framework -draft guidance consultation example controls risk statement infrastructure architecture inhibits ability recognise respond act upon individual requests preventative • ensure developers receive training includes requirement consider individual ir offset • set document levels approval authority development/use including consideration ir model maintain evidence appropriate approval • implement document policy process dealing ir requests processing pipeline particular defining circumstances would ’ respond eg train versus output impact individual • provide individual training 'customer facing individuals including escalate complex requests • dpia include thorough flow mapping • consider indexing making searchable using common identifiers part design ir requests anticipated • fully automated decision making ensure humans required investigate decision skil ls tools autonomy investigate override decision • ensure subjects informed processing purposes training profiling cases training another organisation direct relationship dat subject informing directly would involve disproportionate effort ensure make publicly available organisations source processes place inform subjects processing • ensure individuals given means provide additional order identified within • maintain documented policies processes dealing third parties particular roles responsibilities controller processor detective • conduct peer reviews ensure actions completed required 96 version 1.0 auditing framework -draft guidance consultation • conduct periodic review sample ir requests ensure accurate complete declined justification eg manifestly unfounded appropriate • systematically monitor time taken respond requests order identify potentially complex • submit ‘ dummy ’ ir requests test process measure outcomes corrective • re-design storage indexing training • consider additional ata could help identify subjects case request • correct inaccurate personal contextualise inferred misleading matter fact • delete personal required • re-train employees responsible fo r identification execution ir requests • retrain humans reassessment resource requirements eg humans pressured make x decisions time • redesign eg simplification inclusion warnings pop-ups • select appropriate model including thorough justification change • re-review overturn decisions eg one rogue reviewer action taken result including broader assessment impacts individuals role oversight inform legal similarly significant decisions individuals risk decisions made without appropriate oversight infringes article 22 gdpr mitigate risk ensure people assigned provide oversight remain engaged critical able challenge ’ outputs wherever appropriate difference solely automated partly automated decision making two ways • automated decision making adm makes decision automatically 97 version 1.0 auditing framework -draft guidance consultation • decision -support supports decision maker deliberation example could automatically approves rejects financial loan merely provide additional support loan officer deci ding whether grant loan application whether fully automated -driven decision making generally less risky -supported decision making depends specific circumstances therefore need evaluate based ow n context regardless merits automated decisions treated differently decisions protection law specifically article 22 gdpr restricts fully automated decisions legal similarly significant effects individuals limited set lawful bases requires certain safeguards place contrast decision support tools support decision -making subject conditions result restrict ions safeguards automated decision -making arguably carries higher risk decision- making even though cases mitigate risks decision -making decide support decision -making aware decision fall outside scope article 22 ‘ rubber- stamped ’ input needs meaningful degree quality review intervention final decision made individual key factors determining whether automated decision-making merely decision -support ensuring input meaningful situations responsibility using senior leaders scientists business owners oversight functions among others expected play role ensuring applications designed built intended deploying desi gned decision support tools therefore intended outside scope article 22 aware existing guidance issues ico edpb key considerations • reviewers involved checking ’ recommendation apply automated recommendation individual routine fashion • reviewers ’ involvement token gesture actual ‘ meaningful ’ influence decisio n 98 version 1.0 auditing framework -draft guidance consultation including ‘ authority competence ’ go recommendation • reviewers ‘ weigh -up ’ ‘ interpret ’ recommendation consider available input take account additional factors relevant provisions legislation gdpr article 22 recital 71 external link dpa sections 14 49 50 external link reading – ico guidance read guidance au tomated decision making profiling guide gdpr reading – protection board protection board edpb replaced article 29 working party wp29 includes representatives protection authorities member state adopts guidelines complying requirements gdpr wp29 published guidelines automated decision making profiling . edpb endorsed guidelines . additional risk factors need consider meaningfulness input automated decision -making however basi c however complex two additional factors could potentially cause intended decision -support inadvertently fail ensure meaningful input therefore fall scope article 22. th ey • automation bias • lack interpretability ‘ automation bias mean models based mathematics people tend think objective trust output regardless accurate 99 version 1.0 auditing framework -draft guidance consultation terms automation bias automation -induced complacency describe users routinely rely output generated decisio n-support stop using judgement stop questioning whether output might wrong ‘ lack interpretability ’ mean types outputs difficult reviewer interpret examp le rely complex high dimensional ‘ deep ’ models outputs easily interpretable explanation tools available reliable risk able meaningfully assess output factor decision -making meaningful reviews possible reviewer start agree ’ recommendations without judgement challenge means resulting decisions effectively ‘ solely automated ’ distinguish solely non -solely automated yes take view intended beginning specify document clearly whether using support enhance decision -making make solely automated decisions senior management review sign -off intended making sure line organisation ’ risk appetite means senior management needs solid understanding key risk implications associated option ready equipped provide appropriate degree challenge ensure lines accountability effective risk manageme nt policies place outset intended support decisions policies specifically address additional risk factors automation bias lack interpretability possible • know advance whether partly fully automated application meet needs best • believe fully automated fully achieve intended outcome processing carry risks individuals partly automated cases risk management policies dpias clearly reflec include risk controls option throughout ’ lifecycle 100 version 1.0 auditing framework -draft guidance consultation address risks automation bias think address automation bias chiefly improving effectiveness training monitoring reviewers training key component effective risk management controls mitigate automation bias place start project including scoping design phases well deployment design build phase relevant parts organisation eg business owners scientists oversight functions work together develop design requirements support meaningful review outset think features expect consider additional factors revi ewers take account finalising decision instance could consider quantitatively measurable properties like many years ’ experience job applicant reviewer qualitatively assesses aspect application eg written communication reviewers access arguably taking account additional factors means review sufficiently meaningful decision end considered ‘ solely automated ’ necessary consider capture additional factors consideration reviewers example might interact directly person decisi gather charge designing front -end interface understand needs thought process behaviours reviewers enable effectively intervene therefore helpfu l consult test options reviewers early however features depend available type model selected building choices need test confirm assumptions made design phase trained built address risks interpretability consider interpretability design phase however interpretability challenging define terms measured different ways example reviewer • predict ’ outputs change given different inputs • identify important inputs contributing particular output • identify output might wrong 101 version 1.0 auditing framework -draft guidance consultation important define document interpretability means measure specific context wish personal process interpretable others instance models small number -interpretable features eg age weight likely b e easier interpret models large number features relationship input features model ’ output either simple complicated simple rules set conditions certain inferences made case decision trees easier interpret similarly linear relationships value output increases proportional input easier interpret relationships non -linear output value proportional input non-monotonic output value increase decrease input increases one approach address low interpretability 'local explanations using methods like local interpretable model -agnosti c explanation lime provides explanation specific output rather model general limes simpler surrogate model summarise relationships input output pairs similar try ing interpret addition summaries individual predictions limes sometimes help detect errors eg specific part image led model classify incorrectly however represent logic underlying outputs misleading misused therefore assess whether context lime similar approaches help decision maker meaningfully interpret output many statistical models designed provide confidence score alongside output could help reviewer decision -making lower confidence score indicates reviewer needs input final decision ‘ need statistical accuracy ’ assessing interpretability requirements part design phase allowing develop explanation tools part required risk management policies establish robust risk based independent approval process processing operation uses set clearly responsible testing final validatio n deployed individuals accountable negative impact interpretability 102 version 1.0 auditing framework -draft guidance consultation effectiveness reviews provide sign -off line adopted risk management policy train staff address risks training staff pivotal ensuring considered non solely automated starting point train retrain reviewers • understand works limitations • anticipate misleading wrong • healthy level scepticism ’ output given sense often could wrong • understand expertise meant complement provide list factors take account • provide meaningful explanations either rejecting accepting ’ output – decision responsible escalation policy place order training effective important • reviewers authorit override output generated confident penalised authority confidence created policies training alone supportive organisational culture crucial • training programme kept date line technological developments changes processes reviewers offered ‘ refresher ’ training intervals appropriate focussed training reviewers however worth noting consider whether function requires additional training provide effective oversight eg risk internal audit monitoring undertake analysis many times reviewer accepted rejected ’ output key part effective risk monitoring risk monitoring reports flag reviewers routinely agreeing ’ outputs demonstrate genuinely assessed decisions effectively classed solely automated gdpr 103 version 1.0 auditing framework -draft guidance consultation need controls place keep risk within target levels outcomes go beyond target levels processes swiftly assess compliance take action necessary might include temporarily increasing scrutiny ensuring appropriate lawful basis safeguards case decision -making effectively become fully automated reading – ico guidance read explain draft guidance methods explaining interpreting example controls risk statement incorrectly classified fully automated result lack meaningful oversight potential non -compliance dp legislation preventative • implement document policy process classification relation article 22 including level approval authority maintain evidence decision -making process appropriate sign-off approval • provide training humans employed provide meaningful oversight including ability challenge decision provide independent review • ensure developers understood skills experience ability overseers designing • include pre -implementation testing assessment oversight ensure meaningful • set document levels approval authority development/use particular relation model complexity ensure reviewers interpret challenge maintain evidence appropriate approval • conduct document analysis time expected meaningfully review detective • conduct post -implementation testing document results testing action taken result • test sample decisions ensure making decision document tests including sample selected criteria 104 version 1.0 auditing framework -draft guidance consultation • monitor decisions made compare decisions document action taken result performance goes outside defined tolerances • conduct document ‘ mystery shopping ’ exercises periodically provide deliberately misleading disagree ensure input meaningful • monitor individual requests complaints individuals particular relating article 22 including action taken result individual level boarder analysis • conduct periodic assessment confidence overturning outcome • monitor individuals ’ performance identify outliers action taken result corrective • re-train decision makers reassess resource requirements eg humans pressured make many decisions short space time • re-design eg simplification inclusion warnings pop-ups • select appropriate model include thorough justification change • re-review overturn decisions eg one rogue reviewer action taken result including broader assessment impacts individuals 105 version 1.0\",\n",
       " 'opinion ethics commission opinion ethics commission overview executive summary ..................................................................................... 12 introduction ................................................................................................ 33 ethical legal principles .......................................................................... 39 technical foundations ................................................................................. 49 multi-level governance complex ecosystems ................................... 67 ............................................................................................................. 79 algorithmic ................................................................................... 159 path ......................................................................................... 225 appendix .................................................................................................... 229a b c e f g executive summary ..................................................................................... 12 1. general ethical legal principles ............................................................................... 14 2. ............................................................................................................... 16 3. algorithmic .............................................................................................. 24 4. path .................................................................................................. 32 introduction ................................................................................................ 33 guiding motifs ....................................................................................................... 34 1. mission basic understanding .................................................................................. 35 2. working method .................................................................................................. 36 3. objectives scope report ................................................................................ 37 ethical legal principles .......................................................................... 39 1. fundamental value agency ......................................................................... 40 2. relationship ethics law .............................................................................. 41 3. general ethical legal principles ............................................................................... 43 3.1 dignity ............................................................................................... 43 3.2 self-determination ........................................................................................... 43 3.3 privacy ....................................................................................................... 45 3.4 security ...................................................................................................... 45 3.5 democracy ................................................................................................... 46 3.6 justice solidarity .......................................................................................... 46 3.7 sustainability ................................................................................................. 47 technical foundations ................................................................................. 49 1. status quo ................................................................................................... 51 2. elements ............................................................................................. 52 2.1 .................................................................................................... 52 2.1.1 definition properties ....................................................................... 52 2.1.2 management ...................................................................................... 53 2.1.3 big small ................................................................................. 53 2.2 processing ......................................................................................... 54 2.2.1 algorithms ............................................................................................. 54 2.2.2 statistical inference .................................................................................... 55 2.2.3 machine ....................................................................................... 57 2.2.4 ................................................................................... 59 2.2.5 algorithmic ............................................................................... 62 2.3 software ................................................................................................ 62 2.4 hardware ............................................................................................... 63 2.5 architecture ...................................................................................... 63a b ctable contents multi-level governance complex ecosystems ................................... 67 1. general role state .......................................................................................... 69 2. corporate self-regulation corporate responsibility .................................................... 70 3. education boosting skills critical reflection ........................................................... 72 4. technological developments ethical design ................................................................... 74 5. .......................................................................................................... 75 6. standardisation ................................................................................................... 76 7. two governance perspectives perspective algorithms perspective ............................... 77 ............................................................................................................. 79 1. general standards governance ........................................................................ 81 1.1 foresighted responsibility ................................................................................ 81 1.2 respect parties involved .............................................................. 82 1.3 sharing good ............................................................. 82 1.4 fit-for-purpose quality .............................................................................. 83 1.5 risk-adequate level security ............................................................... 83 1.6 interest-oriented transparency ........................................................................... 83 2. corresponding obligations .................................................................... 85 2.1 general principles obligations .......................................................... 85 2.2 clarification general principles reference typical scenarios ................................... 87 2.2.1 scenarios involving desistance ............................................................ 87 2.2.2 scenarios involving access .................................................................. 90 2.2.3 scenarios involving rectification .................................................................... 92 2.2.4 scenarios involving economic share ............................................................. 93 2.3 collective aspects obligations ...................................................... 94 3. standards personal ........................................................................ 95 3.1 personal relating legal entities ........................................................... 95 3.2 self-determination challenge tackled legal whole ........................ 95 3.2.1 cooperative relationship applicable legal regimes ...................................... 95 3.2.2 risk-adequate interpretation applicable legal framework ...................................... 96 3.2.3. need clarify tighten applicable legal framework ................................... 99 3.2.4 uniform market-related supervisory activities ...................................................... 103 3.3 personal asset ................................................................................ 104 3.3.1 commercialisation personal ............................................................... 104 3.3.2. ownership issue financial compensation ............................................ 104 3.3.3. counter-performance ..................................................................... 105 3.3.4 basis personalised risk assessments ................................................. 106 3.3.5 reputational capital ....................................................................... 107 3.3.6 tradeable items ........................................................................... 108d e 3.4 inheritance ............................................................................. 110 3.4.1 precedence living wills ......................................................................... 110 3.4.2 role intermediaries ......................................................................... 110 3.4.3 post-mortem protection ..................................................................... 111 3.5 special groups subjects .......................................................................... 112 3.5.1 employees ....................................................................................... 112 3.5.2 patients .......................................................................................... 113 3.5.3 minors ........................................................................................... 114 3.5.4 vulnerable care-dependent persons ..................................................... 115 3.6 protection technical design ...................................................................... 116 3.6.1 privacy-friendly design products services .................................................... 116 3.6.2 privacy-friendly product ............................................................. 120 summary important recommendations action ................................................ 121 4. improving controlled access personal ................................................................ 124 4.1 enabling uses personal ............................................................... 124 4.1.1 preliminary considerations ........................................................................ 124 4.1.2 legal clarity certainty ......................................................................... 125 4.1.3 consent processes sensitive ............................................................... 126 4.1.4 legal protection discrimination ............................................................ 128 4.2 anonymisation pseudonymisation synthetic .................................................... 129 4.2.1 procedures standards presumption rules ...................................................... 131 4.2.2 ban de-anonymisation ......................................................................... 132 4.2.3 synthetic .................................................................................... 132 4.3 controlled access management trust schemes ................................ 133 4.3.1 privacy management tools pmt personal management pims ............ 133 4.3.2 need regulation pmt/pims ................................................................. 133 4.3.3 pmt/pims potential interface economy ......................................... 135 4.4 access portability ..................................................................... 136 4.4.1 promotion portability ...................................................................... 136 4.4.2 scope portability extended ...................................... 137 4.4.3 portability interoperability interconnectivity ........................................... 137 4.5 crowdsensing good ....................................................................... 138 summary important recommendations action ................................................ 139 5. debates around access non-personal ................................................................. 141 5.1 appropriate access macroeconomic asset ....................................................... 141 5.2 creation necessary framework conditions ......................................................... 142 5.2.1 awareness raising skills .................................................................. 142 5.2.2 building infrastructures needed data-based economy ...................................... 142 5.2.3 sustainable strategic economic policy ......................................................... 144 5.2.4 improved industrial property protection ........................................................... 144 5.2.5 partnerships ................................................................................. 145 5.3 access existing value creation ............................................................ 145 5.3.1 context .......................................................................................... 145 5.3.2 presence contractual relationship ............................................................. 146 5.3.3 absence contractual relationship .............................................................. 147 5.3.4 sector-specific access .................................................................. 147 5.4 open sector ........................................................................... 148 5.4.1 preliminary considerations ........................................................................ 148 5.4.2 legal framework infrastructures ............................................................... 149 5.4.3 state ’ duty protection ..................................................................... 150 5.5 open private sector .......................................................................... 151 5.5.1 platforms ............................................................................ 151 5.5.2 additional incentives voluntary sharing .................................................... 151 5.5.3 statutory access ....................................................................... 152 5.5.4 role competition law ........................................................................... 153 5.6 access public-sector b2g public-interest purposes ......................................... 154 summary important recommendations action ................................................ 155 algorithmic ................................................................................... 159 1. characteristics algorithmic ....................................................................... 160 2. general standards algorithmic ................................................................... 163 2.1 human-centred design ................................................................................. 163 2.2 compatibility core societal values ................................................................... 164 2.3 sustainability design algorithmic ............................................... 165 2.4 high level quality performance ................................................................... 165 2.5 guarantee robustness security ................................................................... 166 2.6 minimising bias discrimination prerequisite fair decisions ..................................... 167 2.7 transparent explainable comprehensible ................................................... 169 2.8 accountability structures .......................................................................... 171 2.9 result responsibility-guided consideration .............................................................. 171 3. recommendation risk-adapted regulatory approach .................................................... 173 3.1 criticality requirements .............................................................. 173 3.2 criticality pyramid ...................................................................................... 177 3.3 regulation algorithmic enshrining horizontal requirements formed sectoral instruments ................................................................................. 180 summary important recommendations action ................................................. 183f 4. instruments obligations controllers subjects ....................................... 185 4.1 transparency requirements ............................................................................. 185 4.1.1 mandatory labelling “ ” ......................................................................... 185 4.1.2 duties provide duties provide explanation access “ ” “ ” ...................................................... 185 4.1.3 risk impact assessment ........................................................................... 188 4.1.4 duty draw documentation keep logs ..................................................... 190 4.2 requirements algorithmic ............................................................. 190 4.2.1 general quality requirements algorithmic .............................................. 190 4.2.2 special protective measures algorithmic context decision-making .......................................................................... 191 4.2.3 appropriate algorithmic inferences ....................................................... 193 4.2.4 legal protection discrimination ............................................................ 193 4.2.5 preventive official licensing procedures high-risk algorithmic ........................... 195 summary important recommendations action ................................................. 196 5. institutions ................................................................................................ 198 5.1 regulatory powers specialist expertise ............................................................... 198 5.1.1 distribution supervisory tasks within sectoral network oversight authorities ................ 198 5.1.2 definition oversight powers according tasks involved ...................................... 199 5.1.3 criticality-adapted extent oversight ............................................................. 200 5.2 corporate self-regulation co-regulation ............................................................. 201 5.2.1 self-regulation self-certification ............................................................... 201 5.2.2 creation code conduct ..................................................................... 202 5.2.3 quality seals algorithmic .............................................................. 203 5.2.4 contact persons algorithmic companies authorities .............................. 203 5.2.5 involvement civil society stakeholders .......................................................... 203 5.3 technical standardisation ............................................................................... 203 5.4 institutional legal protection particular associations file action ......................... 204 summary important recommendations action ................................................. 205 6. special topic algorithmic media intermediaries .............................................. 207 6.1 relevance democratic process example social networks .................................... 207 6.2 diversity media intermediaries example social networks ....................................... 208 6.3 labelling obligation social bots ...................................................................... 209 6.4 measures combat fake news .......................................................................... 210 6.5 transparency obligations news aggregators ........................................................... 210 summary important recommendations action ................................................. 211 7. algorithmic state bodies .................................................................. 212 7.1 opportunities risks involved algorithmic state bodies ......................... 212 7.2 algorithmic law-making ..................................................................... 212 7.3 algorithmic dispensation justice ....................................................... 213 7.4 algorithmic administration ............................................................ 214 7.5 algorithmic security law ............................................................... 214 7.6 transparency requirements algorithmic state actors ............................. 215 7.7 risk involved automated total enforcement ........................................................ 217 summary important recommendations action ................................................. 218 8. liability algorithmic ............................................................................. 219 8.1 significance ............................................................................................ 219 8.2 harm caused algorithmic .......................................................... 219 8.2.1 liability “ electronic person ” ................................................................ 219 8.2.2 vicarious liability “ autonomous ” ...................................................... 219 8.2.3 strict liability ..................................................................................... 220 8.2.4 product security product liability .............................................................. 221 8.3 need reassessment liability law .................................................................. 222 summary important recommendations action ................................................. 224 path ......................................................................................... 225 appendix .................................................................................................... 229 1. federal government ’ key questions ethics commission ...................................... 230 2. members ethics commission .................................................................... 234g 12 executive summar executive summary 13 executive summar society experiencing profound changes brought digitalisation innovative data-based technologies benefit us individual wider societal levels well potentially boosting economic productivity promoting sustainability catalysing huge strides forward terms scientific progress time however digitalisation poses risks fundamental freedoms raises wide range ethical legal questions centring around two wider issues role want technologies play design want ensure transformation serves good society whole society elected political representatives engage debate shape data-based technologies including germany ’ federal government set ethics commission datenethikkommission 18 . given one-year mandate develop ethical benchmarks guidelines well specific recommendations action aiming protecting individual preserving social cohesion safeguarding promoting prosperity age starting point federal government presented ethics commission number key questions clustered around three main topics algorithm-based decision-making adm opinion ethics commission however merely one among many possible variants algorithmic much common terms ethical legal questions raises mind ethics commission structured work two different headings algorithmic broader sense .in preparing opinion ethics commission inspired following guiding motifs ●ensuring human-centred value-oriented design ●fostering skills critical reflection world ●enhancing protection individual freedom self- determination integrity ●fostering responsible utilisation compatible good ●introducing risk-adapted regulation effective oversight algorithmic ●safeguarding promoting democracy social cohesion ●aligning strategies sustainability goals ●strengthening sovereignty germany europe 1 general ethical legal principles humans morally responsible actions escaping moral dimension humans responsible goals pursue means pursue reasons dimension societal conditionality action always taken account designing technologically shaped future time notion serve humans rather humans subservient taken incontrovertible fact germany ’ constitutional founded understanding nature adheres tradition europe ’ cultural intellectual history technologies altered ethical framework – terms basic values freedoms enshrined german constitution charter fundamental union yet challenges facing mean need reassert values freedoms perform balancing exercises mind ethics commission believes following ethical legal principles precepts viewed indispensable socially accepted benchmarks action.human dignity dignity principle presupposes uncon ditional value every prohibiting practices total monitoring individual humiliation deception manipulation exclusion self-determination self-determination fundamental expression freedom encompasses notion informational self-determination term “ self- determination ” express idea selfdetermined player society privacy privacy intended preserve individual ’ freedom integrity personal identity potential threats privacy include wholesale collection evaluation even intimate topics security principle security relates physical emotional safety humans environmental protection involves preservation vitally important assets guaranteeing security entails compliance stringent requirements e. g. relation human/machine interaction resilience attacks misuse 15 executive summar democracy technologies systemic relevance flourishing democracy make possible shape forms political participation foster emergence threats manipulation radicalisation justice solidarity view vast amounts power accumulated using technologies threats exclusion discrimination safeguarding equitable access distributive justice urgent task digitalisation foster participation society thereby promote social cohesion sustainability developments serve sustainable technologies contribute towards achieving economic ecological social sustainability goals ethics equated one-to-one basis law words everything relevant ethical perspective enshrined legislation conversely provisions law motivated purely pragmatic considerations nevertheless law times heedful potential ethical implications legal provisions force well living ethical standards ethics commission holds view regulation necessary replaced ethical principles particularly true issues heightened implications fundamental require central decisions made democratically elected legislator regulation essential basis building citizens companies institutions trust transformation society guided ethical principles time regulation unduly inhibit technological social innovation dynamic market growth overly rigid laws attempt regulate every last detail situation place stranglehold progress increase red tape extent innovation german companies longer keep pace rate technological international stage yet legislation one range tools lend tangible shape ethical principles synergistic various governance instruments different levels multi-level governance vital view complexity dynamism ecosystems instruments include legislative measures standardisation various forms co- regulation self-regulation technological design moreover function governance instruments applies business models options steering economy governance broader sense encompasses policy-making decisions fields education important consider aforesaid governance instruments national context particular international contexts view ethics commission key questions presented federal government belong one two different perspectives questions concentrate mainly “ perspective ” questions primarily focused algorithmic “ algorithms perspective ” two perspectives regarded competing views two sides coin instead represent two different ethical discourses complement contingent upon different ethical discourses typically reflected different governance instruments including different acts legislation perspective focuses machine basis algorithmically shaped decisions plethora purposes perspective considers primarily view origin potential impact processing certain parties involved subject well society large ethical legal point view important identify standards governance typically however parties involved enforce others play even significant role central distinction context personal non-personal since determines whether provisions protection law apply general standards governance opinion ethics commission responsible governance guided following ethics principles ●foresighted responsibility possible future cumulative effects network effects effects technological developments changing actor constellations taken account gauging potential impact collecting processing forwarding individuals general ●respect parties involved parties involved generation – whether subjects different role – relation respected ●data sharing good non-rivalrous resource duplicated parallel many different individuals many different purposes thereby furthering good ●fit-for-purpose quality responsible includes ensuring high level quality fit relevant purpose ●risk-adequate level security vulnerable external attacks difficult recover gone astray standard security applied therefore commensurate potential risk inherent situation question ●interest-oriented transparency controllers prepared account data-related activities requires appropriate documentation transparency necessary corresponding liability regime place 2 17 executive summar corresponding obligations self-determined navigation society parties able enforce certain data-related others first foremost among relating individual ’ personal derive informational selfdetermination enshrined fundamental guaranteed applicable protection law self-determination society includes self-determined economic exploitation one ’ includes selfdetermined manage ment non-personal non-personal generated one ’ devices ethics commission takes view principle self-determination society applies companies legal entities – least extent – groups persons collectives often generated contributions different parties acting different roles – subject owner data- generating device yet another role opinion ethics commission contributions generation lead exclusive ownership rather dataspecific co-determination participation turn lead corresponding obligations part parties extent individual entitled kind shape take depends following general factors nature scope party ’ contribution generation b weight party ’ legitimate interest granted c weight possibly conflicting interests part party third parties taking account potential compensation arrangements e. g. protective measures remuneration interests general e balance power parties involved.data allow holders pursue number different goals particular following ●requiring controller desist require erasure ●requiring controller rectify ●requiring controller grant access full portability ●requiring economic share profits derived help type desistance rectification access economic share exists separate set conditions defining e. g. counts party ’ legitimate interest granted determining whether party require desistance particular key considerations include potential harm associated said circumstances party question contributed generating potential harm relevant request made rectify benchmark lower respect party requests access graded spectrum interests count legitimate interest granted access particularly relevant within existing value creation narrowly defined conditions party independent claim economic share profits derived others granted subjects ’ general protection regulation gdpr particularly important manifestation aimed specifically protecting natural persons pertain extent standardised manifestation given hinge qualification personal considering principles ethics commission wishes submit following key recommendations action 18 executive summar standards personal 1 ethics commission recommends measures taken ethically indefensible uses examples uses include total surveillance profiling poses threat personal integrity targeted exploitation vulnerabilities addictive designs dark patterns methods influencing political elections incompatible principle democracy vendor lock-in systematic consumer detriment many practices involve trading personal 2 protection law well branches legal including general private law unfair commercial practices law already provide range instruments prevent ethically indefensible uses however spite widespread impact enormous potential harm little done date terms harnessing power instruments particularly market giants various factors contributing enforcement gap tackled systematically 3 well steps make front-line players e. g. supervisory authorities aware existing options urgent need legislative framework force fleshed clearly strengthened certain areas examples recommended measures include blacklisting data-specific unfair contract terms fleshing data-specific contractual duties fiduciary nature data-specific torts blacklisting certain data-specific unfair commercial practices introduction much detailed legislative framework profiling scoring trading 4 order allow supervisory authorities take action effectively authorities need significantly better material resources attempts made strengthen formalise cooperation different protection authorities germany thereby ensuring uniform coherent application protection law attempts fail consideration given centralisation market-related supervisory activities within federal-level authority granted broad mandate cooperates closely specialist supervisory authorities authorities land level remain responsible supervisory activities relating sector however 5 ethics commission believes “ ownership ” i.e exclusive modelled ownership tangible assets intellectual property would solve problems currently facing would create problems instead recommends refraining recognition advises granting subjects copyrightlike economic exploitation respect personal might managed collective societies 6 ethics commission argues referred “ counter-performance ” provided exchange service even though term sums issue nutshell helped raise awareness among general regardless protection authorities court justice ultimately take regard prohibition gdpr “ tying ” “ bundling ” consent provision service ethics commission believes consumers offered reasonable alternatives releasing commercial e. g. appropriately designed pay options 19 executive summar 7 stringent requirements limitations imposed personalised risk assessment e. g. “ black ” premiums certain insurance schemes particular processing intrude intimate areas private life causal relationship risk difference individual prices charged basis personalised nonpersonalised risk assessments exceed certain percentages determined stringent requirements respect transparency nondiscrimination protection third parties 8 ethics commission advises federal government consider issues falling heading “ inheritance ” settled federal court justice ’ ruling ephemeral spoken word replaced many situations communications recorded less entirety possibility records handed deceased ’ heirs adds whole dimension privacy risk range mitigating measures taken including imposition obligations service providers quality assurance standards estate planning services national regulations post-mortem protection 9 ethics commission recommends federal government invite social partners work towards common legislative provisions adopted view stepping protection employee based examples best practices existing collective agreements concerns individuals non-standard forms employment taken account process 10 view benefits could gained digitalising healthcare ethics commission recommends swift expansion infrastructures sector expansion range quality digitalised healthcare services include measures better allow patients exercise informational self-determination measures could taken respect include introduction roll-out electronic health record building participatory process involves relevant stakeholders procedures reviewing assessing medical apps insurer-funded consumer-funded health markets 11 ethics commission calls action significant enforcement gap exists regard statutory protection children young people sphere particular attention paid mandatory provision technologies including effective identity management default settings guarantee reliable protection children young people familyfriendly i.e neither demand much parents guardians allow even encourage excessive surveillance home environment 12 standards guidelines handling personal vulnerable care-dependent persons introduced provide greater legal certainty professionals care sector time consideration given clarifying relevant legal provisions living wills include dispositions regard future processing personal far processing require care-dependent person ’ consent e. g. dementia patients provide legally valid consent 20 executive summar 13 ethics commission believes number binding requirements introduced ensure privacy-friendly design products services principles privacy design privacy default gdpr imposes controllers already put practice upstream manufacturers service pro viders requirements would particularly important regard consumer equipment con text standardised icons introduced consumers able take informed purchase decisions 14 action taken number different levels provide manufacturers adequate incentives implement features privacy-friendly design cludes effective legal remedies pursued parties along entire distribution chain ensure manufacturers held accountable inadequate application principles privacy design privacy default consideration given particular requirements built tender specifications procure ment guidelines bodies conditions funding programmes applies privacy-friendly product including training algorithmic 15 debates protection tend quite rightly centre around natural persons important ignore fact companies legal persons granted protection almost limitless ability pool together individual pieces means obtaining comprehensive picture company ’ internal operating procedures passed competitors negotiating partners parties interested takeover bid poses variety threats – inter alia sovereignty germany europe – view significant volumes flow third countries many ethics commission ’ recommendations action therefore apply mutatis mutandis basis legal persons ethics commission believes action taken federal govern ment step level data-related protection afforded companies .improving controlled access personal 16 ethics commission identifies enormous potential purposes serve interest e. g. improve healthcare provision protection law currently stands acknowledges potential principle granting far-reaching privileges processing personal purposes uncertainty persists however particular regards scope so-called privilege secondary scope counts “ ” context product ethics commission believes appropriate clarifications law necessary rectify situation 17 fragmentation research-specific protection law within germany among member states represents potential obstacle datadriven ethics commission therefore recommends research-specific regulations harmonised federal land level different legal within introducing notification requirement research- specific national law could bring improvement could establishment clearing house cross-border projects 18 case involving particularly sensitive categories personal e. g. health guidelines produced researchers obtain consent legally compliant manner innovative consent models promoted explicitly recognised law potential options include roll-out consent assistants recognition so-called meta consent alongside endeavours clarify scope privilege secondary 21 executive summar 19 ethics commission supports principle move towards “ healthcare ” healthcare provision continuously improved making systematic quality-oriented health generated day-to-day basis keeping principles evidence-based medicine progress made direction however greater efforts made time protect subjects significant potential discrimination exists sensitive categories might involve prohibiting exploitation beyond defined range purposes 20 procedures standards anonymisation pseudonymisation central efforts improve controlled access formerly personal legal presumption compliance standard achieved longer qualify personal “ appropriate safeguards ” provided respect subject ’ would improve legal certainty long way measures accompanied rules – pain criminal penalty – prohibit de-anonymisation anonymised e. g. becomes available would allow re-identification subjects reversal pseudonymisation absence narrowly defined grounds field synthetic shows enormous promise funding funnelled area 21 fundamentally speaking ethics commission believes innovative management trust schemes hold great potential provided designed robust suited real-life applications compliant protection law broad spectrum models falls heading ranging dashboards perform purely technical function privacy manage ment tools pmt comprehensive consent management services personal man agement services pims underlying aim empower individuals take control personal overburdening decisions beyond capabilities ethics commission recom mends field management trust schemes identified funding priority wishes make adequate protection legitimate interests parties involved require additional regulatory meas ures level regulatory measures would need secure central functions without operators since scope action would otherwise limited hand necessary protect individuals parties assume acting interests reality prioritising financial aims interests others event feasible method protection found trust schemes could serve vitally important mediators protection interests economy interests 22 far portability enshrined article 20 gdpr concerned ethics commission recommends industry-specific codes conduct standards formats adopted given underlying purpose article 20 gdpr make straightforward change provider allow providers access easily important evaluate carefully market impact existing portability analyse potential mech anisms prevented small number providers increase yet market power findings evaluation available expansion scope example cover provided subject real- time porting would seem premature advisable 23 certain sectors example messenger services social networks interoperability interconnectivity obligations might help reduce market entry barriers providers obligations designed asymmetric basis i.e stringency regulation increase step company ’ market share interoperability interconnectivity obligations would prerequisite building strengthening within europe certain basic services society 22 executive summar debates around access nonpersonal 24 access companies appropriate non- personal appropriate quality key factor growth economy order benefit enhanced access however stakeholders sufficient degree data-awareness skills necessary make access proves disproportionately advantageous stakeholders already built largest reserves best infrastructures hand ethics commission therefore wishes stress factors referred always receive due attention discussing whether improve access keeping asisa principle awareness – skills – infrastructures – stocks – access 25 ethics commission therefore supports efforts already initiated level promote improve infrastructures broadest sense term e. g. platforms standards application program ming interfaces elements model contracts support centre recommends federal govern ment efforts continue matched corresponding efforts national level would advisable set ombudsman ’ office federal level provide assistance support relation nego tiation access agreements dispute settlement 26 ethics commission ascribes enormous impor tance holistically conceived sustainable strategic economic policy outlines effective methods preventing exodus innovative companies acquisition third-country compa nies excessive dependence third-country infrastructures e. g. server capacities balance struck context much-needed international cooperation networking one hand resolute assumption responsibility sustaina -ble security prosperity europe backdrop ever-evolving global power dynamic 27 perspective boosting economy ethics commission benefit introducing exclusive “ ownership ” “ producer ” instead recommends affording limited third-party effects contractual agreements e. g. restrictions utilisation onward transfer recipient third-party effects could modelled regime protection trade secrets ethics commission recommends adoption legislative solutions enabling companies cooperate example using trust schemes without running afoul anti-trust law “ partnerships ” 28 accumulated existing value creation e. g. production distribution chains often enormous commercial significance inside outside value creation many cases however provisions access appear contractual agreements concluded within value creation unfair and/or inefficient lacking entirely certain cases contractual agreement efforts therefore made raise awareness among businesses sectors far outside commonly perceived “ economy ” provide practical guidance support e. g. model contracts 29 ethics commission furthermore recommends cautious adaptations current legislative framework first stage process make explicit reference section 311 german civil code bürgerliches gesetzbuch bgb special relationship exists party contributed generation value creation controller clarifying parties certain quasi-contractual duties fiduciary nature duties normally include duty enter negotiations fair efficient 23 executive summar access arrangements consideration given whether additional steps taken could range blacklisting particular contract terms b2b transactions formulating default provisions contracts introducing sector- specific access 30 ethics commission believes open govern ment ogd concepts hold enormous potential recommends concepts built promoted recommends series measures promote shift mindset among authorities something yet fully taken place make easier practice share basis ogd concepts measures include establishment relevant infrastructures e. g. platforms harmonisation improvement existing legal framework currently fragmented sometimes inconsistent 31 nevertheless ethics commission identifies degree tension efforts promote ogd relying principles “ open default ” “ open purposes ” efforts enhance protection protection trade secrets legally enshrined concepts “ privacy default ” ethics commission submits cases doubt priority given duty protecting individuals companies entrusted state often without given choice matter e. g. tax state deliver duty implementing range different measures include technical well legal safeguards misuse 32 particular would beneficial develop standard licences model terms conditions public- sector sharing arrangements make mandatory least sector-specific basis standard licenses model terms conditions include clearly defined safeguards third parties affected access arrangement provision made way ultimately harms interests still greater accumulation market power part big players would likely undermine competition taxpayer pay twice 33 regards open-data concepts private sector priority given promoting supporting voluntary data-sharing arrangements consideration given improvement infrastructures e. g. platforms broad range potential incentives might include certain privileges context tax breaks procurement funding programmes licensing procedures statutory access corresponding obligations grant access considered fall-back options measures fail deliver desired outcomes 34 generally speaking ethics commission believes cautious approach taken introduction statutory access ideally developed sector-by-sector basis sectors level demand analysed include media mobility energy sectors case statutory access even disclosure obligation introduced full impact assessment needs carried examining weighing possible implications include implications protection protection trade secrets investment decisions distribution market power well strategic interests german companies compared companies third countries 35 ethics commission recommends considering enhanced obligations private enterprises grant access interest public-sector purposes business-to-government b2g cautious sector-specific approach however recommended respect well algorithmic algorithms perspective focuses architecture data-driven algorithmic dynamics ’ impacts individuals society ethical legal discourse area typically centres around relationship humans machines particular automation outsourcing increasingly complex operational decision- making processes “ autonomous ” enabled algorithms perspective differs perspective processed might connection whatsoever persons affected particular individuals suffer ethically indefensible implications even e. g. train algorithmic nonpersonal current debates “ algorithmic oversight ” liability central importance respect general standards algorithmic ethics commission distinguishes three different levels algorithmic involvement decision-making based distribution tasks machine specific case question algorithm-based decisions decisions based either whole part obtained using algorithmic calculations b algorithm-driven decisions decisions shaped outputs algorithmic way ’ factual decision-making abilities capacity self-determination restricted c algorithm-determined decisions trigger consequences automatically provision made decision individual case.in opinion ethics commission following principles observed ensure responsible algorithmic ●human-centred design centred around uses affected decisions prioritise fundamental freedoms basic needs physical emotional well-being skills ●compatibility core societal values process design take account ’ impact society whole particular effects democratic process citizen- centred nature state action competition future work sovereignty germany europe ●sustainability considerations relating availability skills participation environmental protection sustainable resource management sustainable economic activity becoming increasingly important factors design algorithmic ●quality performance algorithmic work correctly reliably goals pursued help achieved ●robustness security robust secure design involves making secure external threats protecting humans environment negative impacts emanate ●minimisation bias discrimination decision- making patterns upon algorithmic based source systematic bias cause discriminatory decisions 3 25 executive summar ●transparent explainable comprehensible vitally important ensure users algorithmic understand function explain control parties affected decision provided sufficient exercise properly challenge decision necessary ●clear accountability structures questions allo cation responsibility accountability including possible liability arising algorithmic unambiguously resolved criticality level criticality algorithmic dictates specific requirements meet particular regard transparency oversight criticality determined assessing algorithmic ’ potential harm basis two-pronged investigation likelihood harm occur severity harm severity harm could potentially sustained example result mistaken decision depends significance legally protected interests affected privacy fundamental life physical integrity prohibition discrimination level potential harm suffered individuals including non-material harm loss utility hard calculate monetary terms number individuals affected total figure harm potentially sustained overall harm sustained society whole go well beyond straightforward summation harm suffered individuals likelihood harm sustained influenced properties question particular role algorithmic components decision-making process complexity decision effects decision reversibility effects severity likelihood predicted harm contingent whether algorithmic operated state private enterprises particularly business context market power wielded ’ operator.in conclusion ethics commission wishes make following recommendations action basis principles risk-adapted regulatory approach 36 ethics commission recommends adopting risk-adapted regulatory approach algorithmic principle underlying approach follows greater potential harm stringent requirements farreaching intervention means regulatory instruments assessing potential harm sociotechnical whole considered words components algorithmic application including people involved phase – example training – implementation application environment evaluation adjustment measures 37 ethics commission recommends potential algorithmic harm individuals and/ society determined uniformly basis universally applicable model purpose legislator develop criteria-based assessment scheme tool determining criticality algorithmic scheme based general ethical legal principles presented ethics commission 38 among things regulatory instruments requirements apply algorithmic include corrective oversight mechanisms specifications transparency explainability comprehensibility ’ results rules allocation responsibility liability using 26 executive summar 39 ethics commission believes useful first stage determining potential harm algorithmic distinguish five levels criticality applications fall lowest levels level 1 associated zero negligible potential harm unnecessary carry special oversight impose requirements general quality requirements apply products irrespective whether incorporate algorithmic 40 applications fall level 2 associated potential harm regulated as-needs basis regulatory instruments connection include ex-post controls obligation produce publish appropriate risk assessment obligation disclose supervisory bodies enhanced transparency obligations access individuals affected 41 addition introduction licensing procedures justified applications fall level 3 associated regular significant potential harm applications fall level 4 associated serious potential harm ethics commission believes applications subject enhanced oversight transparency obligations extend way publication factors influence algorithmic calculations weightings pool algorithmic decision-making model option “ always-on ” regulatory oversight via live interface required 42 finally complete partial ban imposed applications untenable potential harm level 5 43 ethics commission believes measures proposed implemented regulation algorithmic enshrining general horizontal requirements regulation algorithmic eu-asr horizontal regulation incorporate fundamental requirements algorithmic sytems ethics commission developed particular group together general substantive rules – informed concept criticality – admissibility design algorithmic transparency individuals affected organisational technical safeguards supervisory institutions structures horizontal instrument fleshed sectoral instruments member state level concept criticality serving guiding framework 44 process drafting eu-asr recommended incorporate debate best demarcate respective scopes regulation gdpr number factors taken account respect firstly algorithmic pose specific risks individuals groups even involve processing personal risks relate assets ownership bodily integrity discrimination secondly regulatory framework introduced future horizontal regulation algorithmic need flexible risk-adapted current protection regime 27 executive summar instruments 45 ethics commission recommends introduction mandatory labelling scheme algorithmic enhanced criticality level 2 upwards mandatory scheme kind would oblige operators make whether i.e extent algorithmic regardless criticality operators always obliged comply mandatory labelling scheme risk confusion machine might prove problematic ethical point view 46 individual affected decision able exercise “ meaningful logic involved well scope intended consequences ” algorithmic cf gdpr respect fully automated situations involve kind profiling regardless whether decision taken basis later line expanded future apply algorithm-based decisions differing levels access decisions according criticality measures require clarification certain legislative provisions widening regulatory scope level 47 certain cases appropriate ask operator algorithmic provide individual explanation decision taken addition general explanation logic procedure scope main objective provide individuals affected decision comprehensible relevant concrete ethics commission therefore welcomes work carried banner “ explainable ” efforts improve explainability algorithmic particular self-learning recommends federal government fund area 48 view fact certain sectors society whole affected well individual members particular parties individually affected algorithmic entitled access certain types likely kind would granted primarily journalistic purposes order take due account operator ’ interests would need accompanied adequate protective measures ethics commission believes consideration given granting unconditional access certain circumstances particular algorithmic serious potential harm level 4 state 49 appropriate reasonable impose legal requirement operators algorithmic least potential harm level 2 upwards produce publish proper risk assessment assessment kind cover processing non-personal well risks fall heading protection particular appraise risks posed respect self- determination privacy bodily integrity personal integrity assets ownership discrimination encompass underlying logic model methods gauging quality fairness model accuracy example bias rates statistical error overall certain sub-groups exhibited forecasting/category formation 28 executive summar 50 provide controllers processors greater legal clarity work done terms fleshing requirements document log sets models level granularity retention periods intended purposes addition operators sensitive applications obliged future document log program runs software cause lasting harm sets models described way comprehensible employees supervisory institutions carrying oversight measures regards origin sets way pre-processed example optimisation goals pursued using models 51 operators required standard- setting guarantee minimum level quality technical mathematical-procedural perspective procedural criteria imposed ensure algorithmically derived results obtained correct lawful manner purpose quality criteria could imposed particular regards corrective control mechanisms quality security example would appropriate impose quality criteria relationship algorithmic processing outcomes obtain outcomes 52 ethics commission believes necessary first step clarify flesh greater detail scope legal consequences article 22 gdpr relation algorithmic context decision-making second step ethics commission recommends introduction additional protective mechanisms algorithm-based algorithm-driven decision-making since influence real-life settings almost significant algorithm-determined applications prohibitory principle followed date article 22 gdpr replaced flexible risk-adapted regulatory framework provides adequate guarantees regards protection individuals particular profiling concerned options individuals take action mistakes made jeopardised 53 consideration given expanding scope anti-discrimination legislation cover specific situations individual discriminated basis automated analysis automated decision-making procedure addition legislator take effective steps prevent discrimination basis group characteristics qualify protected characteristics law discrimination often currently qualify indirect discrimination basis protected characteristic 54 case algorithmic regular significant level 3 even serious potential harm level 4 would useful – supplement existing regulations – covered licensing procedures preliminary checks carried supervisory institutions interests preventing harm individuals affected certain sections population society whole institutions 55 ethics commission recommends federal government expand realign competencies existing supervisory institutions structures necessary set ones official supervisory tasks powers primarily entrusted sectoral supervisory authorities already built wealth expert knowledge relevant sector ensuring competent authorities financial technical resources need particularly important factor respect 29 executive summar 56 ethics commission recommends federal government set national centre competence algorithmic centre act repository technical regulatory expertise assist sectoral supervisory authorities task monitoring algorithmic ensure compliance law 57 ethics commission believes initiatives involving technical statistical quality standards test procedures audits differentiated according critical application areas necessary worthy support test procedures kind – provided designed adequately meaningful reliable secure – make vital contribution future auditability algorithmic 58 opinion ethics commission particular attention paid innovative forms coregulation self-regulation alongside complement forms state regulation recommends federal government examine various models co-regulation self-regulation potentially useful solution certain situations 59 ethics commission believes option worth considering might require operators law inspired “ comply explain ” regulatory model sign declaration confirming willingness comply algorithmic accountability code independ ent commission equal representation – free state influence – could set develop code kind would apply binding basis operators algorithmic appropriate involvement civil society representatives drafting code guaranteed 60 voluntary mandatory evidence protective measures form specific quality seal serve guarantee consumers algorithmic question reliable time providing incentive developers operators develop reliable 61 ethics commission takes view companies authorities operating critical algorithmic obliged future appoint contact person way companies specific currently obliged appoint protection officer communications authorities routed contact person subject duty cooperation 62 ensure official audits algorithmic take due account interests civil society companies affected suitable advisory boards set within sectoral supervisory authorities 63 opinion ethics commission technical standards adopted accredited standardisation organisations generally useful measure occupying intermediate state regulation purely private self-regulation therefore recommends federal government engage appropriate efforts towards adoption standards 64 granting competitors competition associations consumer associations file action important feature german legal landscape many years could play key role civil society oversight algorithmic particular private kind could allow civil 30 executive summar society players legitimate mandate enforce compliance legal provisions area contract law fair trading law anti-discrimination law without needing rely authorities take action without needing wait individuals authorise special topic algorithmic media intermediaries 65 given specific risks posed media intermediaries act gatekeepers democracy ethics commission recommends options examined countering risks regard influencing legislation → recommendation 43 whole gamut risk mitigation measures considered extending ex-ante controls e.g form licensing procedure 66 national legislator constitutional obligation protect democratic dangers free democratic pluralistic formation opinions created providers act gatekeepers establishing binding normative framework media ethics commission believes small number operators concerned obliged algorithmic allow users least additional option access unbiased balanced selection posts embodies pluralism opinion 67 federal government consider measures take due account risks typically encountered media sector respect media intermediaries respect providers act gatekeepers whose associated lower potential harm measures might include mechanisms enhancing transparency example ensuring available technical procedures select rank news stories introducing labelling obligations social bots establishing post countering responses timelines algorithmic state bodies 68 state interests citizens make best available technologies including algorithmic exercise particular prudence actions view obligation preserve fundamental act role model general rule therefore algorithmic authorities assessed basis criticality model particularly sensitive entailing least comprehensive risk assessment 69 areas law-making dispensation justice algorithmic peripheral tasks particular algorithmic undermine functional independence courts democratic process way contrast enormous potential exists algorithmic connection administrative tasks particular relating provision services benefits legislator take due account fact giving green light greater number partially fully automated administrative procedures cautious consideration therefore given expanding scope section 35a german administrative procedures act verwaltungsverfahrensgesetz vwvfg couched overly restrictive terms corresponding provisions statutory law measures accompanied adequate steps protect citizens 31 executive summar 70 decisions taken state basis algorithmic still transparent still possible provide justifications necessary clarify expand existing legislation freedom transparency order achieve goals furthermore algorithmic negate principle decisions made authorities generally justified individually contrary principle impose limits overly complex algorithmic finally greater priority accorded opensource solutions since latter significantly enhance transparency government actions 71 ethical point view general non-compliance rules regulations time however automated “ total ” enforcement law raises number different ethical concerns general rule therefore designed way override technical enforcement specific case balance struck potential transgression automated perhaps preventive enforcement measure times meet requirements proportionality principle liability algorithmic 72 liability damages alongside criminal responsibility administrative sanctions vital component ethically sound regulatory framework algorithmic already apparent today algorithmic pose challenges liability law currently stands inter alia complexity dynamism growing “ autonomy ” ethics commission therefore recommends current provisions liability law undergo in-depth checks necessary revisions scope checks revisions restricted basis narrowly defined technological features machine 73 proposal future legal personality would granted high-autonomy algorithmic would liable damages “ electronic person ” pursued far concept protagonists based purported equivalence machine ethically indefensible far boils introducing type company company law fact solve pertinent problems 74 way contrast harm caused autonomous way functionally equivalent employment auxiliaries operator ’ liability making correspond otherwise existing vicarious liability regime principal auxiliaries cf particular section 278 german civil code example bank uses autonomous check creditworthiness customers liable towards least extent would employee perform task 75 debate currently stands appears highly likely appropriate amendments need made product liability directive dates back 1980s connection established product safety standards addition certain changes need made rules relating fault-based liability and/ bases strict liability need introduced case necessary determine liability regime appropriate particular types products services exact shape regime take depending criticality relevant algorithmic consideration given innovative liability concepts currently developed level path ethics commission examined great many different questions course work discussions questions raised ones turn alone serve indicate opinion serve one many building blocks larger edifice debate ethics law continue many years come ethics commission takes view important remember ethics law democracy serve shaping force change broader sense specifically field achieve goal interdisciplinary discourse politics society required care taken ensure rules regulations adopted open enough retain regulatory clout ability adapt even face fast-paced changes technologies business models rules regulations enforced effectively means appropriate instruments procedures structures latter make possible intervene promptly response infringements undesirable developments.in global contest future technologies germany europe confronted value models society cultures differ widely ethics commission supports “ path ” followed date defining feature technologies consistent alignment values fundamental particular enshrined union ’ charter fundamental council europe ’ convention protection fundamental freedoms ethics commission believes state particular responsibility develop enforce ethical benchmarks sphere reflect value order deliver promise citizens act political economic strength global stage excessive dependence others turns nation rule taker rather rule maker resulting citizens nation subject resulting citizens nation subject requirements imposed players elsewhere world private corporations part exempt democratic legitimacy oversight embarking efforts safeguard sovereignty germany europe long term therefore politically far-sighted necessity expression ethical responsibility 4 part introduction 34 part ntroduction guiding motifs society experiencing profound changes brought digitalisation innovative data-based technologies benefit us individual wider societal levels well potentially boosting economic productivity promoting sustainability catalysing huge strides forward terms scientific progress time however digitalisation poses risks fundamental freedoms raises wide range ethical legal questions centring around two wider issues role want technologies play design want ensure transformation serves good society whole society elected political representatives engage debate shape data-based technologies including germany ’ federal government set ethics commission datenethikkommission 18 . given one-year mandate develop ethical benchmarks guidelines well specific recommendations action aiming protecting individual preserving social cohesion safeguarding promoting prosperity age starting point federal government presented ethics commission number key questions clustered around three main topics algorithm-based decision-making adm opinion ethics commission however merely one among many possible variants algorithmic much common terms ethical legal questions raises mind ethics commission structured work two different headings algorithmic broader sense .in preparing opinion ethics commission inspired following guiding motifs ●ensuring human-centred value-oriented design ●fostering skills critical reflection world ●enhancing protection individual freedom self- determination integrity ●fostering responsible utilisation compatible good ●introducing risk-adapted regulation effective oversight algorithmic ●safeguarding promoting democracy social cohesion ●aligning strategies sustainability goals ●strengthening sovereignty germany europe 35 1. mission basic understanding 1. mission basic understanding society experiencing profound changes brought digitalisation innovative data-based technologies benefit us individual wider societal levels well potentially boosting economic productivity promoting sustainability catalysing huge strides forward terms scientific progress cases already happened transformation offers tremendous opportunities countries particular germany closely networked high-tech economy means german companies coming increasing competitive pressure international market time already becoming apparent digitalisation poses risks fundamental freedoms raises wide range ethical legal questions centring around two wider issues role want technologies play design want ensure transformation serves good individuals society whole society elected political representatives engage debate shape design data-based technologies including 18 federal government set ethics commission datenethikkommission named 16 members → annex 2 christiane wendehorst christiane woopen appointed co-spokespersons ethics commission given one-year mandate develop ethical benchmarks guidelines aiming protecting individual preserving social cohesion safeguarding promoting prosperity age asked put forward specific recommendations action suggestions possible legislation view allowing ethical guidelines observed implemented supervised starting point federal government presented ethics commission number key questions → annex 1 clustered around three main topics algorithm-based decision-making ii iii context “ ” understood ethics commission catch-all term technologies related applications based methods involve machine processing potentially large heterogeneous sets complex procedure mimics results obtained procedure applied automated way important methods underpinning one aspect much wider computer science landscape include sub-symbolic pattern recognition machine computer-based knowledge representation knowledge engineering turn encompasses heuristic search methods inference techniques action planning ethics commission however believes would wrong restrict ethical legal debate alone merely one among many possible variants algorithmic thus represents subset field types algorithmic share number features give rise ethical problems meaning regulations focused alone would tackle part problem feature self-learning foreground brings specific challenges due consideration given risk assessment stage time however many features besides self-learning require special attention following arguments therefore relate algorithmic kinds applications rarely based single algorithm examining algorithms isolation rarely meaningful ethical appraisal based sociotechnical whole words components algorithmic application including people involved phase – example training – implementation application environment evaluation adjustment measures 36 part ntroduction 2. working method ethics commission met monthly basis discussed examples cases technologies range different sectors analysed terms involved ethical legal issues raised findings obtained work fundamental debates made possible identify overarching topics questions starting point ethical appraisal framework drafting specific recommendations future political legislative action early response policy paper federal government ethics commission put forward two specific recommendations points included strategy recommendations taken federal government ethics commission issued another recommendation calling roll-out electronic health record building participatory process.1 ethics commission involved two conferences first took place 7 federal ministry justice consumer protection bundesministerium der justiz und für verbraucherschutz centred around issue “ selfdetermination external determination age ” second – international round table title “ towards ethical shaping future ” – held 9 federal ministry interior building community bundesministerium des innern für bau und heimat events allowed ethics commission engage in-depth discussions experts stakeholders well members interested citizens.2 1 documents available ethics commission ’ website www.datenethikkommission.de 2 conferences including video recordings found ethics commission ’ website www.datenethikkommission.de .on 14 federal government ’ digitalklausur exchange views took place federal chancellor members federal government two co-spokespersons ethics commission ad-hoc discussions held individual members federal government addition ethics commission organised expert hearings consultation meetings institutions bodies working related topics including study commission “ ” commission experts competition law 4.0 federal government ’ council advisory council consumer affairs many one defining features ethics commission work advisory activities fully independent free external political influence viewpoints outlined report reflect either personal opinions expressed ethics commission ’ individual members opinions emerged internal discussions within institutional members ethics commission adopted recommendations report consensus 37 3. objectives scope report 3. objectives scope report goal pursued ethics commission publishing report ethical legal framework order confront challenges posed technologies main concern ensure fundamental conditions place free democratic basic order preserved potential exists leveraged sustainability-oriented goals achieved social market economy flourish given increase volume personal collected automated methods process different purposes one main priorities ethics commission reconcile need protect individual ’ fundamental freedoms – including self-determination integrity – need promote progress prosperity safeguarding democracy shaping society fit future protecting individuals misuse discrimination guaranteeing security parties involved tasks fall squarely within remit state governed rule law effective regulations adopted institutions set purpose time however state facilitate emergence innovative business models safeguard future prosperity everyone.the ethics commission believes digitalisation – particular rapidly increasing availability complex algorithmic including – holds enormous potential technical social innovation achievement un ’ sustainable goals promising avenues action include promoting health humanising world work designing sustainable cities communities providing decent education implementing effective climate protection measures time however forget major risks face individuals society whole free democratic basic order connection extensive technologies risks include possibility high- granularity profiling using techniques online tracking voice analysis remote job interviews even diagnosis pathological mental conditions basis social media posts potential profiles exploited purpose controlling manipulating people either small individual pricing larger manipulating democratic opinion-building processes “ micro- targeting ” potential discrimination different social groups ability delegate responsibility machines factors mind ethics commission believes actively shape future way realise potentials avoiding risks ethics commission advocates multi-step approach achieving goals first step ethical reflection value activity environment shaped reaffirmation key ethical principles precepts upon society founded → part b view ethics commission key questions divided questions concentrate mainly “ perspective ” questions primarily focused algorithmic “ algorithms perspective ” two perspectives represent ethical discourses complement contingent upon reflected different governance instruments → part 38 part ntroduction section devoted perspective → part e ethics commission outlines general ethical principles governance → e 1 particular ethical principles governing obligations → e 2 serve basis series specific recommendations action regarding access → e 3 5 section devoted algorithms perspective → part f ethics commission sets general ethical requirements design algorithmic → f 2 risk-adapted regulation → f 3 instruments institutions would required implement regulations kind examined detail summarised recommendations legislator → f 4 8 shared basic understanding technical parameters relationships → part c serves essential foundation considerations kind report ends plea federal government follow “ path ” → part g per mission ethics commission ’ recommendations targeted primarily german federal government associated institutions certain points however target audience widened include stakeholders example länder municipalities institutions enterprises federal government always secondary target audience recommendations given underlying recommendation encourage support stakeholders efforts recommendations viewed context institutions rules put place international level context developments arenas cases ethics commission suggests recommendation implemented international level interpreted recommendation german federal government make vigorous future-oriented contribution debate taking place within europe across globe ethical legal principlespart b 40 part b e thical legal principles 1. fundamental value agency given fast-paced technologies including self-learning algorithmic “ ” incorporate certain functions outperform abilities humans elementary question raised whether agency poses ethically relevant value transcends considerations effectiveness efficiency inherently preferable functioning machine question pressing momentum internal logic international competition part dictated solely goal maximising economic efficiency agency derives basic value moral significance provide reasons one ’ actions decide whether perform bear responsibility actions taking action individuals develop realise full potential accordance capabilities preferences understanding meaningful life dimension meaning lends value activity could never claimed functioning technical ever means achieving goal humans set even – hypothetically speaking – humans decide algorithmic could set goals allowing would goal set humans technical therefore component activity even ethically required certain cases never possible technical replace moral dimension agency completely agency drive develop living characterised multi-dimensional nature although conceptions man espoused different cultures different faiths vary significantly incorporate dimension living moral responsibility despite differences respective answers embrace question meaning life whereas technical merely function weigh many different criteria identifying cases preference given activity algorithmic basic principle higher level effectivity prioritised regard performance certain limited functions effectiveness rule supreme place material restrictions ability humans take action form self-development take second place basic ethical dimension meaningful flourishing life individual member society example even possible cared effectively robot another care robot allowed replace element attention affection person needing care time however robots perform care-related tasks alongside humans deemed expedient makes situation significantly safer person receiving care yet effectiveness gains technical take back seat entail intrusion privacy personal integrity individual example force employee modify work processes order maximise effectiveness people allowed retain subjectivity rather morphing objects “ acted upon ” machines humans morally responsible actions escaping moral dimension humans responsible goals pursue means pursue reasons dimension always taken account designing technologically shaped future time notion serve humans rather humans subservient taken incontrovertible fact germany ’ constitutional founded understanding adheres tradition europe ’ cultural intellectual history 41 b 2. relationship ethics law 2. relationship ethics law exponential technical developments relating collection deployment algorithmic increasingly shaping life every individual aspects social coexistence developments give rise far-reaching profound questions answers questions guided fundamental legal ethical principles democratic society undertakes uphold benchmarks guiding principles underpinning processes society shapes shape various sectors – economy education spaces healthcare finance transport energy – fundamentally ethical nature although liberal characterised high degree moral pluralism common ethical framework nevertheless established constitutional law especially fundamental far relationship state individual concerned significance ethical legal framework relation individual case event conflict differing values fundamental always clear-cut yet relativise binding nature fundamental importance ethical foundation community instead merely goes prove crucial importance open ongoing debate future shape society serves basis democratic decision-making processes acknowledge possibility different answers within framework constitution ethics equated one-to-one basis law words everything relevant ethical perspective enshrined legislation conversely provisions law motivated purely pragmatic considerations ethically imperative nevertheless legislation times heedful potential ethical implications live ethical standards – least requirements outlined constitutional law.the ethics commission holds view regulation necessary replaced ethical principles guidelines cases constitutionally developed principle materiality requires enactment form parliamentary legislation democratically legitimate rules enforced anyone internet governance governance society algorithmic including become increasingly normal feature daily lives lead together society develop enforce rules govern calls ongoing debate – particularly cases fundamental threat – parliamentary debate legislative initiatives given past experiences law enforcement internet sphere view experience power tends accumulated hands large corporations certain sectors markets dominated technologies systematic move away enforceable rules towards voluntary regulation would appear mistake time regulation unduly inhibit technological social innovation dynamic market growth overly rigid laws attempt regulate every last detail situation place stranglehold progress increase red tape extent innovative processes germany longer keep pace rate technological international stage hand regulatory frameworks protect fundamental freedoms create legal certainty essential first stage building within citizens companies institutions trust fact transformation society guided ethical principles addition “ toolbox-like ” nature legal options regulating matters many different levels ranging acts ordinances codes self-governance options voluntary obligations makes suitable creating framework adaptable keep technological progress 42 part b e thical legal principles however need guidance goes far beyond regulatory sphere mind many different stakeholders – professional groups companies advisory boards national regional international level – responded manifold upheavals drafting ethical codes sets guiding ethical principles cases ensuing debate ethics commission welcomes diversity stakeholders taking action number voices heard discussion process digitalisation shaped ethical way since highlights indispensability debate everyone take responsibility flourishing future lives together keeping mission assigned coalition agreement ethics commission based recommendations “ framework develop policy deal algorithms innovations ” precepts constitutional law cross-cutting ethical principles apply differing degrees areas society principles briefly outlined below.1 1 following approach ethics commission adhering basic principles endorsed group ethics science technologies ege opinion ege statement robotics “ autonomous ” available /ec.europa.eu/research/ege/pdf/ege_ai_statement_.pdf 43 b 3. general ethical legal principles 3. general ethical legal principles 3.1 dignity dignity ethical viewpoint synonymous unconditional value every enshrined “ fundamental constitutional principle ” constitutional order foundational supreme importance follows principle dignity every individual merits respect regardless attributes achievements protecting value inherent every need acquired implies beings ranked classifying across various spheres life activities “ super scoring ” labelled like object price treated accordingly fact individual rather pattern made points borne mind times situations behaviour measured measurements processed algorithmic algorithmic therefore always designed way cater ’ claim individuality acknowledging dignity involves recognising humans always “ superior ” i.e completely irrevocably subordinated technical opportunities configuration intervention localised different levels specific application principle sovereignty action upheld humans hold responsibility human/machine interactions regarded defective beings need optimised perfected machine instead algorithmic aims realising ideas objectives effectively rapidly fewer errors.protecting dignity involves ensuring relational misled nature relationship example would wrong systematically deceived thinking speaking another actually bot psychological integrity individual particularly important factor protecting dignity rules datadriven manipulative purposes particularly draw comprehensive highly granular personality profiles rules algorithmic discriminate systematically individuals groups example “ downgrading ” preventing using certain services ethically untenable reasons systematically misleading participate democratic discourse 3.2 self-determination opportunity self-determination inextricably linked dignity humans express freedom determining life goals way lead lives basis determining developing enacting essence self society takes freedom seriously put place framework within citizens develop freely respect ’ freedom despite differences example people lead self-determined life develop freedom technical restrict control avenues action without ethically meaningful reason self-determination viewed solely individualistic lens – humans relational beings whose life unfolds social interactions others basis manifold reciprocal links influences rules govern interactions shaped time cultural socionormative framework serves basis life together society shaped law democratic society especially imbalances power prevail 44 part b e thical legal principles third parties collected individual difficult becomes individual act unselfconsciously social situations even reinvent completely steps taken ensure collection evaluation practices result personal social profiles routinely created multiple locations thereby “ cementing ” particular version individual selfdetermination therefore encompasses develop alter one ’ identity possibility starting one ’ life afresh self-determination thus includes individual ’ decide perceived prevent misrepresentations another vital aspect self-determination people allowed assume responsibility justice task responsibility always lies – institutionally enshrined necessary – never machine even technical apply inferences based automated evaluations i.e whether loan granted responsibility developing using ethically sound manner lie humans important manifestation self-determination informational self-determination includes individual ’ determine collect personal purpose informational self-determination allows individual protect freedom action privacy extent deems important determine personality wants perceived treated public.in era digitalisation special importance individuals self-determined actors society goes beyond informational self-determination term self-determination refers encompasses skills needed individual determine basis interacting environment unfold personality interactive way certain circumstances include self-determined economic exploitation individual ’ assets self-determined governance non-personal example generated operating certain devices self-determination always goes hand hand accountability ethics commission takes view businesses legal persons entitled self-determination legal persons invoke concept dignity granted article 1 paragraph 1 german basic law grundgesetz gg protected framework general personality therefore barred referring associated core area personality enjoys protection article 2 paragraph 1 basic law conjunction article 19 paragraph 3 basic law however grant legal persons protected personality incorporates informational self-determination ability consumers take self-determined action conscious consumption decisions vital prerequisite optimum resource allocation maximisation good macroeconomic level erosion skills needed consumers exercise self-determination example excessive decision-making assistants associated habituation effects raises ethical questions regarding external determination freedom individuals take decisions regarding ability small number market-dominant firms exert control society 45 b 3. general ethical legal principles 3.3 privacy protection dignity self-determination closely materially linked protection privacy individual ’ determine access personal relating purpose informational self-determination section 3.2 justified supreme ethical importance ability prevent intrusions one ’ private sphere appear certainty one ’ privacy protected efforts protect dignity include legislative measures regulate responsible personal aspect privacy need preserve integrity individual ’ personal identity example integrity violated algorithmic – using collected entirely different purposes – “ calculates ” personality individual together preferences proclivities operator uses calculations purposes regardless even contrary individual ’ given different spheres society shaped data-driven technologies important us increase amount attention pay many people willing make personal available semi-public receive certain products services return wish contribute good merely telling think twice disclosing personal effective instead effective regulations adopted people rely fact responsibly steps taken prevent ethically unacceptable uses 3.4 security algorithmic give rise crucial security questions context promote jeopardise user security security relevant ethical legal perspective role plays protecting high-ranking values individual ’ physical mental health privacy security peace free equal democratic elections security relate collecting using means concept bearing protection privacy major scandals hit headlines recent years made privacy breaches personal manipulative purposes far-reaching – sometimes political – consequences consideration given physical emotional safety individual operates uses algorithmic stringent requirements apply respect e.g connection human/machine interactions robot carer example ensured neither person receiving care person providing care suffer harm terms physical mental integrity algorithmic impact environmental safety malfunctions algorithmically controlled infrastructures e.g traffic energy water supply infrastructures cause enormous amounts damage algorithmic innately unsafe causing malfunctions even functioning gateways malicious attacks manipulation even beyond inherent vulnerabilities kind forgotten algorithmic could misused harmful purposes 46 part b e thical legal principles 3.5 democracy technologies complex manner systemically relevant fundamental particular freedom expression informational self-determination confidentiality telecommunications freedom assembly association freedom occupation property democracy safeguarding diversity open societal debate free equal elections example social media sites serve low-threshold opportunity every citizen participate debates shape future principle welcomed time however risk manipulation radicalisation state take decisive action counter risks adopting rules setting institutions capable preventing undesirable developments misuse undeniable fact rise internet accompanied economic decline journalism privately funded plurality yet electronic sphere way considered valid replacement role played journalism democracy namely “ fourth estate ” “ watchdog democracy ” – i.e instance exercises control power claim truth basis systematic independent investigations criticism certain circumstances powerful media intermediaries playing gatekeeper function exert controlling influence democratic formation posing significant threat democracy – based ethical considerations provisions constitutional law – countered legislative means.education training play prominent role safeguarding free democratic basic order since influence wide variety ways participation citizens shaping society – process critical fundamental importance democracy citizens ’ understanding appraisal socially relevant interrelationships developments – ultimately – level confidence future shaped founded values education training impart technical mathematical skills skills fields ethics law economics social sciences 3.6 justice solidarity observance principles justice society institutions another fundamental factor allows us live together peace prosperity freedom democracy placed enormous influence – economic clout societal sway results former – hands small number large companies raised questions fair economic order availability large volumes digitalisation processes e.g workplace healthcare sector raises questions relating equitable access distributive justice however example relation income provision healthcare developments mean scarce resources distributed fairly mean individual groups people suffer disadvantage discrimination close link justice opportunities participation stronger participatory processes supported tools play important role promoting social innovations time technology-induced social upheavals finally questions justice arise connection situations algorithmic – particular self-learning algorithmic – means individuals groups people suffer discrimination justifying reason 47 b 3. general ethical legal principles assignment responsibility accountability indispensable feature democratic state rule law adequate level transparency explainability essential prerequisite auditing algorithmic appropriately basis real potential harm opportunities seeking legal recourse necessary holding another party accountable i.e liable available certain conditions world stands today access resources via internet fundamental requirement thus social participation part provision remit state obliged ensure citizens access up-to-date internet infrastructure anywhere country adequate extent using either mobile connection part educational remit provide citizens skills needed self-determined navigation world accurate appraisal opportunities risks internet opportunities participation promote social cohesion based fundamental attitude societal solidarity integration latter institutional framework technologies strengthen solidarity weaken destroy algorithmic certain spheres society insurance sector provision opportunities social participation care taken avoid systematic weakening solidarity cases caused subtle effects example perfectly possible data-driven differentiation unequal treatment appears plausible justified individual cases lead overall reduction solidarity certain groups people particularly reliant society ’ support.3.7 sustainability technologies offer huge potential terms efficient resource management innovative business models economic aspect generally attracts lion ’ share attention general debates topic date however less interest shown question whether technologies contribute economic sustainability consideration given issues relating ecological social sustainability un adopted 17 sustainable goals relating economic social ecological aspects apply un member states achieved 2030. technologies make easier aim pursued international telecommunication union itu “ good ” initiative example similarly german advisory council global change wissenschaftliche beirat der bundesregierung globale umweltveränderungen recently outlined vision ai-based highly granular network environmental sensors would allow unprecedented “ comprehensive real-time monitoring natural earth condition ” vital building future sustainability policy yet technologies conserve resources consume example ever-rising demand electricity reliance products certain rare earth elements available limited quantities certain countries rare-earth mining causes enormous damage environment raises questions regard sustainable economic ecological questions international justice concerning natural resources global responsibility future generations 48 part b e thical legal principles knowledge skills resources whose sustainability safeguarded technologies concomitant reduction tasks need performed humans mean individuals gain certain skills lose competences debate held responsibility towards next generation measures required preserve develop certain skills avenues independent action noted elsewhere opinion need regular comprehensive technological impact assessments assessments consider sustainability technologies various manifestations incumbent upon legislator ensure responsibility sustainability incorporated rules govern economy algorithmic example introduction obligation disclose entire energy footprint energy-hungry blockchain pursuit sustainability goals set united nations particular investments economy algorithmic allocating government funding priority given economic gains short-term nature algorithmic purposes recording monitoring environmental impacts developments optimising reducing energy resource consumption addition done promote sustainability-oriented social innovations foster social creativity participation part c technical foundations part c echnical foundations 50 data-intensive applications lasting impact living working environment economy scientific endeavours society well permanently tethered smartphones search engines daily basis rely recommendation software send text voice messages family friends regulate temperature home remotely allow navigation devices guide us one place another able series technological developments occurred past decades fundamental technical concepts underpinning developments described aim provide comprehensive account highlight key points basis identifying resulting problems starting points potential governance approaches c 1. status quo 51 1. status quo entirely fields application opened thanks improved performance miniaturisation physical components hardware store process along continual enhancements wired wireless connectivity smartphones tablets wearables gradually infiltrating workplaces homes along sensors actuators cases “ autonomous ” robots many locations internet “ always ” thanks mobile access making possible – e. g. combination various sensors smartphones geolocators gyrosensors cameras microphones etc – input text upload image video audio recordings internet time almost anywhere penetration makes possible communicate social networking sites link devices internet things iot become impossible draw dividing line analogue worlds former contains components transfer latter becoming ever widely available analogue world bringing two closer closer together creating hybrid world .data volumes increasing exponentially thanks comprehensive arrays sensors iot falling price storage capacity specialised tools needed process large volumes time accumulation much together availability high-performance hardware promoted widespread machine procedures achieved impressive results example field speech image recognition speech recognition video processing seen huge leaps forward terms performance potential boundaries reality computer-generated become blurred happens people longer sure whether talking speech bot whether watching normal video recording “ deep fake ” i.e synthesised image saying things real person never actually said part c echnical foundations 52 2. elements 2.1 2.1.1 definition properties keeping ethics commission ’ mission report concentrates machine-readable made stream binary electrical impulses transient signals exist instant e. g. control impulse technical persistent stored medium multifaceted word “ ” umbrella term encompasses enormous range manifestations example categorised basis type e. g. binary nominal ordinal metric textual process generate e. g. survey sensor sector collected e. g. financial weather function e. g. login training categorised basis level processing yet processed referred “ raw ” processed referred “ structured ” “ unstructured ” depending level structuring normalisation function input output output turn function input another represent assets multimedia units cryptocurrency distinction enormous legal significance personal non-personal data.the terms “ ” “ ” always synonymous make sense binary electrical impulses form basis i.e “ ” necessary know context semantics meaning one possible context would origin generated signal – knowing precise sensor emitted signal example term “ semantics ” refers contained certain sequence binary signals example “ 4 ” appears survey equally well represent number children household number tubes toothpaste bought past six months potential sources context semantics include metadata domain tables ontologies identifiers technical specifications supplement values whenever term “ ” remainder report familiarity context semantics always implied varying quality purpose – accurately contained therein – reflect reality accurately possible example done assigning attributes exhibited entities real life correct entities world objects many types intended express likelihood something happening reality either future types intended construct hypothetical reality others relation reality whatsoever cases pool contain errors distinction made errors cases expected unsuitable achieving specific goal example performing particular analysis e. g. insufficiently granular outdated incomplete way quality decisive importance data-driven since even perfect algorithm deliver high-quality results receives poor input i.e inaccurate inadequate quality value relevant quality dimensions quality level depend specific figure 1 c 2. elements 53 2.1.2 management pre-existing entity – created process collecting preparing processing involves many different decisions implications future example potential might gained irretrievably lost stored without context semantics careful management necessary avoid situations kind collating different sources vital ensure collation possible technical semantic perspective “ interoperability ” different sources mapped way reflects semantics cases interoperability particularly important efforts made achieve standardisation technical specifications formats descriptive metadata etc. reference play important role respect i.e standardised schemes ontologies fall remit national international institutions e. g. international classification diseases icd published 1 doug laney 3d management controlling volume velocity variety meta group inc. .2.1.3 big small term “ big ” refer separate type instead methodological approach identification relationships laney1 famously “ three vs ” – volume velocity variety – define approach still incipient stages large volumes varied potentially variety sources generated high velocity often real time special technologies needed process large volumes rapidly changing vary terms nature quality analysis large sets “ big ” particularly well suited situations necessary identify promising large number potential correlations field medical example helpful start big methods identify number likely candidates long list environmental factors might increase risk disease going perform costly high-precision experiments studies investigate candidates specific problem associated approach initially shows correlations rather causalities completely unsuitable candidates therefore identified shape perfect colour brilliant surface glossy taste — blemishes —shape — colour — surface — taste intense blemishes noneuse photographuse strawberry mousse figure 1 example different use-specific quality requirements part c echnical foundations 54 many areas volumes available never large enough allow analysis using big methods example client base small medium-sized company never exceed 200 customers number political parties one country rarely reaches three figures suitable “ small ” analytical methods extract great deal knowledge quantity matters instead decisive factor availability suitable tools make possible combine adequately high quality quantities sufficient task hand basis effective analysis 2.2 processing 2.2.1 algorithms protection point view term “ processing ” refers entire sequence actions generation extraction storage transformation actual article 4 2 gdpr way contrast mathematical technical sciences mainly deploy term refer following arguments based latter two understandings term method processing follows ipo input processing output model – enter input processed leave output form internal processing within ipo based algorithm words operational processing sequence specifies procedure series different processing steps aim achieving desired result successive transformations inputs algorithms around since time euclid specified method easily calculating greatest common divisor two natural numbers word “ algorithm ” derived name arabian mathematician al-khwarizmi formerly latinised “ algorithmi ” published collection calculation rules solving algebraic equations 830 ad thereabouts.it hard overestimate importance term “ algorithm ” modern computer science solve particular problem processing algorithm implemented correctly productively presumes knowledge algorithm many cases however algorithm ultimately deliver desired result yet known first important task find suitable algorithm many situations practical relevance processing specifications derived directly i.e deduced specialist knowledge known models legislative provisions situations understanding context yet sophisticated enough allow described using less simple mathematical formulae framework understanding absent various strategies applied identify algorithm include random chance trial error data-based inference latter approach follows principle induction – attempt made infer general rule individual cases i.e general rule found solve question assumed suitable algorithm worth remembering well several suitable rules furthermore result process induction necessarily correct result inferred individual cases partially wholly inaccurate c 2. elements 55 2.2.2 statistical inference central concern statistics drawing inferences statistical inference procedures applied sets investigate problems lack known inherent logic importantly however problems random chance forms integral part process modelled examples would estimating probability rain following day identifying highprobability prospects particular product many different statistical inference methods choose among starting various forms regression linear regression logistic regression regularisation ridge regression moving support-vector machines svm bayesian networks rule learners aprioiri cart random forest ending neural networks nn procedures suitable extracting available specifically designed solve regression questions example estimating future child based parents whereas others svm cart nn classification-type question e. g. pregnant/not pregnant dog/cat whether represent suitable means answering question depends many factors including volume type.besides methods induction statistics offers broad set tools measuring quality results estimations obtained measurements estimate potential errors monitor actual errors practice thus estimate child ’ future stated 175 cm deviation range +/– 4 cm pregnancy test yields positive result result might deemed 93 accurate pregnancy test good example need monitor two different parameters number false positives e. g. women pregnant pregnancy test positive number false negatives e. g. woman pregnant pregnancy test negative ideal statistical procedure would never result errors practice necessary weigh severity two errors decide false rate minimised worse woman find later date fact pregnant told woman told pregnant true two error types minimised time since generally case lower frequency one higher frequency balance struck look different depending context part c echnical foundations 56 quality characteristics methods basis assessing quality results even possible guarantee quality results obtained using certain methods example estimation procedures uniformly minimum-variance unbiased estimator umvue ensure best possible results obtained using available regression using umvue-based parameters supplies result stating expected child 175 cm +/− 4 cm estimator would achieved smaller error similarly support-vector machine model determined basis relevant provided model found guaranteed best possible model method question certain cases well-founded procedures assessing quality either model estimates generated using model yet developed – applies particular method class neural networks quality indications provided neural networks however measurements well model functions using previously unknown particularly important model taught using one set training assessed quality using different set test approach identify models reflect general rule learned training thoroughly cases kind referred overfitting overfitted model achieve significantly better quality values training test many statistical procedures solved analytically means question formulated mathematical equation equations solved transformations even though often requires great deal skill however direct analytical solution impossible many methods example additional conditions regularisation term applied cases made optimisation procedures approximate solution many small steps optimisation procedures necessarily optimal example calculated result local optimum global optimum one different classes problems analytical procedures optimisation procedures direct analytical solution possible tasks “ find value equation y=4 · x+3 x=3 ” solution kind possible task “ solve linear equation · x1+ b · x2+⋯+ h · x8= many parameters possible b … g h equal 0 ” .an additional regularisation term applied purpose min · x1+ b · x2+⋯+ h · x8– sum parameter ≠0 optimisation procedures find solutions c 2. elements 57 2.2.3 machine boundary traditional statistics machine term first defined mitchell,2 difficult delineate scales tip towards machine latest optimisation procedures → section 2.2.2 details solve inductive inference problems different approaches estimation “ ” strategies fall heading machine differentiated basis formulation optimisation problem solved distinction made number different procedures ●supervised supervised procedures require knowledge correct output “ ” ipo model piece input “ ” classic example inferring child output parents input necessary know child advance necessary know correct result pregnancy test actual weather follows weather forecast properties soil predicted soil analysis etc practice real challenge often lies obtaining correct output assessing quality output frequently referred label majority machine algorithms currently trained using supervised procedures 2 tom mitchell machine mcgraw-hill ●the decisive questions regard procedures formulate actual optimisation problem regularisation terms define loss function i.e errors treated different weightings levels severity e. g. comparing false negatives patients cancer incorrectly diagnosed healthy false positives healthy patients incorrectly diagnosed cancer quality labels labels contain errors several levels complexity defined labelling 1. labels whose accuracy verified collected example one correct relevant value exists physical properties speed object temperature room individual ’ date birth principle therefore values ascertained labels algorithm 2. labels whose accuracy verified collected certain cases verifiable later date 3. labels construed non-verifiable relationship real world example concepts social milieus character types developed view achieving better understanding analytical grasp humans behaviour concepts abstractions necessarily accurate representation “ truth ” far exists part c echnical foundations 58 ●reinforcement involves assessing agent ’ actions imposing punishment reward agent selects pool different actions performs whichever action selected action changes state functions optimisation input addition state change state brought agent ’ actions clearly defined reward function case supervised correct optimal solution available every input necessarily true case reinforcement instead optimisation goal pursued finding action strategies lead best end state reference optimisation problem actions deliver short-term improvements need rejected achieve goal alongside optimisation problem relevant loss factor reward function plays particularly important role strategy ●unsupervised involves searching structures particular quantity input need correct structures known reward function exist precise definition structure searched required however example search carried clusters i.e groups imposing requirement difference points cluster minimised difference clusters maximised optimisation problem unsupervised identified basis unsupervised referred mining decisive factors include procedures availability sufficient volumes adequately high quality broad scope since close approximation optimisation goal otherwise achieved many cases volume quality scope lacking way meaning avenues pursued ensure good outcomes nevertheless obtained using machine techniques identifying optimisation goal transport company planning alter bus routes reflect recent changes city operates many residents moved peripheral areas large inner-city brownfield sites developed gentrification brought huge changes composition population various districts project manager collected form passenger usage figures attempting optimise routes served city ’ needs met effectively possible without needing extra buses aware range different goals constraints could imposed optimisation using fewer buses using fewer drivers avoiding creation routes example depending optimisation problem formulated might possible achieve solution whereby densely populated neighbourhoods served bus lines compared districts anyone living suburb forced put longer travel times lower frequency buses since project manager lives affluent commuter belt personal preference optimisation strategy minimises longest travel time strategy kind would result faster connections areas city including outlying districts line manager unimpressed models believes goal transport many passengers possible puts short-distance routes plenty passengers advantage bad news longer routes four stops readily apparent decisions optimisation function social impacts many questions raised including following decide goal optimisation else say decision matter debated general necessary meaningful certain groups/neighbourhoods access legal remedies feel placed unfair disadvantage compared others c 2. elements 59 example synthetic i.e generated artificially rather collected directly real world boast several advantages real-world data.3 produced quantity particularly important dealing simulations real-world yet generated created steps taken ensure entire range possible values included synthetic e. g. order test technical would behave confronted unusual combinations quality measured necessary guaranteed individual cases properties set real-world reference retained alternatively distortions occurring sets real-world pinpointed removed order avoid discrimination set synthetic contains references persons anonymous fall within scope gdpr synthetic train algorithms test however risk algorithm influenced properties artificially generated counterpart reality separate functional testing therefore carried algorithm practical applications middle course frequently adopted form augmentation involves creating real-world greater range situations covered training stage pool enlarged relationship real-world preserved term “ augmentation ” describes process generating deviate slightly original example characteristic feature augmented images shifted rotated distorted way 3 jörg drechsler/nicola jentzsch synthetische daten innovationspotenzial und gesellschaftliche herausforderungen synthetic potential innovation societal challenges stiftung neue verantwortung available /www.stiftung-nv.de/sites/default/files/synthetische_ daten.pdf 4 john mccarthy/marvin minsky/nathaniel rochester/claude shannon proposal dartmouth summer project 1955.2.2.4 current parlance field machine – specifically neural networks – referred term often gives rise confusion machine one specific procedure falls heading “ weak ” solve well-specified tasks way contrast “ strong ” methods expected tackle single task handle broad spectrum tasks potentially without intervention despite hopes raised term “ ” machine methods capable feats historically speaking concept first appeared dartmouth proposal published back 1956 usa,4 refer broad area within field computer science decades since first emerged field marked repeated cycles unrealistic expectations followed disillusionment ivory towers made inroads economy everyday life workplaces homes latest 1970s 1980s form “ expert ” efforts germany stepped gear 1980s achievements chalked include machine techniques large number vitally important methods procedures pattern recognition knowledge representation inferences action planning user modelling applications procedures include speech image dialogue comprehension robotics multi-agent part c echnical foundations revision f_overhauledvalidation f x =y ystorage x production f x =y search f f x =ydevelopment production monitoring quality assurancerecalibration f_new60 figure 2 process model algorithm based machine ongoing monitoring assessment process starts algorithm f developed using training algorithm identified meets desired quality standards put production ensure monitoring quality control capabilities production process make possible record input x enters algorithm output leaves algorithm relevant correct value basis monitoring algorithm production environment comparison carried determine extent output algorithm reflects expected value algorithm continue operated without changes event non-critical deviations values significant deviations detected necessary re-evaluate i.e recalibrate parameters algorithm critical deviations detected algorithmic redesign recommended problem understanding comprehending humans often find difficult impossible understand methods intuitively described mathematical technical terms even goes experts field modelling even case relatively simple classification methods well understood mathematically logistic regression almost one intuit result return given set input values.neural networks image recognition good example phenomenon generally look photograph understand immediately looking looking structures input neural network intended classify photograph likely understand almost nothing means even familiar input values comprehends steps neural network necessarily understand recognition process error occurs example able determine recognition failed problem humans machines recognise objects patterns according different sets rules always easy two c 2. elements 61 problem understanding comprehending humans often find difficult impossible understand methods intuitively described mathematical technical terms even goes experts field modelling even case relatively simple classification methods well understood mathematically logistic regression almost one intuit result return given set input values.neural networks image recognition good example phenomenon generally look photograph understand immediately looking looking structures input neural network intended classify photograph likely understand almost nothing means even familiar input values comprehends steps neural network necessarily understand recognition process error occurs example able determine recognition failed problem humans machines recognise objects patterns according different sets rules always easy two part c echnical foundations 62 2.2.5 algorithmic algorithmic generally incorporates multiple algorithms work together rather single algorithm term “ component ” describe executable part different components algorithm might based different technical implementations architectural style known microservices good example important remember individual components kind might subject different regulatory requirements protection objectives addition different stakeholders might responsible different components algorithmic example suppliers operators manufacturers borne mind different requirements different sets rules might apply individual components e. g. respect quality non-discrimination freedom contract.2.3 software algorithm formulated programming language formal language rather natural language executable automated form computer program software functioning software depends processes context executed cf concepts “ stack ” contains hardware software components execution parameterisation parameters “ outside-in ” method configuring software make possible pass software ranging simple options path names complex models extensive parameterisation options generally go hand hand flexible software complex process making parameters important example software parameterised adapted different contexts relatively small amount effort without modifying source text i.e actual implementation special variants adaptive time automatically adapt context – individual using environment order guarantee improve efficiency high-quality software processes spite increasingly complex framework conditions order reduce communication problems processes model-driven approaches pursued successfully many years generic software component parameterised basis complex model using language specific application context mathematical statistical models represent special case differ domain-specific languages model explicitly specified programmed instead mathematical statistical model implicitly taught trained using → section 2.2.3 machine c 2. elements 63 2.4 hardware software executed hardware particular processors recent years processors seen steady gains performance devices seen continual reductions meaning array potential applications become ever wider moore ’ law according performance increase hundredfold every 10 years subject physical constraints however chip components become small barely bigger individual atoms fulfilling moore ’ predictions using silicon transistor material becomes increasingly costly technically challenging task researchers therefore currently investigating alternative materials graphene conjunction computing concepts photonic quantum computing question whether suitable everyday remains open however solutions focusing parallel computing established include multi-core many-core processors graphics processing units gpus order accelerate machine using bulk application-specific chips tensor processing units tpus optimised handle highly parallel addition multiplication matrices neural networks developed increasingly parallel nature computing without problems however humans find difficult identify related processor errors calculations performed hardware level almost impossible reproduce comprehend.2.5 architecture applications today rarely run single computer instead many different software components run different computers interact perform task term “ distributed ” refer method distributing work across different hardware nodes distributed made different software hardware components interact within network network nodes communicate wired wireless links wide range protocols standards exist network communication basis processing network nodes forwarding network i.e transporting nodes specifications outlining requests submitted server published application programming interface api example general rule steps taken prevent interfaces incorrectly accessed attackers infrastructures reached via internet referred cloud cloud applications accessed billions users groups related cloud applications often referred platforms many – “ big four ” “ gafa ” google apple facebook amazon “ gafam ” microsoft included – high level name recognition part c technical foundations hub 1 e. g. smart lighting hub 2 e. g. heating control router hub 3 … hub 4 … components controller smart home gateway internet network communication wireless wired64 early days internet things sent directly cloud processed large platforms way contrast increasing number solutions currently developed involve processing least pre-processing immediately close possible place collected words “ edge ” internet practice processing near collected referred edge computing distinguish situations processed cloud cloud computing pre-processing particularly important since allows minimisation communication effort creation privacy-friendly since references individuals required removed point close collected complex landscape emerged recent years incorporating internet edge computing iot entails high level interconnection making hard distinguish individual one another.the way architecture distributed designed significant impact business processes supported since acts factor decisions network nodes software runs interfaces protocols communications parties involved communications example manufacturers want hardware collected devices purpose long-term efforts improve devices choice setting communication infrastructure making user ’ infrastructure available asking user make available via interface way kind handled cooperative processes transparent agreed contractually necessary technical parameters place constraints contractual provisions governing exchange figure 3 example architecture smart home c 2. elements 65 way architecture distributed designed significant impact business processes supported since acts factor decisions network nodes software runs interfaces protocols communications parties involved communications example manufacturers want hardware collected devices purpose long-term efforts improve devices choice setting communication infrastructure making user ’ infrastructure available asking user make available via interface way kind handled cooperative processes transparent agreed contractually necessary technical parameters place constraints contractual provisions governing exchange figure 3 example architecture smart homehub 1 e. g. smart lighting hub 2 e. g. heating control router hub 3 … hub 4 … components controller smart home gateway internet network communication wireless wired blockchain distributed ledger technologies significant improvements field distributed made possible distributed ledger technologies dlt technologies involve management multiple identical copies ledger different partners instead centralised management single ledger ledger entries added copies current accuracy database confirmed consensus underlying architecture kind varies linear approaches wide range graphbased solutions depending intended purpose structure transactions consensus achieved using different methods methods outlined consensus protocols.one famous examples dlt architecture blockchain concept implementations include bitcoin ethereum blockchains store list records “ blocks ” blocks linked using cryptography meaning transaction stored implicitly confirms accuracy previous transactions i.e entire chain making extremely difficult fraudsters manipulate modifying deleting entries decentralised consensus protocol eliminates need additional instance confirms integrity transactions part multi-level governance complex ecosystems 68 part ulti -level governance comple x ecos ystems high level complexity dynamism ecosystems means challenges overcome terms regulating controlling designing ethical legal framework upon ethics commission based work implemented practice require cooperation different stakeholders interaction different governance instruments many different regulatory levels multi-level governance part examines relevant governance instruments stakeholders details provided following two parts algorithmic particular regarding interplay different instruments stakeholders 69 1. general role state 1. general role state entitled exercise ethically justified obliged comply corresponding obligations – citizens companies government agencies – actually able practice presents state wide range tasks first foremost state responsible establishing legal framework within society geared towards interest develop speed algorithmic developing infiltrating ever areas life poses major challenges legislature courts hand rulings clarifying legislative provisions state ensure regulations adopted environment kind sufficiently hard-hitting steer developments time flexible enough continue fulfilling purpose even technological parameters change statutory provisions therefore formulated technology-neutral manner innovative regulatory models developed addition appropriate infrastructural technological prerequisites place – enabling technologies institutions intermediaries complemented involvement broad gamut civil society actors ethics commission believes state play key role guaranteeing safeguarding services general interest opportunities opened society impose far-reaching educational remit state necessary identify skills required take creative yet reflective approach technologies determine framework conditions put place appropriate training offered diverse range target groups state ’ educational remit understood broad sense incorporate outreach work aim raising awareness area.furthermore state generally responsible encouraging r particularly important support r regard ethically sound technologies e.g uphold principles accountability transparency antidiscrimination extensive programmes needed ensure ethical legal principles taken account funding channelled towards programmes funding needs provided state institutions closely aligned state state put place framework legal otherwise society individuals businesses alike operate self-determined fashion basis ethical values principles individuals businesses provided adequate protection potential algorithmic harnessed shape worthwhile future germany ’ efforts direction ethically sound multi-level governance include contributions debates international level global dimension technological developments means action single nation state regulations adopted national level alone inadequate ethics commission therefore welcomes international initiatives already launched commission oecd example view ensuring future shaped basis ethical principles safeguarding sovereignty germany europe international context vitally important task regard → part g details 70 part ulti -level governance comple x ecos ystems 2. corporate self-regulation corporate responsibility responsibility mitigating risks digitalisation leveraging significant potential placed solely feet state legislators responsibility shared parties develop disseminate technologies even absence legal obligation although state shoulder responsibility least obliged protect citizens guaranteeing confidentiality integrity safeguarding fundamental self-regulation tools vitally important particularly context transformation process term “ corporate responsibility ” cdr theoretical practical level refer idea companies manufacturers operators technologies assume responsibility consequences digitalisation like corporate social responsibility csr cdr falls broader umbrella corporate responsibility case voluntary corporate activities sphere go beyond currently prescribed law actively shape world benefit society general customers employees particular aim federal ministry justice consumer protection launched initiative clarify principles concepts corporate responsibility www.bmjv.de/cdr according initiative cdr encompass many topics,1 including protection personal inclusion sphere transparency e.g relation algorithms protection innovations help achieve sustainability objectives algorithmic geared interest open security 1 corporate responsibility initiative shaping digitalization process responsibly joint platform available /www.bmjv.de/ shareddocs/downloads/de/news/artikel/100818_cdr-initiative_en.pdf __blob=publicationfile v=3 .the responsible products services central priority corporate decisions taken levels company ethical questions matter legal departments compliance officers alone instead viewed cross-cutting task integrated processes parties involved aware responsibility consider ethical values participation fairness equal treatment selfdetermination transparency negative social societal impacts digitalisation business models employees suppliers clients society whole wider environment thus minimised opportunities digitalisation offers achievement macrosocial goals leveraged applied correctly concept cdr lead improvements terms consumer protection participation sustainable economy cdr fundamentally similar corporate social responsibility csr requires companies take self-regulatory action voluntary basis internal strategies in-house industry-specific codes values therefore particularly effective way implementing cdr respect ethics commission welcomes proliferation professional ethical standards codes conduct published associations companies data-processing industry proviso standards codes help clarify exactly needs done cdr reduced metaphorical fig leaf allows companies pretend upholding principles ethics truth different 71 2. corporate self -regulation corporate responsibilit ethics commission ’ view protection impact assessment relevant circumstances carried pursuant gdpr product still stage accompanied comprehensive general societal impact assessment focused assumption foresighted responsibility including impact employees customers company particularly affected transformation process takes account long-term social effects data-driven business models might good idea companies commanding large market share set advisory panel along lines consumer customer advisory panels could consulted drawing impact assessments kind panel made representatives groups people affected relevant business model 72 part ulti -level governance comple x ecos ystems 3. education boosting skills critical reflection self-determination presupposes skills ethics commission therefore unreservedly welcomes efforts undertaken federal government consumer protection associations legal professional groups bodies raise awareness importance selfdetermined technologies smartphone settings inheritance planning provide straightforward easy-tounderstand available options well practical guidance welcomes steps taken raise awareness among consumers potential inherent provide muchneeded real opportunities risks involved economic exploitation ethics commission recommends efforts continued stepped school pupils made aware issues connected digitalisation early possible skills integrated curriculum teachers provided comprehensive training subject regular intervals way ensure generations grow become competent “ natives ” able assess opportunities risks applications take informed decisions assert effectively addition lifelong education technologies provided age groups social groups borne mind skills require basic knowledge underlying turn requires ongoing education technical mathematical subjects adequate familiarity economic legal ethical social sciences broad spectrum knowledge necessary comprehend discuss assess various opportunities risks complexity education training computer science science software particular relevance respect well basic instruction ethical legal issues in-depth teaching statistics methodology scientific theory needed particularly important ensure questions relating ethics ethics embedded discipline-specific methodological training major push area ensure ethical legal considerations incorporated earlystage discussions parties develop products services involved decisions essential first step towards achievement goals cooperation many different entities possible including government agencies bodies closely aligned state private actors federal state bundesland municipal levels challenges involved providing general skills maintaining skills long term adapting individual ’ lived experience great could never tackled successfully single centralised said key role played supervisory authorities protection authorities and/or relevant specialist supervisory authorities foundation protection consumer protection associations training providers media institutions involved media regulation large part play connection provide society technologies cast critical eye technical progress establish forums debate although government agencies remain chiefly responsible imparting skills general task realised full unless necessary civil society structures put place volunteering tech accountability journalism consumer-focused market observation ethics commission therefore recommends federal government provide long-term support establishment structures kind 73 3. education boosting skills critical reflection companies responsibility provide training staff example company attain high ethical standards employees particularly management product adequate awareness potential ethical legal issues far education training concerned questions relating ethics law included broad spectrum academic professional training routes workplace training particular attention given technical business professions view ensuring ethical legal considerations incorporated earlystage discussions parties develop products services involved decisions 74 part ulti -level governance comple x ecos ystems 4. technological developments ethical design efforts impart advanced skills general population end shifting weight responsibility away manufacturers service providers towards users least users limited opportunities grasp comprehend steps involved processing underlying business models responsibility laid first foremost feet able exert influence products services concept embodied principle ethics design ethics design appears gdpr reference protection intrusions private sphere heading protection design default aligning technologies products including services applications ethical values principles outlined good way increasing confidence products acceptance products time however design every product tailored target user groups involving user groups needs early stage product participatory product helpful respect particularly important products targeted vulnerable and/or less digitally literate user groups inclusive design including privacy-friendly default settings view protecting self-determination user groups inclusive design allows manufacturers operators meet constitutional requirement informational self-determination enshrined article 1 paragraph 1 german basic law dignity according protection contingent upon individual capabilities personal circumstances.the popular methods platforms develop technologies commonly libraries code components rarely supported requirements ethics design date components “ better ” design perspective ethics protection law best niche interest need change area compliance ethical principles general protection principles particular becomes rule rather continuing exception ethics design requires gap different communities bridged certain implications professions affected goals approach could furthered methods catalogues best-practice concepts supporting tools frameworks open-source code components platforms repositories components usable pools cases necessary prerequisite checks would make possible highlight specific properties required supply documentation needed provide opportunities exchanging know-how experience although ethics design crucial governance instrument allows process designing products processes services aligned individual interests outset provides guarantee resulting products services ethical ethical principles positive influence technological developments ethics task delegated furthermore decisions ethical principles implemented implemented example whether fairness metrics applied algorithmic metrics developers alone instead decisions negotiated context-specific basis necessary involvement parties affected 75 5. 5. although data-processing ethical design frequently developed showcased researchers gulf world real world one reasons fact technical solutions example based cryptographic mechanisms counterintuitive nature difficult many people understand conventional methods prime example identification document changes appearance every time shown making impossible “ join dots ” holder ’ observed behaviours many people attempt understand innovative technologies drawing conceptual models surrounding analogue world latter provide insufficient basis comprehending appraising added value despite advantages offered technologies terms ethics protection law unlikely become widespread gains better understanding confident many cases cross-cutting therefore interdisciplinary cooperation essential starting point understanding implications developments designing ethical cooperation kind adequately rewarded discipline-bound metrics good science many areas interdisciplinary given due recognition shift mindset occurs applies universities peer reviews expert opinions example funding funnelled towards interdisciplinary cooperation delivers results would impossible achieve within silos individual disciplines allow necessary institutional frameworks long-term career paths established.in many cases high-quality promising technical solutions already emerged sector demand solutions currently still lacking need methodologies technologies signpost route current implementation status improved state funding channelled innovation improved solutions move drawing board reality instead providing support outstanding success stories need broad-based progress field ethical design acknowledged 76 part ulti -level governance comple x ecos ystems 6. standardisation latest lawrence lessig coined aphorism “ code law ” ,2 thereby emphasising relevance technical reality obvious technical standardisation essential factor implementation legal ethical requirements bodies responsible technical standardisation communications networks established international level iso/iec ieee ietf itu etsi w3c level cen national level din prime example germany alongside specific standards bodies technical standard legal force anyone uses technical comply applicable legislation even provisions legislation run counter requirements imposed global technical standard nevertheless standardisation hugely influential terms available market wherever possible therefore steps taken avoid adopting standards infringe current legislation standardisation process often criticised lack democratic legitimacy true groups within society stand affected often deprived opportunity representative participation example non-governmental organisations civil society representatives seldom involved standardisation process generally speaking even protection authorities rarely involved standardisation technical worst-case scenario mean operation technical complies standards violates legislation another point criticism number international standards manufacturers operators supposed comply available free charge domain instead purchased 2 lawrence lessig code laws cyberspace .past standardisation efforts field security served major contributing factor addition extra security features gradual improvements level security example online banking yet snowden revelations made number services government agencies deliberately attempting weaken standards including security loopholes backdoors way safeguarding access future role technical standardisation expected gain importance coming years example result gdpr-imposed requirement take due regard state-of-the-art consequence german security act it-sicherheitsgesetz political influence exerted number different countries europe expected increase impact assessment standards currently existence still debated go beyond purely technical economic considerations expanded include ethical societal factors state ensure civil society actors protection authorities consumer protection experts spokespersons organisations representing parties affected play role standardisation process alongside stakeholders dominated date obligationsstandards algorithmic 77 7. two governance perspectives perspective algorithms perspective 7.two governance perspectives perspective algorithms perspective following two parts arguments set applied data-based algorithmic basis two different complementary approaches general ethical principles precepts basis ethics commission part b important two respects firstly guide governance measures particular view ensuring procedures collecting accessing using ethically sound secondly guide design algorithm-based process including oft-cited “ ” perspective focuses primarily “ perspective ” perspective concentrates mainly algorithmic “ algorithms perspective ” regarded competing views two sides coin instead represent two different ethical discourses complement contingent upon different ethical discourses typically reflected different governance instruments including different acts legislation perspective focuses train algorithmic basis algorithmically shaped decisions plethora purposes specifically associated context meaning semantics part c section 2.1 particular requires thinking origin potential impact processing individuals involved context semantic ethical legal perspective important identify standards governance typically however individuals assert others play even significant role central distinction context personal non-personal since determines whether granted subjects protection law apply current debates pertinent connection include “ ownership ” open example.figure 4 perspective algorithms perspective way contrast algorithms perspective focuses architecture data-driven algorithmic dynamics ’ impacts individuals society ethical legal discourse area typically centres around relationship humans machines particular automation outsourcing increasingly complex operational decision-making processes autonomous enabled algorithms perspective differs perspective subjects affected necessarily anything original training processing even attention objective requirements apply observance enforced failure comply lead liability sanctions current debate “ algorithmic oversight ” relevant important respect part e 80 part e ata provide access lead knowledge knowledge bestows influence power light capabilities automated processing exponential increase memory computing capacity access mean enormous increase power opportunities controlling important resources inherently associated certain level responsibility thus like resources lawful ethically acceptable purposes like resources impact individuals general whole always assessed yet exhibit certain characteristics differentiate resources.in following sections ethics commission therefore take specific characteristics starting point develop basis principles outlined part b without claiming exhaustive general standards governance → section 1 well corresponding obligations → section 2 set specific recommendations action relation standards personal → section 3 improvements controlled access personal → section 4 general access particular non-personal → section 5 81 e 1. general standards governance 1. general standards governance attempt identify specific principles governance start differences traditional resources oil goods unique characteristics include particular following ●data created processed distributed dynamic process interaction number different players acting different roles e. g. subject operator data- generating developer process principle never fully complete ●data non-rivalrous resource i. e. duplicated often necessary parallel multiple different players multiple different purposes ●data multifunctional across different sectors potential risks inherent depend exceptionally large extent controller ’ specific goals opportunities particular given importance effects ability combine data.1.1 foresighted responsibility special characteristics unusually dynamic nature unusually high context dependence opportunities risks associated mean particular need foresighted responsibility making decisions collecting using forwarding assessing potential impacts including risk infringing third parties particular consideration given following points ●the volume emerging collections particular cumulative effects network effects effects ●the technological means processing particular technological options available large corporations government bodies especially relation recombination decryption ●the purposes processing particular potential changes context players involved e. g. result access government agencies following corporate takeover case personal principle foresighted responsibility found standardised expression maxims minimisation storage limitation enshrined gdpr range duties gdpr need carry protection impact assessment mandatory requirements controller-to-processor contracts likewise follow principle 82 part e ata 1.2 respect parties involved always underpinned respect others acts omissions ethically unacceptable unlawful general terms violate others become acceptable lawful simply committed way using e. g. fraud criminal offence regardless whether committed otherwise generated distributed processes interaction many different players parties way involved process generation example subject owner data-generating device – ethical possibly legal perspective – entitled genuinely data-specific relation → details section 2 respected whenever respect others implies much simply avoiding intrusion legally protected spheres another party ’ copyright needed instead ethical perspective in-depth consideration data-related legitimate interests parties specifically linked therefore certain co-determination participation concerning in-depth consideration imply duties take action example granting another party access certain ways case personal principle respect third-party expressed particularly clearly principles lawfulness fairness purpose limitation enshrined gdpr gdpr sets number vested subject e. g. informed rectification restriction processing erasure portability.1.3 sharing good resources could key legally protected interests individuals e. g. health promote good particularly pursuit un ’ 17 sustainable goals relating economic social ecological aspects neglected basic principle ethical imperative resources cases would increase overall prosperity overriding conflicting interests parties particularly one special features make unique non-rivalrous resource “ wear ” even parallel many different players many different purposes duplicated almost infinite number times sharing mean player first shares least worse everyone else involved however loosely better would shared ethically responsible approach governance take fact account sharing enormously important terms safeguarding fair efficient competition time however conflicts sometimes arise principle furthering good sharing one hand principles foresighted responsibility respect parties ’ including considerations appropriate investment protection creation incentives voluntary sharing therefore always prioritised legislative requirements share exception 83 e 1. general standards governance 1.4 fit-for-purpose quality together context semantics stored regularly purports accurate possible representation reality currently stands accurate possible prediction future reality situations involve automated processing algorithmic immediately obvious everyone incorrect worthless potentially harmful soon automation comes play however common people fall prey false objectivity show foolhardy willingness rely results calculations carried using incorrect incomplete therefore likely share characteristics “ garbage garbage ” interests everyone therefore responsible governance society include efforts achieve standard quality appropriate intended purpose → part c section 2.1.1 meaning “ appropriate ” always determined context- specific basis relation quality however example important remember reflect societal preconceptions stereotypes discrimination turn influence functioning algorithmic trained using → details part f section 2.6 accurately reflect existing deficit therefore unsuitable basis purposes even high statistical quality another important factor connection across different sectors different purposes fair principle findable accessible interoperable reusable relevant context example regards storage encoding methods according principle prepared stored way findable accessible coded interoperable format way makes reusable different contexts many different players possible case personal desire achieve high level quality manifested principle accuracy enshrined gdpr 1.5 risk-adequate level security freely duplicated almost impossible recover gone astray wide range possibilities external attack many invisible outside mean vulnerable malicious attempts falsify destroy high level security commensurate relevant risk potential therefore technical perspective directly related principles foresighted responsibility respect parties involved appropriate security encompassing broad spectrum measures different levels vital prerequisite mutual trust part involved society case personal concept security manifested principle integrity confidentiality enshrined gdpr 1.6 interest-oriented transparency since party uses effectively controls gain influence power result party principle able willing account actions one reasons protection parties whose might affected even violated interest-oriented level transparency required parties entities enforcing law benefit others determine whether extent fact affected violated lodge claims case personal transparency – i. e. ensuring processing operations easy subjects understand – basic principle gdpr true principle accountability many provisions gdpr example relating documentation request access designed improve transparency foresighted responsibility respect parties involved fit-for-purpose quality riskadequate level securityinterest-oriented transparencydata sharing good84 part e figure 5 standards governance 85 e 2. corresponding obligations 2. corresponding obligations according ethical principle selfdetermination individuals merely perceived passive need protection facing actual potential threats rather self-determined actors society self-determined navigation society individuals requires individuals certain asserted others first foremost among relate individual ’ personal derive informational self-determination enshrined fundamental freedom guaranteed protection law currently force self-determination encompasses self-determined economic exploitation one ’ self-determined handling non-personal example generated operation one ’ devices ethics commission takes view principle self-determination applies companies legal entities – least extent – groups persons collectives context ethics commission believes possible identify general principles underpinning obligations go beyond protection alone.1 2.1 general principles obligations complex generation processes understood broader sense i. e. including various phases creation enhancement refinement often involve interactions different parties pursuing different goals playing different roles contribute respective roles generation process contribution party i. e. natural legal person generation relevant following true stored relates terms meaning party object associated party e. g. belonging 1 model obligations based preliminary drafts 2 3 “ principles economy ” law institute eli american law institute ali made available ethics commission preliminary drafts yet adopted either ali eli yet represent official either organisations.b generated activity party operation object e. g. sensor belongs party c generated software another component e. g. sensors created invested party situation referred i. e. situation party subject stored relates natural persons particular significance since situation gives rise informational self-determination protection enshrined constitutional law given specific characteristics inextricable link personal personality ethics commission believes contribution generation give rise exclusive ownership said beyond existing intellectual property → sections 3.3.2 5.2.4 instead contribution generation entitle party specific form co-determination participation turn impose obligations actors ethical perspective result dynamic special relationship party involved generation party controlling duration relationship vary intensity far personal concerned relationship largely determined applicable protection law ethical perspective recognition design corresponding obligations dynamic environments depend following general factors normally factors underlying relevant legal provisions obligations already substantiated law scope nature contribution generation party asserting balance power partiesweight interest granted rightcontribution generation weight conflicting interests part others interests general publicdata obligations86 part e b weight party ’ legitimate interest granted said particular require desistance access rectification economic share c weight possibly conflicting interests part party third parties taking account potential compensation arrangements e. g. protective measures remuneration interests general e balance power party asserting party.these factors interact one another described flexible interest access particularly high example compensate relatively insignificant contribution generation consideration always given general principles outlined part b order avoid situations crucially important individual interests undermined purported actual interest factors determine certain details e. g. formats deadlines protective measures financial compensation fleshed put practice includes question whether action taken upon request party asserting e. g. access claim proactively e. g. obligation publish figure 6 general factors shaping corresponding obligations 87 e 2. corresponding obligations granted subjects gdpr particularly important manifestation principles aimed specifically protecting natural persons pertains extent standardised manifestation given hinge qualification personal principles formulated applied non-personal however relate individuals legal entities collectives 2.2 clarification general principles reference typical scenarios number different goals include obliging another party desist using requiring erasure gaining access e. g. disclosure transfer full portability arranging rectified claiming economic share profits derived help 2 article 6 1 article 9 1 gdpr.2.2.1 scenarios involving desistance situations often occur party requests another party desist using certain way gdpr even works basic assumption personal unless legal basis number requirements met.2 general sense beyond scope gdpr party significant legitimate interest controller desisting outcome ethical perspective require said desistance potentially even including erasure processing operation might cause harm party third party b inconsistent circumstances party contributed generation particular contribution made another purpose party could reasonably expected contribute generation foreseen present processing operation ii consent party would invalid overriding reasons require desistance affirmed however party ’ legitimate interest granted weighed factors referred → section 2.1 example affirmed cases processing way exception justified compelling interests e. g. prosecution criminal offences 88 part e ata regard non-personal requests desist become relevant example context value creation chains customer relationships non-personal often enormous economic significance party involved significant legitimate interest assert → section 5.3 example 1 non-personal collected sensors modern agricultural machinery relating soil quality weather etc manufacturers basis many services provide precision farming predictive maintenance etc. manufacturers forward potential investors lessors land however latter would given might prove harmful agricultural holding negotiations land take place future assumed agricultural holding would helped generate voluntarily known would purpose assessing require desistance ethical perspective consideration given balance power parties case hand fact agricultural holding made extremely significant contribution generation third-party deemed worthy protection would include manufacturer ’ interest maximising profit general interest part investors lessors etc obtaining accurate information.from ethical perspective waiver require desistance possible limited circumstances waiver automatically ruled cases consent would invalid overriding reasons within meaning requirement b ii example illegal inconsistent policy legal fundamental values underpinning exists thing liberty kind harm oneself others cases waiver possible provided stringent requirements met e. g. separate agreement linked services involve party placed pressure ensure voluntary nature waiver meaning requirement b would longer apply example 1 agricultural holding could consent forwarded third parties e. g. basis individual agreement appropriate remuneration tractor dependent forwarded 89 e 2. corresponding obligations personal obligations desist normally follow already provisions protec tion law criteria outlined determine whether substantive limits consent exceeded → section 3.2.1 guide balancing different legitimate interests example example 2 relating activities social network user extensive personality profiling profile contains attributes “ mentally unstable ” “ esoteric tendencies ” result user shown advertisements companies offer personal horoscopes energy healing services significant cost almost daily basis often immediately posted signals stress anxiety often makes purchases result set user account clicked checkbox next following statement “ happy evaluated personal preferences attributes identified accurately services offered including third-party providers personalised needs profiling ” “ consent ” kind make subsequent processing operations lawful number different arguments reaching conclusion one processing purpose cause significant harm user would inconsistent circumstances generated could reasonably expected known would purpose law allow abuse mental states kind cf section 138 german civil code bürgerliches gesetzbuch bgb .there many circumstances obligation desist mitigated consent balancing conflicting interests cases reference often made “ red lines ” “ limits ” requirement limits data-specific example reasonable prohibit election manipulation practices incompatible principle democracy regardless whether said practices involve view ethics commission example data-specific limits total surveillance individuals example 3 entering employment contract employee signs agreement stating location tracking functions smartwatch mobile telephone well number apps collect e. g. tracking sleeping behaviours emotions kept switched times even work hand devices employer requested order relevant accessed readily apparent arrangements taken together equivalent total almost total surveillance incompatible dignity self-determination privacy true even employee gave consent measures even decided accord enter contract employer even offers employment available 90 part e ata conversely criteria apply scenarios involving desistance bear indirect relevance situations ethical even legal obligation obligation arise party general obligation protect certain legally protected interests time access could secure improve protection interests kind situation obligation arises corollary obligation protect certain legally protected interests unless third party conflicting require desistance example 4 hospital experiencing outbreak multi- resistant pathogen wants analyse health patients recently become infected order gain better idea certain individuals likely fall prey pathogen basis pinpointing inpatients might benefit move another hospital circumstances hospital general obligation provide patients best possible protection infection taking available reasonable precautions end includes health belonging patients already infected pathogen provided said might protect patients obligation emanating former group patients desist 3 way examples commission building economy 9 final 10 pp 11 seqq available /ec.europa.eu/transparency/regdoc/rep/1//en/com--9-f1-en-main-part-1.pdf commission towards common space 232 final 25 pp 8 seqq available /ec.europa.eu/transparency/regdoc/rep/1//en/com-232-f1-en-main-part-1.pdf 2.2.2 scenarios involving access comes scenarios involving request access many situations party seeking access party effectively controls able reach agreement action taken voluntary arrangements kind welcomed provided conflicting overriding third-party interests particular provided parties require desistance based criteria given enormous potential value creation inherent however in-depth discussions held circumstances conditions access even granted ethical viewpoint.3 apply situations access required perhaps even mandated law order enable party comply special obligation task e. g. prosecution criminal offence health concern access consistent rules apply obligation task particular attention paid principle proportionality potential third-party require desistance → section 2.2.1 considered independent requests access example within existing value creation typically involve many different parties contribute generation different roles e. g. suppliers manufacturers retailers end users principle familiar agreed roles roles players involved → section 5.3 details legitimate interests asserted party basis access request particular include cases required following purposes 91 e 2. corresponding obligations asset line intended purpose within value creation e. g. repair connected device end user b monitoring improving quality service provided within framework value creation e. g. supplier c ascertain truth provide evidence e. g. legal dispute third parties avoid anti-competitive effects e. g. lock-in effects e create value using e. g. developing smart service example 5 supplier provides engines agricultural machinery referred example 1. would extremely useful supplier access certain tractor verify constantly improve quality engines stored manufacturer ’ cloud however latter unwilling allow supplier access situations kind important remember supplier made significant contribution generation engine urgently needed improve quality service provided within framework value creation manufacturer involved consideration given balance power specific case hand fact parties involved – including general – interest high-quality engines however relevant economic interests manufacturer ’ side particular relating confidentiality.access discussed situations party seeking access party effectively controls yet part value creation value creation could originate involved outcome assessment based general criteria normally different situations kind party seeking access typically contributed generation justifications cited granting access rather interest considerations specific considerations safeguarding competition → section 5.5 details example 6 example 1 manufacturer holds dominant tractor market collecting soil weather decades start-up recognises potential database investors using requests access case consideration given fact start-up made contribution generation existence interest access significance interest depends whether manufacturer abusing market power much economy would benefit breaking small group market- dominant companies presuming start-up based europe case potential harmful effects disclosure trade secrets legitimate third-party interests interests manufacturer agricultural holdings example 1 taken account 92 part e ata generally recognised principles open government ogd embody idea government made available private sector include “ open default ” re-use “ anyone purpose ” .4 calls many quarters expand open concepts include created effectively controlled private entities move towards open however gives rise complex ethical questions example extent generalised assessment longer looks individual case acceptable example 7 municipality implements large-scale project collect mobility using smartphone signals view facilitating traffic management adjusting timing transport services example theoretically speaking “ anonymised ” sets combined sets additional knowledge however owner identified confidence level 95 number different parties interested gaining access include researcher wants basis identifying optimal design urban recreational areas start-up wants establish online detective agency via users pay access mobility profile spouse competitor etc institute tasked foreign government investigating political activities citizens case-by-case assessments three access requests would deliver different outcomes therefore difficult question whether municipality even make view many possible uses would promote good 4 recital 16 directive /1024 open re-use sector psi directive principles 1 3 g8 open charter signed g8 summit 18 principle 1 international open charter signed open government partnership summit.the ethics commission wishes emphasise context importance potential individual parties contributed generation particular subjects require desistance follows possible reasonable protective measures including anonymisation techniques improved ongoing basis taken weighing potential harm expected benefit good – depending potential harm – granting blanket access question → section 5.4 details 2.2.3 scenarios involving rectification high quality problems particularly likely arise include unsuitable context inaccurate encoding incomplete sense deductions obtained using incorrect circumstances kind party involved generation ethically justified quire rectification underlying deductions obtained using threshold kind granted relatively low since principle neither protected individual interest interest processing inaccurate incomplete general rule following requirements met processing inaccurate incomplete potentially harmful party particular party relates b rectification disproportionate taking account severity likelihood harm one hand effort involved rectifying 93 e 2. corresponding obligations example 8 high error rate detected engine stored manufacturer example 5. problematic company supplies engines deprives company possibility fulfil quality assurance remit engine-related pooled engine-related engine suppliers basis evaluations poor performance metrics engines relevant supplier might reduce latter ’ chances securing orders manufacturers case processing inaccurate causes harm supplier indications effort involved rectification would disproportionate amount effort involved rectifying excessive potential harm significant require desistance frequently arise → section 2.2.1 2.2.4 scenarios involving economic share cases party uses create value parties contributed generation said everyday occurrence good thing principle provided one entitled require desistance → section 2.2.1 normally tolerated parties contributed generation given strong affinity obligations set section considerations good potent arguments recognising general remuneration parties contributed generation instead parties existing mechanisms collective economic participation particular taxation value creation.in cases valid contract back claim remuneration financial compensation considered mitigating measure example exercising without compensation appears disproportionate specific case hand → section 2.1 factor c ethical perspective view ethics commission party contributed generation entitled independent remuneration others exceptional cases cases kind might arise party ’ contribution generation required unusual amount effort particularly unique would hardly possible economic viewpoint replace contributions players b exceptionally large amount value created using c circumstances contribution generation made mean would impossible unreasonable party engage negotiations remuneration amount remuneration paid exceptional cases adequate particular basic incentives using create value removed remembered party creating value typically incurred financial risks 2.3 collective aspects obligations answer found issue whether extent arguments concerning require desistance access rectification economic share profits derived help applied collectives sense defined groups persons e. g. indigenous peoples regard genetic i. e. whether collectives entitled certain connection “ ” example 94 part e ata thought given question whether – ethically speaking – population nation state generated economic share profits form taxes transfer payments ethics commission believes question principle answered affirmative example 9 internet giant earns billions generated individuals around world services yet even though megalith company generates 10-digit sums year year using eu-based individuals pays virtually taxes question arises whether company obliged ethical grounds allow general share taxation value creates issue raises fundamental questions distributive participatory justice economic looks like however aspects market power unique nature contributions e. g. audio certain language develop voice-controlled services taken account relational nature many types makes particularly important include groups collectives debate relational nature apparent way many services require users disclose contacts “ friends ” example far corresponding obligations concerned “ friends ” require desistance gain access etc time potential interests always taken account weighing whether granted → section 2.1 however cases party contributes generation indirectly provide parties – even latter played role even broadest sense word generation particularly relevant sphere genetic applies types still another closely related group cases individualised even aggregated form implications potentially negative third-party effects extend beyond individual supplied example 10 health insurance company offers reduced premiums incentive sign health tracking schemes agree disclose benefit lower premiums refuse end paying issues relating representativeness train algorithmic interpreted problems relationality lack relationship parties supply training parties trained applied result systematic bias potential discrimination → part f section 2.6 details overcome hurdle individualistic approaches ethics law design expanded include relational concepts cf debate group privacy certain circumstances therefore possible – least viewed lens ethics – one group member ’ contribution generation attributed group members well potentially entitling latter spite fact made individual contribution certain request desistance gain access example 95 e 3. standards personal 3. standards personal 3.1 personal relating legal entities relating identified identifiable natural person regarded personal identifiable natural person one identified directly indirectly particular reference identifier name identification number location online identifier one factors specific physical physiological genetic mental economic cultural social identify natural person article 2 1 gdpr even though remainder section focuses personal legal sense term ethics commission wishes stress protection companies legal entities valid concern relegated completely sidelines potential hazards confronting legal entities exacerbated yet networking machines exchange factory components storage production generated industry 4.0 plants “ twins ” individual sets generated operation devices example pooled together result almost seamless overview company ’ internal operating procedures – absence appropriate protective mechanisms – easily fall hands wrong parties outside company competitors negotiating partners authorities prospective buyers etc. ethics commission believes risk posed self-determination companies legal entities sovereignty germany europe since flows predominantly involve third countries concerning ethical viewpoint steps taken mitigate it.a key legislative starting point protecting enterprise protection trade secrets particular german act protection trade secrets gesetz zum schutz von geschäftsgeheimnissen geschgehg interpreting applying act efforts made guarantee comprehensive protection sensitive business given central importance latter building fair competitive economic basis economic social well-being many respects however directive /943 provisions transposed act protection trade secrets adequately tailored reality iot industry 4.0. ethics commission therefore calls federal government step data-related protection german companies recommendations action relating personal put forward ethics commission remainder section example relation riskadequate interpretation applicable legal framework → section 3.2.2 privacy-friendly design products services → section 3.6 apply protection relating companies legal entities modified attenuated form appropriate 3.2 self-determination challenge tackled legal whole 3.2.1 cooperative relationship applicable legal regimes economy society heavily reliant personal huge variety different contexts yet always degree tension personal fundamental individuals constitutional informational self-determination part general personality essentially part protection dignity protection law particular gdpr clarifies benchmarks binding force private bodies 96 part e ata gdpr one great achievements legislator currently functions source inspiration countries important temper expectations piece legislation however gdpr focused protection rather comprehensive promotion individual welfare good economy taken isolation suitable tool averting harm individual suffer result personal processed therefore regarded protecting integrity respects different mechanisms provided legal whole safeguard legally protected interests particularly specifically addressed provisions protection law e. g. economic interests life health physical integrity reputation applies even situations personal play concept consent enshrined protection law vitally important mechanism safeguarding informational self-determination analogue spheres yet concept self-determination subject substantive limitations includes freedom inflict kind harm oneself third parties would alien element legal ethically indefensible law limit even prohibit individual ’ free informed consent – expression general freedom action protected fundamental – narrowly defined exceptional circumstances however consent protection law subject substantive limitations way analogy limitations freedom contract consent comes intrusions bodily integrity view ethics commission become average individual systematically overwhelmed number complexity decisions required take connection consent protection law 5 cf recital 42 gdpr 6 relates particular fairness test applied general terms conditions business sections 307 seqq german civil code bürgerliches gesetzbuch bgb principles morals section 138 civil code wilful immoral damage section 826 civil code contractual quasi-contractual protection fiduciary duties section 241 paragraph 2 civil code .difficulty involved estimating potential impacts processing ethics commission believes inadequate consent providers services one several reasons general loss trust society things stand individuals often longer rely fact state legal put place framework conditions necessary navigate world safety relatively speaking free care without needing worry possibility suffering serious harm parties business-to-consumer transactions contract law specifically unfair contract terms control provided basis ‘ rational indifference ’ part consumers far-reaching protection even low-value cases result achieved way applying fairness test declarations consent .5 applying fairness test general values principles underlying legal whole taken account 3.2.2 risk-adequate interpretation applicable legal framework ethics commission wishes stress existing legal framework interpreted applied way mitigate maximum hazards facing connection widespread collection analysis personal notwithstanding need comply requirements protection law processing operations subject number limits wherever possible uses go beyond limits prevented interpreting applying law force6 manner consistent fundamental view ethics commission relevant example 97 e 3. standards personal ●incursions personal privacy integrity incompatible fundamental result profiling and/or scoring e. g. certain methods determining personality traits emotions expected behaviours ●total surveillance incompatible dignity inter alia “ comprehensive surveillance footprint ” “ super scoring ” ●immoral exploitation situations urgent need medical conditions ●election manipulation practices run counter principle democracy legislation currently force already categorises ethically reprehensible attempts mislead manipulate consumers commercial context – include business practices aimed persuading party disclose personal – misleading aggressive commercial practices german unfair competition act gesetz gegen den unlauteren wettbewerb uwg regardless whether provisions protection law infringed attempts therefore trigger appropriate legal consequences e. g. rescission grounds fraud threat injunctive relief compensation ethics commission wishes cite following potential examples practices ●addictive designs i. e. technologies exert undue influence user particular means mechanisms promote addictive behaviour therefore liable substantially adverse impact freedom decide whether stop using ●dark patterns i. e. technologies mainly user interfaces designed way deceive user certain facts and/or manipulate taking certain decision financial implications 7 cf instruments referred footnote 6.absolute limits imposed processing order protect individuals placed undue financial disadvantage existing legislation contains various provisions enforce protection.7 view ethics commission examples unfair contract terms violations contractual pre-contractual duties fiduciary nature include following ●preventing access generated device required normal said device including performance repairs independent workshop making unreasonably difficult access e. g. access granted accordance article 12 gdpr i. e. within one month even three months ●preventing access needed operate pre-owned networked device making unreasonably difficult access e. g. individual bought house equipped smart home ●making harder individuals switch provider means lock-in i. e. refusing hand analyses user already paid economic perspective protected trade secrets ●processing user generated manufacturer another member supply chain purpose runs completely counter user ’ economic interests e. g. price differentiation aim extracting maximum individual willing pay 98 part e ata 3.2.3. need clarify tighten applicable legal framework things currently stand level protection legally protected interests line constitutional requirements achieved many questions arising society case-by-case interpretation general legal concepts blanket clauses supervisory authorities courts ethics commission believes situation untenable general legal concepts blanket clauses offer advantage flexible keeping future options open yet authorities courts often take years even decades develop established case law phenomena phenomena particular meantime results structural enforcement gap regard law force lack legal social media monitoring social media monitoring systematic oversight social media particular topic evolved utilisation tool takes advantage fact social networks expand users ’ communication options allow behaviour constantly monitored companies frequently deploy generated social network users e. g. purpose market marketing although public-sector bodies far slower make opportunities afforded social media monitoring means unheard-of practice example tax authorities web crawlers trawl publicly available internet way pinpointing business sellers paying vat algorithmic make collated social media monitoring usable exploitable far-reaching intrusive purposes particular creation personal profiles commercial purposes provided weighing interests pursuant article 6 1 f gdpr supports exploitation another legal basis processing entirely consistent law pursuant recital 51 gdpr fact subject disclosed exploitation ethics commission takes view monitoring activities rate deemed crossed boundary lawful unlawful publicly available monitored scope monitoring could gauged subject disclosed example – generally speaking – statements made minors without due consideration alternatively highly sensitive example suicidal ideation statements even applicants job willingly made recruitment process represent great intrusion personal integrity clearly related applicant ’ job history e. g. statements sexual orientation applies systematic evaluation originating individual ’ private life e. g. tracking particularly modes exploitation far-reaching intrusive weighing interests result limits placed admissibility e. g. businesses target advertisements basis sexual orientation exploit individuals known emotionally vulnerable state certain providers particular providers social networking sites technically capable carrying in-depth evaluations communications exchanged via central platforms operate even general access prevented using end-to-end encryption metadata provide means obtain highly instructive analytical findings legislative ban evaluation communications individuals within closed groups imposed private providers keeping principle telecommunications secrecy ethics commission therefore recommends federal government delay efforts secure introduction ban forthcoming negotiations adoption eprivacy regulation 99 e 3. standards personal 3.2.3. need clarify tighten applicable legal framework things currently stand level protection legally protected interests line constitutional requirements achieved many questions arising society case-by-case interpretation general legal concepts blanket clauses supervisory authorities courts ethics commission believes situation untenable general legal concepts blanket clauses offer advantage flexible keeping future options open yet authorities courts often take years even decades develop established case law phenomena phenomena particular meantime results structural enforcement gap regard law force lack legal certainty given extent issue affects fundamental uncertainty whether solutions emerge meet constitutional requirements ethics commission believes prompt action establish binding regulatory framework falls squarely within remit democratically legitimised legislator view hazards posed individuals personality-sensitive profiling sometimes resulting scoring ethics commission believes urgent need take effective action tighten current legal framework particularly critical area order effectively counter risks individuals manipulated suffering discrimination social media monitoring social media monitoring systematic oversight social media particular topic evolved utilisation tool takes advantage fact social networks expand users ’ communication options allow behaviour constantly monitored companies frequently deploy generated social network users e. g. purpose market marketing although public-sector bodies far slower make opportunities afforded social media monitoring means unheard-of practice example tax authorities web crawlers trawl publicly available internet way pinpointing business sellers paying vat algorithmic make collated social media monitoring usable exploitable far-reaching intrusive purposes particular creation personal profiles commercial purposes provided weighing interests pursuant article 6 1 f gdpr supports exploitation another legal basis processing entirely consistent law pursuant recital 51 gdpr fact subject disclosed exploitation ethics commission takes view monitoring activities rate deemed crossed boundary lawful unlawful publicly available monitored scope monitoring could gauged subject disclosed example – generally speaking – statements made minors without due consideration alternatively highly sensitive example suicidal ideation statements even applicants job willingly made recruitment process represent great intrusion personal integrity clearly related applicant ’ job history e. g. statements sexual orientation applies systematic evaluation originating individual ’ private life e. g. tracking particularly modes exploitation far-reaching intrusive weighing interests result limits placed admissibility e. g. businesses target advertisements basis sexual orientation exploit individuals known emotionally vulnerable state certain providers particular providers social networking sites technically capable carrying in-depth evaluations communications exchanged via central platforms operate even general access prevented using end-to-end encryption metadata provide means obtain highly instructive analytical findings legislative ban evaluation communications individuals within closed groups imposed private providers keeping principle telecommunications secrecy ethics commission therefore recommends federal government delay efforts secure introduction ban forthcoming negotiations adoption eprivacy regulation profiling “ profiling ” defined article 4 4 gdpr form automated processing personal consisting personal evaluate certain personal aspects relating natural person particular analyse predict aspects concerning natural person ’ performance work economic situation health personal preferences interests reliability behaviour location movements profiling ultimately involves making deductions drawing conclusions basis input particular using certain statistical inference methods → part c section 2.2.2 deductions relate actual purported “ properties ” individual e. g. “ mental stability ” “ reliability ” “ social acceptability ” and/or take form predictions relate individual ’ future behaviour e. g. particular consumption pattern .in addition profiling attempts frequently made assign users predefined stereotype category basis observed behaviour interacting using “ matching algorithms ” example someone books holiday might classified sports fan culture enthusiast family man woman keen hiker sales representative gourmet stereotype instantiated individual user store typical preferences goals personality traits subsequent algorithmic processing operations sometimes profiles stored instead ad-hoc deductions particular behavioural predictions generated dynamically real time using raw e. g. “ ready purchase shoes ” 100 part e ata given profiling makes possible personalise wide range products services degree many users perceive convenient helpful categorical ban would overshoot mark however ethics commission recommends federal government speak – forthcoming evaluation gdpr example – favour expanding gdpr include specific rules profiling go beyond existing provisions article 22 gdpr permissibility automated decision-making alternatively federal government could lobby separate legislative act would effectively counter risks profiling poses fundamental individuals adequately hard-hitting solution proves unworkable foreseeable future legislative rules put place national level within scope permitted law regulate profiling procedures pose potential risk fundamental ethics commission believes particularly urgent need provisions horizontal and/or sectoral profiling concerning following matters far solutions already follow correct interpretation gdpr imposition limits i. e. prohibiting law certain critical applications e. g. selecting pool job applicants profiles generated basis originating private lives profiling procedures involve highly sensitive personal example connection emotion detection software biometric processing operations entail unacceptable potential harm subjects society 8 high-level expert group policy investment recommendations trustworthy 26 pp 14 40 available /ec.europa.eu/digital-single-market/en/news/policy-and-investment-recommendations-trustworthy-artificial-intelligence .b imposition admissibility requirements critical profiling procedures including quality requirements relation meaningfulness accuracy profiles generated → part f section 4.2.1 details risk-adequate opt-ins opt-outs latter appropriate level risk low c clarification principle proportionality inter alia regards requirements apply nature scope profiling permitted level detail conclusions drawn profiling purposes particular purposes profiling admissibly imposition specific labelling disclosure obligations inter alia regards existence purpose algorithmic carry ad-hoc deductions critical deductions already carried instead providing automated decisions taken later stage process e provision feasible options subjects exert influence profiles created including option erase/rectify/ verify includes “ start ” involving erasure existing profiles e. g. upon reaching age majority recently suggested high-level expert group.8 voice assistants voice assistants promise great deal terms convenience easier access technologies particularly people disabilities yet harbour risks far self-determination subjects concerned voice assistants record ambient noise often without user activated related function recordings include speech user third parties regarded biometric purpose gdpr speech recordings analysed real time response given spoken commands automated processes often log certain types log file unique timbre individual ’ voice speech patterns analysed basis uniquely identifying individual deciphering speech emotions profiling kind represents particularly deep invasive intrusion core area personality entails risk exacerbating structural imbalances demand supply side market enormous potential misuse present given possibility recombining digitally reconstructing spoken word deep fakes reality individual users often vague idea processing carried indeed whether carried particularly user relatively inexperienced technical matters easily persuaded disclose additional sensitive personal upon hearing authentically human-sounding voice many cases voice assistants limited simply recording going immediate vicinity instead – networked virtual assistants smart home products – act control centre “ technological heart ” modern homes.the ethics commission believes creation comprehensive profiles based voice assistants integration wide range software hardware components poses critical risk ease convenience apparent benefits connecting voice assistants devices ultimately lead users “ plug-and-play trap ” view ethics commission range measures taken mitigate risks associated voice assistants include bans particularly critical profiling procedures applications following binding technical requirements implement principles protection design default → section 3.6 especially processing speech files exclusively local basis well option erase files locally restrictions stating forwarded operators third parties form commands already translated machine language e. g. order placed b binding technical requirements include option switch microphone internet connection way telling i. e. visual indication whether microphone → section 3.6 c transparency obligations designed manner appropriate medium → part f section 4.1 i. e. ensure important provided acoustically either pertinent situation arises regular intervals 101 e 3. standards personal b imposition admissibility requirements critical profiling procedures including quality requirements relation meaningfulness accuracy profiles generated → part f section 4.2.1 details risk-adequate opt-ins opt-outs latter appropriate level risk low c clarification principle proportionality inter alia regards requirements apply nature scope profiling permitted level detail conclusions drawn profiling purposes particular purposes profiling admissibly imposition specific labelling disclosure obligations inter alia regards existence purpose algorithmic carry ad-hoc deductions critical deductions already carried instead providing automated decisions taken later stage process e provision feasible options subjects exert influence profiles created including option erase/rectify/ verify includes “ start ” involving erasure existing profiles e. g. upon reaching age majority recently suggested high-level expert group.8 voice assistants voice assistants promise great deal terms convenience easier access technologies particularly people disabilities yet harbour risks far self-determination subjects concerned voice assistants record ambient noise often without user activated related function recordings include speech user third parties regarded biometric purpose gdpr speech recordings analysed real time response given spoken commands automated processes often log certain types log file unique timbre individual ’ voice speech patterns analysed basis uniquely identifying individual deciphering speech emotions profiling kind represents particularly deep invasive intrusion core area personality entails risk exacerbating structural imbalances demand supply side market enormous potential misuse present given possibility recombining digitally reconstructing spoken word deep fakes reality individual users often vague idea processing carried indeed whether carried particularly user relatively inexperienced technical matters easily persuaded disclose additional sensitive personal upon hearing authentically human-sounding voice many cases voice assistants limited simply recording going immediate vicinity instead – networked virtual assistants smart home products – act control centre “ technological heart ” modern homes.the ethics commission believes creation comprehensive profiles based voice assistants integration wide range software hardware components poses critical risk ease convenience apparent benefits connecting voice assistants devices ultimately lead users “ plug-and-play trap ” view ethics commission range measures taken mitigate risks associated voice assistants include bans particularly critical profiling procedures applications following binding technical requirements implement principles protection design default → section 3.6 especially processing speech files exclusively local basis well option erase files locally restrictions stating forwarded operators third parties form commands already translated machine language e. g. order placed b binding technical requirements include option switch microphone internet connection way telling i. e. visual indication whether microphone → section 3.6 c transparency obligations designed manner appropriate medium → part f section 4.1 i. e. ensure important provided acoustically either pertinent situation arises regular intervals 102 part e ata addition special legislative measures kind aimed protecting users federal government examine extent would possible lobby expanded legislative framework ensure appropriate governance preferably level otherwise national level framework entirely separate goals protection law i. e. outside scope gdpr ethics commission wishes issue following special recommendations connection → section 3.2.2 examples case blacklisting data-specific unfair contract terms sections 308 309 german civil code bürgerliches gesetzbuch bgb data-specific contractual pre-contractual duties fiduciary nature section 241 paragraph 2 civil code b specification data-specific torts umbrella existing tort intentional infliction harm contrary policy e. g. section 826a civil code c blacklisting data-specific misleading aggressive commercial practices addictive designs dark patterns expanding blacklist already exists german unfair competition act gesetz gegen den unlauteren wettbewerb uwg full harmonisation approach ’ unfair commercial practices directive means change would need initiated level however.when profiling carried government agencies potential cumulative infringements fundamental aggregated surveillance taken account potential side effects “ collateral damage ” ethics commission believes particular potential abuse individual subsystems connected resulting pooling analytical findings different areas sectors significantly steps intensity surveillance intelligent pattern recognition techniques particular facial recognition make easier link personal across variety surveillance merge profiles view fact ethics commission recommends firstly pattern recognition techniques kind come play absolutely vital prerequisite fulfilment state obligations secondly legal limits – beyond separation rule concerning activities – imposed exchange patterns authorities encompass legal provisions banning particular types exploitation particularly regards sharing government agencies engaged preventive repressive measures 103 e 3. standards personal 3.2.4 uniform market-related supervisory activities task supervising compliance protection law players german economy shared federal land authorities discrepancies observed terms interpretation protection law approach enforcement raises certain challenges parties affected although protection board edpb introduced member states aim ensuring uniform application gdpr institution power adopt binding decisions individual cases coexistence different protection authorities various german länder within framework federal date prevented emergence binding uniform approach national level event proves impossible strengthen formalise cooperation german protection authorities thereby safeguarding uniform consistent application protection law consideration given establishment protection authority federal level market-related activities concentrating supervisory powers within single would make possible build specialist expertise required enforce protection law environment characterised highly dynamic technological developments single authority – either acting alone close cooperation authorities – would need able safeguard enforcement data-related areas law close functional ties protection legislation e. g. general private law unfair commercial practices law establishment single able wield market supervisory powers field protection might make germany ’ voice louder within protection board since member states already represented edpb protection authority national jurisdiction finally centralisation official competencies go hand hand designation single court responsible judicial control market-related supervisory authorities field protection court build relevant expertise set forth consistent case law.various models conceivable perspective organisational law based powers regulate economic law federal government could transfer supervisory competences protection economy i. e. private sector federal commissioner protection freedom provide latter relevant resources setting number different satellite offices commissioner could ensure nation-wide presence protection bodies similar federal office migration refugees bundesbank alternatively länder could establish joint facility basis interstate treaty way analogy similar projects broadcasting sector example central offices länder safety engineering health protection joint facility responsible supervisory activities field protection would need independent principle enshrined interstate treaty irrespective decisions taken connection authorities provided better material resources allow “ punch weight ” reasons constitutional law protection authorities land level retain jurisdiction sector 104 part e ata 3.3 personal asset 3.3.1 commercialisation personal economic significance personal hard overestimate generally acknowledged protection personality fundamental encompasses individual ’ decide whether certain aspects personality made available fee e. g. one ’ image words whether exploited economic purposes.9 way complete ban exploitation individuals however rules categorically stating personal exploited economic purposes initiative third parties people compare situation trade organs comparison flawed several respects unlike organs non-rivalrous resource mere fact personal processed someone else necessarily cause harm subject – harm caused processing specific contexts specific purposes interpreting informational self-determination natural corollary dignity makes limits imposed economic exploitation personal generally coincide general limits placed processing personal → sections 3.2.1 3.2.2 including substantive limitations consent backdrop economic exploitation personal neither subject stringent rules general privileged way economic aspects frequently come play general protection rules applied however example consent longer freely given subject exposed economic pressure 9 e. g. section 22 german act protection copyright works art photographs gesetz betreffend das urheberrecht werken der bildenden künste und der photographie kunsturhg 10 way examples commission building economy 10 9 final available /ec.europa eu/transparency/regdoc/rep/1//en/com--9-f1-en-main-part-1.pdf arbeitsgruppe “ digitaler neustart ” der konferenz der justizministerinnen und justizminister der länder working group “ start ” conference ministers justice länder report 15 pp 29 seqq available /www.justiz.nrw.de/jm/schwerpunkte/digitaler_neustart/zt_bericht_arbeitsgruppe/bericht_ag_dig_ neustart.pdf .3.3.2. ownership issue financial compensation things stand ethics commission believe adequate grounds introducing additional ownership-like exploitation would allow subjects request economic share profits derived help often referred concepts “ ownership ” “ producer ” .10 protection law general private law already provide individual range legal effective vis-à-vis third parties basis individuals could theoretically make toleration activities dependent payment appropriate fee individual fails negotiate fee kind attributed circumstances e. g. lack negotiating power and/or poorly functioning competition nothing absence additional ownership-like exploitation theory imbalance negotiating power could counter-balanced introduction collective societies collectively exercise ownership-like exploit extending concept personal include ownership-like economic component would however potentially odds protection particular regards voluntary nature consent ability withdraw consent time request erasure would create questionable financial incentives encouraging generation maximum personal would put pressure individuals particular vulnerable groups minors low earners disclose much possible industry passes costs remuneration customers privacyconscious individuals might forced shoulder comparatively greater burden financial terms 105 e 3. standards personal arguments hold water extent comes anonymised however given huge number individuals contribute generation processing level complexity fair remuneration 24/7 monitoring would required measure flows would proportion potential gains terms justice quality might negatively affected since incentives would created generate “ artificially ” e. g. creation fake profiles ultimately producing distorted picture reality ethics commission therefore counsels introducing exploitation designed exclusive either anonymised types 3.3.3. counter-performance large number service types e. g. search engines social networks messenger services online games offered end users monetary consideration financed ways particular payments received third parties exchange personalised advertising personalised services targeted users user profiles user scores personal therefore often referred shorthand terms “ counter-performance ” services example original draft article 3 1 directive although term removed later point legislative procedure .11 extent economic model described fact compatible prohibition article 7 4 gdpr “ tying ” “ bundling ” consent provision service12 ultimately clarified court justice 11 commission proposal directive parliament council certain aspects concerning contracts supply 9 634 final available /ec.europa.eu/transparency/regdoc/rep/1//en/1--634-en-f1-1.pdf 12 protection supervisor opinion 4/ proposal directive certain aspects concerning contracts supply 14 p. 15 available /edps.europa.eu/sites/edp/files/publication/17-03-14_opinion_digital_content_en.pdf .the ethics commission argues referred “ counter-performance ” provided exchange service even though term sums issue nutshell helped raise awareness among general firstly personal form integral part individual ’ personality protected constitutional law secondly classification counter-performance might unintended consequences example might abused argument favour largely excluding data-related standard contract terms unfairness control justification triggering contractual sanctions consumers withdraw consent exercise erasure etc connection german legislator – implementing directive /770 certain aspects concerning contracts supply services – leeway available member states way might prevent individual seeking legal remedies protection law particular individual withdraws consent processing provider terminate provision service immediate effect however possible provider request payment services already provided retrospective automatic reversion pay option pay options increasingly discussed way avoiding “ tying ” “ bundling ” consent provision service yet even smallest financial burdens represents disadvantage particular vulnerable population groups dissuade subjects encourage disclose excessive amounts personal feared financial burden privacy-conscious individuals would disproportionate commercial users previously able certain services free e. g. company ’ page social networking site therefore preferred source funding 106 part e ata pay options however increase consumer awareness financial value create transparency reasons ethics commission believes offering pay options alternative ethically acceptable way ensure consent given users genuinely free time however price abusive exceed market prices consumer ’ perspective represent realistic alternative disclosure personal ethical viewpoint safeguards put place protect privacy-conscious users “ cross-subsidise ” users equally needs socially vulnerable groups taken consideration example government transfers 3.3.4 basis personalised risk assessments price-related predictions obtained using algorithmic purpose personalised risk assessment e. g. one-off basis approving loan ongoing basis case black schemes operated insurance companies characterised higher level granularity ultimately sector-specific case certain profiling technique associated scoring procedures → section 3.2.3 part f section 4.2.2 details profiling general processing additional personal purpose personalised risk assessments regularly requires consent subjects individuals hope gain economic advantages result particularly likely grant consent yet granting consent one individual significant impacts others give rise chain reactions problematic ethical viewpoint unravelling effects put subjects disproportionate pressure jeopardise voluntary nature consent.example 11 insured parties healthy particularly likely consent processing health insurance company result others come pressure grant consent order avoid arousing suspicions regarding state health cases individual behaviour influence parameters models kind significant influence people lead lives another ethical consideration particularly relevant insurance sector goal increasingly granular risk assessments runs counter basic principle collective risk sharing community insured persons taken extreme i. e. insurer access “ comprehensive ” adjusts price individual risk whole concept insurance would reduced absurdity ethics commission therefore believes personalised risk assessments comply following ethical requirements particular processing intrude core individual ’ private life restricted areas individual already contact exterior world therefore expect conclusions drawn basis behaviour principle dictates would ethically acceptable car insurance company example record miles driven traffic offences committed driver purely private behaviour inside vehicle even behaviour might relevant risk perspective e. g. often yawns whether chats passengers even driver ’ state health e. g. heart problems lifestyle factors e. g. purchasing behaviour relation coffee alcohol b causal relationship exist processed risk determined linking avoid discriminatory repercussions → part f section 2.6 details 107 e 3. standards personal c allow conclusions drawn directly implications relatives third parties full transparency required regards specific parameters weighting impacts pricing conditions individual provided comprehensible explanations improve conditions → part f section 2.7 e order keep unwanted chain reactions check difference “ optimal ” conditions conditions apply consent refused exceed certain ceiling e. g. maximum price difference 3.3.5 reputational capital coupled personalised economic conditions personalised prices personalised ranking personalised products services personal profiles scores serve reputational capital personalised behavioural rewards aimed increasing customer loyalty e. g. granting discounts depending quantity purchased previous month incentivise consumers consent processing personal apt influence way lead lives evidence ethical limits outlined → section 3.3.4 currently disregarded german economy connection customer loyalty programmes come attention ethics commission developments continue monitored 13 cf article 9 regulation access many general provisions e. g. general terms conditions business ranking.in view ethics commission problems arising connection price differentiation narrow sense measures similar ilk relate regulation algorithmic → part f details time however price differentiation morphs problem soon consumers led believe access prices lower overall disclosing much personal possible exhibiting certain behaviours tailored relevant criteria e. g. making online purchases using computer manufactured certain company conversely suggested consumers refuse consent processing purpose personalised pricing always pay higher prices average ethics commission believes latter would pose ethically questionable risk voluntary nature consent true reputational external third parties e. g. “ stars ” indicating someone profile online platform good person business gaining ever economic nonmaterial significance certain extent reputational kind covered regulation /1150 promoting fairness transparency business users online intermediation services.13 regulatory approach chosen lawmakers drafted regulation – based part transparency requirements self-regulation – cautious ethics commission welcomes approach principle however worth noting certain sectors heavily dependent true reputational factor particular might lead significant lock-in effects jeopardise competition cause problems individuals unable take switching different online intermediary platform 108 part e ata example 12 micro entrepreneur offers taxi services via online platform ranked highly many former passengers wishes switch platform take rankings ethics commission aware problems would arise general obligation recognise ranking profiles built different platform enshrined law however recommends federal government examine conditions commercial users profiles kind might nevertheless granted portability view lobbying broader regulation level.14 way contrast rise significance social reputation number “ likes ” “ followers ” “ friends ” part wider trend society – limited exception “ influencers ” – longer viewed predominantly lens personal economic asset instead discussed relation systemic societal implications 3.3.6 tradeable items significant number companies already deriving financial gain cases earning great deal money compiling personal profiles scores personalised statistical evaluations carried using aggregated raw reselling third parties enriching existing profiles estimated placing market following section business models kind referred “ trading ” 14 cf example articles 6 7 draft “ model rules online intermediary platforms ” law institute made available ethics commission.the gdpr currently contain provisions relating specifically trading instead business models kind categorised merely normal processing operations subject general provisions gdpr many cases closer examination applicable provisions leads inescapable conclusion certain types trading infringe provisions gdpr therefore contrary law generally speaking however field trading characterised significant enforcement gap ethics commission therefore believes urgent action taken protection authorities relation sector protection board edpb alternatively conference independent protection authorities federal government länder konferenz der unabhängigen datenschutzaufsichtsbehörden des bundes und der länder develop – keeping gdpr ’ risk-based approach – clearly delimitable categories different types lawful trading greater clarity needed regarding instances trading subject grant consent forwarding instances subject object processing instances compelling reasons rule even object regard general principles governing processing article 5 gdpr forwarding third parties permitted within closely prescribed limits situations covered existing provisions protection law ethics commission therefore recommends federal government speak level – connection forthcoming evaluation gdpr example – favour expanding scope gdpr include specific provisions trading following ethical considerations already enshrined gdpr taken account drafting future legal provisions kind 109 e 3. standards personal individual ’ informational selfdetermination starting point balancing exercise meaning trading principle requires prior consent subject due regard substantive limitations consent → sections 3.2.1 3.2.2 b processed legal basis consent likely occur isolated cases individual straightforward opportunity exercise object advance e. g. unchecking checkbox immediately collected forced communicate objection via separate communication channels c trading models deprive subjects choices whatsoever rarely considered extent need forwarded order interests manifestly outweigh countervailing interests comprehensive legislative clarification category required gdpr contains detailed provisions transfer processors forwarding third countries given rationale gdpr would illogical assume requirements apply transfers third parties within less stringent apply transfers outside certain points inferred general provisions e. g. requirements regarded “ appropriate safeguards ” nevertheless ethics commission recommends urgent action taken clarify explicitly law obligations apply transferring third parties e. g. control obligations well circumstances parties held liable.e controllers obliged document disclose specific source collected generated algorithmic well identity individual recipients provided standardised machine-readable format allows e. g. automated management using privacy management tool/ personal management → section 4.3 details would take due account fact subjects largely dark regards existence traders means simple list different categories sources recipients would little f given large number traders market subjects able exercise effectively central mechanisms established facilitate process assume responsibility e. g. protection authorities → section 3.2.4 privacy management tools/personal management section 4.3 details g given dispersion effects give rise higher risks potential loss control traders subject certification obligation protection law includes regular audits certification bodies ethics commission recommends specific certification criteria adopted appropriate independent protection authorities federal government länder criteria take due account risks recommendations outlined 110 part e ata 3.4 inheritance modern communication technologies processing capacities make possible record every last detail individual ’ private activities decades end evaluate recordings using automated handing collected deceased individual heirs another third party adds whole dimension privacy risk deceased person particular individuals communicated lifetime often compared diaries personal correspondence comparison flawed many channels communication messenger services chats e-mails etc serve functional replacement ephemeral spoken word rather letters 3.4.1 precedence living wills ethics commission believes bestcase scenario subject make intentional informed dispositions lifetime many cases however people neglect make dispositions sole reason unaware legal practical options put level uncertainty backdrop ethics commission believes justified grounds obliging service providers alert users option making dispositions provide ongoing incapacity provide consent e. g. due dementia death provide technical means making said dispositions minimum barriers i. e. fewest possible changes medium corresponding provisions could added german telemedia act telemediengesetz tmg .15 15 previous discussion topic mario martini juristenzeitung jz p. 1154.in view ethics commission situation following subject ’ death merely extreme example serve prompt reflection general design modes communication ethics commission therefore recommends federal government examine possibility making obligatory messenger services offer default option erasing messages certain period time user chose option message would automatically erased expiry relevant period unless manually archived recipient sender 3.4.2 role intermediaries growing awareness topic inheritance allowed business models flourish large number companies offering services field ranging central storage account passwords comprehensive inheritance management services provide useful guidance associated certain hazards including inadequate provision cases company goes bankrupt otherwise liquidated shortcomings security including genuine fraud ethics commission believes quality assurance regulations characterised cautious approach awareness-raising potential advantages risks required order protect citizens 111 e 3. standards personal addition recommends federal government part remit provide services general interest set least subject state supervision provides affordable basic inheritance protection planning services citizens services reflect latest developments field security german citizen writes choose store privately notary district court similar options private privatesector solutions government-run service available individual ’ inheritance 3.4.3 post-mortem protection ethics commission recommend wholesale rejection principles set forth german federal court justice16 regarding transfer estates heirs since potential advantages would far outweighed effects either undesirable and/ excessive different default solution e. g. trust model imposed law distinction user account regarded asset user account regarded highly personal conversely inheritance law apply nature user account e. g. online account alcoholics anonymous group renders within financially worthless highly sensitive cases principle telecommunications confidentiality applies inter alia protect deceased ’ communication partners legislator case still reconcile inheritance enshrined fundamental example corresponding reference part civil code devoted inheritance law 16 judgment german federal court justice 12 ref iii zr 183/17.the principle set forth federal court justice – estate transferred deceased ’ heirs – linked existence contractual relationship contractual relationship transfer heirs take place owing highly sensitive nature heirs legal recourse since post-mortem protection provided gdpr means legal recourse relatives current state protection law ethical concerns raised fact controllers almost unlimited power dispose deceased ’ personal result ethics commission therefore recommends federal government follow footsteps several member states make option provided recital 27 gdpr enacting provisions post-mortem protection even death subject latter ’ relatives able exercise fundamental erasure rectification incorrect time suitable measures taken ensure compliance dispositions made deceased lifetime even dispositions implied e. g. deliberate choice publish “ life story ” 112 part e ata 3.5 special groups subjects 3.5.1 employees fact employers collect employees ’ location performance widespread phenomenon certain modern workplaces poses significant risk employees ’ informational self-determination general personality true creation biometric profiles necessary precursor certain forms collaboration questions considered include legal basis processing granting co-determination employee representation bodies obligations provide employees e. g. hazards posed multi-sensor fusion depending context opportunities object issues regarding retention procedures terms retention extent employees ’ disclosed third parties rectification incorrect obsolete personal profiles example appropriate erasure procedures points consideration include framework conditions limited control surveillance employees restrictions tracking employees ’ locations ban comprehensive location profiles restrictions obligation share social media accounts allow employer access context “ bring device ” models framework conditions biometric restrictions psychological investigation methods.the ethics commission recommends federal government invite social partners work towards common legislative provisions adopted view stepping protection employee based examples best practices existing collective agreements concerns individuals non-standard forms employment taken account process collective agreements works council agreements continue play significant part employee protection yet foundational principles employee protection regulated solely collective agreements works council agreements firstly employees covered latter secondly importance principles fundamental perspective worth noting legal uncertainty currently reigning scope gdpr provisions negative impact investment security reference wider field legal bases processing employee ethics commission believes traditional construct consent protection law suitable contexts since difficult put place framework conditions necessary consent given voluntarily employment situations impossible find appropriate balance cases employer ’ needs option employees revoke consent request erasure time employee protection measures therefore legal grounds justification specifically tailored employment context guarantee high level protection appropriate weighing interests fundamental outcomes look similar consent certain respects taking account power structures typically exist employment context 113 e 3. standards personal deciding whether interest groups granted co-determination rights17 relation processing within companies due regard given asymmetry knowledge exists employers employees regards operating principles details processing operations need models go existing mechanisms allowing interest groups access external expertise time ensuring appropriate involvement company protection officer protection trade secrets given constant advancement data-processing within companies software updates self-learning elements etc shift away consent single one-off event towards ongoing oversight processes interest groups progress field employee protection neglect stages applying job entering employment relationship example care taken ensure provisions applicable law prohibit employers asking certain questions application procedure recruiting individual e. g. asking whether woman pregnant circumvented “ resources ” algorithms request grant employer access social media accounts 17 examples current legislative provisions e. g. section 87 1 6 german works constitution act betriebsverfassungsgesetz betrvg relation works councils section 75 3 17 german federal staff representation act bundespersonalvertretungsgesetz bpersvg relation staff councils 18 german ethics council deutscher ethikrat big health opinion 30 available /www.ethikrat.org/fileadmin/ publikationen/stellungnahmen/englisch/opinion-big-data-and-health-summary.pdf .steps taken ensure persons nonstandard forms employment excluded progress field employee protection upsurge forms employment platform economy means many people longer access traditional employee co-determination imbalance power arises client platform operator one hand contractors platform workers often significant implications terms protection informational selfdetermination appropriate legislative provisions adopted ideally level institutional framework developed e. g. interest group mitigate risk 3.5.2 patients view benefits could gained digitalising healthcare basic principle ethics commission recommends swift expansion infrastructures sector introduction procedures reviewing assessing healthcare services range quality digitalised healthcare services improved allow patients exercise informational self-determination become health literate.18 even things stand today provision healthcare services involves processing huge volumes personal involved typically health genetic words special categories personal within meaning article 9 gdpr designing future health landscape primarily nature comprehensive account taken need provide special protection time boosting self-determination patients health insurance policies inter alia field → section 4.1 114 part e ata connection ethics commission emphasises urgent need introduce roll electronic health record view improving quality transparency cost-effectiveness medical care.19 given vital role electronic health record would play digitalising healthcare sector ethics commission wishes make greater attention paid security patient autonomy implementing existing cryptosecurity concept based decentralised management keys pins insured parties continue apply example possible electronic health record even patient incapable granting consent based provisions concerning legal representation otherwise apply regardless type health insurance policy held patient health services products collectively financed consumer-funded health market becoming ever important least healthcare services offered statutory health insurance funds far date important underestimate relevance services – include fitness health wellness apps particular self-monitoring apps associated wearables – context digitalised healthcare sector yet apps often questionable poorly verified quality meaning collect limited usefulness carries risk health affected patients users cases significant furthermore assumed patients able assess quality products services independently particular compliance principles protection security equally access healthcare services dependent individual financial wherewithal mind ethics commission welcomes plans federal institute drugs medical devices bundesinstitut für arzneimittel und medizinprodukte introduce procedure examining assessing apps kind 19 respect ethics commission ’ previous recommendation participatory electronic health record dated 28 available www.datenethikkommission.de .3.5.3 minors ethics commission welcomes efforts undertaken – include adoption legislation voluntary self-regulation – develop special protective mechanisms allowing minors exercise self-determination primary goal mechanisms step level protection degree protection profiling manipulation dark patterns addictive designs etc secondary goal provide greater protection age-appropriate glorifies violence example time however ethics commission wishes make protective mechanisms prove futile unless reliable identity management place ensuring age minors detected treated appropriately relying users honest age without question wrong approach viewed lens ethics however would problematic ask providers ascertain user ’ age collecting personal highly sensitive e. g. facial recognition transferred provider ’ cloud time placing entire burden whoever holds parental authority easily result situation latter feels much asked ethics commission therefore recommends federal government promote emergence family-friendly technologies allow minors exercise self-determined time reliably guaranteeing protection 115 e 3. standards personal ethics commission recommends federal government lobby level measures enforce compliance principles protection design default enshrined gdpr particularly case mobile end devices order protect informational self-determination minors protect privacy german protection authorities competition authorities media regulators technical regulatory authorities take action within relevant remits spheres responsibility force manufacturers operating mobile end devices providers services adhere legislative requirements apply age groups question services age-appropriate parties responsible procuring relevant view schools kindergartens incorporate requirements tendering procedures detailed discussion need force manufacturers comply principle protection design default found → section 3.6.1 far action area concerned consideration given introduction eu-wide obligation forces manufacturers child-friendly mobile end devices program outset devices specifically intended children ensure “ jail breaking ” “ rooting ” impossible possible key devices programmed way enforce compliance legislative provisions aimed protecting children services age-appropriate relevant settings enabled device/ operating upon activation minors able change settings without parents ’ consent solution kind would offer advantages parental control apps firstly apps often pose protection security problems secondly raise ethical questions terms opportunities afford total surveillance private life.3.5.4 vulnerable care-dependent persons many cases belonging vulnerable individuals processed benefit individuals e. g. care sector technologies make much safer older people remain environment accustomed example help alleviate negative impacts skills shortage care sector ensure better healthcare provision particular assistance – correctly – serve bridging adjust adaptively varying needs different people life bodily integrity informational self-determination fundamental reconciled accordance principle practical concordance particular consideration given two questions particular whether risks posed life health extent informational self-determination encroached upon 116 part e ata ethics commission believes standards guidelines surveillance professionals care sector developed conference independent protection authorities federal government länder particular standards guidelines specify legal provisions upon professionals base action particular situations cases especially consent granted subject caregiver surveillance either prohibited possible basis article 6 1 f gdpr arrangements provision whereby ethics commission takes differentiated surveillance options provided prior institutional setting e. g. care home kindergarten school consent obtained differentiated basis cases legal basis processing standards guidelines kind would appropriate way provide legal certainty care home operators care staff reduce liability risks section 1901a civil code amended accordingly clarify fact living wills include dispositions relevant subject grants prior consent processing basic principle particularly high level protection accorded people homes since likely regard space within four walls safe privacy technologies opened expanding options surveillance private individuals private individuals e. g. surveillance romantic partners children persons disabilities range way ethically alarming prospect total private surveillance given awareness topic lacking many quarters ethics commission recommends awarenessraising campaigns area initiated federal government governments länder since latter often hold jurisdiction field although recommends federal government continue monitoring developments believe legislative measures e. g. criminal offences required present.3.6 protection technical design citizens companies government agencies parties entitled assert ethically justified obliged comply corresponding obligations first place necessary technical framework put place enabling technologies play prominent role respect yet enabling technologies kind lead situation responsibility protection fundamental freedoms offloaded onto individual users instead state matter principle adopt regulations required provide reliable protection fundamental freedoms without need action part individuals 3.6.1 privacy-friendly design products services heading suggests article 25 gdpr makes mandatory controllers comply principles “ protection design default ” designers technologies therefore take due account concerns relating protection based interpretation term applied article 5 gdpr following risk-adequate approach technical organisational measures implemented end required prior processing i. e. controller determines means processed well processing operation 117 e 3. standards personal design specifications protection law high level practical relevance relation end devices end devices designed worn wearables e. g. smartwatch smart textiles least carried close e. g. smartphone others designed mobile means e. g. networked car immobile e. g. smart home facilities designing software end devices kind amount time spent reflecting ethical questions raise depends likelihood close proximity private intimate spheres e. g. bathrooms bedrooms probability affect particularly vulnerable persons e. g. protection design default 1 working group conference independent protection authorities federal government länder das standard-datenschutzmodell – eine methode zur datenschutzberatung und -prüfung auf der basis einheitlicher gewährleistungsziele v.1.1 – erprobungsfassung standard protection model – method protection consulting assessment basis uniform warranty objectives v.1.1 – test version available /www.datenschutzzentrum.de/sdm/ .data protection design imposes conditions selection technical organisational measures relating state art implementation costs processing risk posed freedoms natural persons example protection default imposes conditions since principle adhered without exceptions practice however often case excessive amounts personal e. g. identifiers processed inadequate restrictions placed processing retention periods long inappropriately high number people able access field “ privacy engineering ” therefore emerged banner additional protectionrelated goals non-linkability transparency intervenability standard protection model sdm german protection authorities incorporates goals “ warranty objectives ” .1 like baseline protection catalogues published federal office security bundesamt für sicherheit der informationstechnik bsi sdm defines modules controllers designers technologies basis choosing technical organisational measures appropriate protection needs although first modules currently available others planned fact many developers baseline protection catalogues iso 2700x series standards reference works means developers familiar fundamental concept able take better account legal requirements designing implementing technical choice centralisation decentralisation another question clarified caseby-case basis designing technical general rule centralised allow operators exercise higher level control influence might good thing example underlying aim incorporate features contribute protection security yet bad thing since potential misuse – either malicious third parties wanting steal sabotage processing operators exploiting large volumes amassed purposes notified subjects – greater stored centrally processing controlled centrally designed appropriately however decentralised help decrease prevent linkability reduce disruptions overall availability 118 part e ata children young people care-dependent persons persons disabilities extent encroach upon individual ’ personality high level responsibility autonomy granted demanded users assemble configure operate devices represents particular challenge attempting design technologies foster selfdetermination ethics commission recommends federal government step support r efforts technical standards end devices urges federal government lobby level introduction technical requirements aimed safeguarding self-determination product safety private sphere particular reference end devices consumers ethics commission takes view following principles minimum enshrined end device requirements adopted ●products protected cyber attacks improper measures taken commensurate need protection comply state art suitable guarantees provided particular sensitive e. g. health high level cyber resilience achieved joint task incumbent upon state industry individual ●users able times identify functions currently enabled particular able whether camera microphone gps sensors switched whether device connected internet whether transferred outside closed local area ●it easy turn transfers including transfers outside local area stored locally function switched transferred without user ’ consent next switched true individual applications e. g. smartphones smart tvs ●if basic device functions technically possible without transfers kind functions remain available transfers turned e. g. smart fridge continue keep contents cool ●devices supplied “ user onboarding ” software onboarding take place automatically devices first put operation possible repeat onboarding process often necessary even second users provided users cover mode operation collection processing user ●if end devices direct connection internet e. g. routers secured using password possible put operation without changing factory password beforehand side passwords allowed comply state art 119 e 3. standards personal way products services applications designed huge influence extent controllers processors able comply protection obligations incumbent upon yet manufacturers directly responsible processing personal fall outside scope gdpr controllers want solutions developed therefore insist “ bakedin ” protection.20 mind ethics commission recommends federal government either take steps support action parties aim forcing manufacturers shoulder greater share responsibility suitable measures might include following 20 cf recital 78 gdpr 21 christiane wendehorst verbraucherrelevante problemstellungen zu besitz- und eigentumsverhältnissen beim internet der dinge teil 2 wissenschaftliches rechtsgutachten consumer-oriented problems relating possession ownership structures internet things part 2 scientific legal opinion studien und gutachten im auftrag des sachverständigenrats für verbraucherfragen studies opinions behalf advisory council consumer affairs p. 120 available /www.svr-verbraucherfragen.de/wp-content/uploads/wendehorst-gutachten.pdf ●direct imposition legislator product design product safety requirements ●new effective legal remedies along distribution chain shift burden responsibility inadequate protection design default onto manufacturers21 whereby certain amount progress made directive /771 certain aspects concerning contracts sale goods terms shifting burden responsibility consumers onto retailers along distribution chain comprehensibility transparency protection design encompasses comprehensibility transparency including applications scripts sources elements point time procedure process ethics commission welcomes ongoing efforts develop best-practice models good terms conditions business “ onepagers ” consumers part multi-level approach consumers initially provided simple “ boiled-down ” important processing operations necessary informed detail general terms conditions business protection measures however approach solve underlying problem provided often fails job either inadequate and/or exceeds consumer ’ capabilities consumers make informed purchase decisions standardised machine-readable readily understandable graphical symbols icons introduced level following broad consultations industry civil society icons convey key characteristics products including products apps services “ basic functions available internet connection ” “ internet connection required enhanced functions ” “ user transfers ” “ user tracking ” examples possible characteristics icons could colour coded would particularly useful case product characteristics apply greater lesser degree ethics commission recommends federal government lobby commission develop standardised icons kind keeping article 12 8 gdpr increased transparency consumers could achieved supporting certified electronic shopping assistants would identify product brick-and-mortar online shop serve product consumer format likely understand 120 part e ata ●calls tenders guidelines procurement measures designed way require evidence all-round compliance gdpr including principles protection design default ●incentives encourage compliance particularly high standards protection design default example requirements effect government funding programmes 3.6.2 privacy-friendly product importance protection technical design taken account product enhancement stages applies particular algorithmic since latter typically require bulk example training → part c section 2.2 details privacy-friendly training algorithmic 1 datatilsynet privacy report pp 27 seq available /www.datatilsynet.no/globalassets/global/english/ai-and-privacy.pdf .various options available complying principles protection enshrined article 5 gdpr training algorithmic example datatilsynet norwegian protection authority proposed privacy-friendly means methods training algorithmic systems:1 8. minimisation procedures relation training e. g. synthetic using generative adversarial networks example federated data-minimising variants proposed neural networks 9. encryption procedures differential privacy homomorphic encryption procedures allow retrieval without granting full access database 10. procedures promote transparency achieve higher level comprehensibility traceability ethics commission believes still needed areas applies options privacy-friendly testing algorithmic 121 1 ethics commission recommends measures taken ethically indefensible uses examples uses include total surveillance profiling poses threat personal integrity targeted exploitation vulnerabilities addictive designs dark patterns methods influencing political elections incompatible principle democracy vendor lock-in systematic consumer detriment many practices involve trading personal 2 protection law well branches legal including general private law unfair commercial practices law already provide range instruments prevent ethically indefensible uses however spite widespread impact enormous potential harm little done date terms harnessing power instruments particularly market giants various factors contributing enforcement gap tackled systematically 3 well steps make front-line players e. g. super visory authorities aware existing options urgent need legislative framework force fleshed clearly strengthened certain areas examples recommended measures include blacklisting data-specific unfair contract terms fleshing data-specific contractual duties fiduciary nature data-specific torts blacklisting certain data-specific unfair commercial practices introduction much detailed legislative framework profiling scoring trading 4 order allow supervisory authorities take action effectively authorities need significantly better material resources attempts made strengthen formalise cooperation different protection authorities germany thereby ensuring uniform coherent application protection law attempts fail consideration given centralisation market-related supervisory activities within federal-level authority granted broad mandate cooperates closely specialist supervisory authorities authorities land level remain responsible supervisory activities relating sector however.summary important recommendations action standards personal 122 part e ata 5 ethics commission believes “ ownership ” i. e. exclusive modelled ownership tangible assets intellectual property would solve problems currently facing would create problems instead recommends refraining recognition advises granting subjects copyrightlike economic exploitation respect personal might managed collective societies 6 ethics commission argues referred “ counter-performance ” provided exchange service even though term sums issue nutshell helped raise awareness among general regardless protection authorities court justice ultimately take regard prohibition gdpr “ tying ” “ bundling ” consent provision service ethics commission believes consumers offered reasonable alternatives releasing commercial e. g. appropriately designed pay options 7 stringent requirements limitations imposed personalised risk assessment e. g. “ black ” premiums certain insurance schemes particular processing intrude intimate areas private life causal relationship risk difference individual prices charged basis personalised nonpersonalised risk assessments exceed certain percentages determined stringent requirements respect transparency nondiscrimination protection third parties 8 ethics commission advises federal government consider issues falling heading “ inheritance ” settled federal court justice ’ ruling ephemeral spoken word replaced many situations communications recorded less entirety possibility records handed deceased ’ heirs adds whole dimension privacy risk range mitigating measures taken including imposition obligations service providers quality assurance standards estate planning services national regulations post-mortem protection 9 ethics commission recommends federal government invite social partners work towards common legislative provisions adopted view stepping protection employee based examples best practices existing collective agreements concerns individuals non-standard forms employment taken account process 10 view benefits could gained digitalising healthcare ethics commission recommends swift expansion infrastructures sector expansion range quality digitalised healthcare services include measures better allow patients exercise informational self-determination measures could taken respect include introduction roll-out electronic health record building participatory process involves relevant stakeholders procedures reviewing assessing medical apps insurer-funded consumer-funded health markets 123 e 3. standards personal 11 ethics commission calls action significant enforcement gap exists regard statutory protection children young people sphere particular attention paid mandatory provision technologies including effective identity management default settings guarantee reliable protection children young people familyfriendly i. e. neither demand much parents guardians allow even encourage excessive surveillance home environment 12 standards guidelines handling personal vulnerable care-dependent persons introduced provide greater legal certainty professionals care sector time consideration given clarifying relevant legal provisions living wills include dispositions regard future processing personal far processing require care-dependent person ’ consent e. g. dementia patients provide legally valid consent 13 ethics commission believes number binding requirements introduced ensure privacy-friendly design products services principles privacy design privacy default gdpr imposes controllers already put practice upstream manufacturers service providers requirements would particularly important regard consumer equipment context standardised icons introduced consumers able take informed purchase decisions 14 action taken number different levels provide manufacturers adequate incentives implement features privacy-friendly design includes effective legal remedies pursued parties along entire distribution chain ensure manufacturers held accountable inadequate application principles privacy design privacy default consideration given particular requirements built tender specifications procurement guidelines bodies conditions funding programmes applies privacy-friendly product including training algorithmic 15 debates protection tend quite rightly centre around natural persons important ignore fact companies legal persons granted protection almost limitless ability pool together individual pieces means obtaining comprehensive picture company ’ internal operating procedures passed competitors negotiating partners parties interested takeover bid poses variety threats – inter alia sovereignty germany europe – view significant volumes flow third countries many ethics commission ’ recommendations action therefore apply mutatis mutandis basis legal persons ethics commission believes action taken federal government step level data-related protection afforded companies 124 part e ata 4. improving controlled access personal types personal non-personal represent key resource within economy serve vital ingredient many applications foster good breakneck speed technologies – benefit every one us enormously – attributed part ability evaluate generated billions users although protection always remain central priority applications involving personal people asking whether general improvements area controlled access personal might ethically tenable even desirable keeping principle sharing good → section 1.3 within framework prescribed protection law 4.1 enabling uses personal 4.1.1 preliminary considerations serves basis almost technical achievements current onslaught digitalisation means data-based becoming increasingly important significance already recognised gdpr backed certain cases national law i. e. german federal protection act bundesdatenschutzgesetz bdsg protection acts länder ethics commission wishes emphasise fact processing operations involving genetic biometric health enormous value terms furthering goals promoting preventive methods developing diagnostic therapeutic approaches holds promise significant progress certain areas – depending problem tackled – rely large pools issue releasing health purposes referred “ donation ” recurrent topic debate term “ donation ” misleading however donated – unlike organs money – reused often necessary parallel even donor 22 cf conference independent protection authorities federal government länder orientierungshilfe der aufsichtsbehörden für anbieter von telemedien guidance supervisory authorities telemedia providers p. 14 available /www.datenschutzkonferenz-online.de/media/oh/0405_oh_tmg.pdf .provided part described public-good activity terms way uses e. g. providing healthcare services developing sustainable mobility concepts improving living conditions broader sense ethics commission recommends full made existing privileges protection law viewed particularly valuable good weighing competing interests.22 additionally recommends länder exercise regulatory powers already hold example area higher education law within framework protection law way foster innovation keeping aforementioned notion special privileges broad interpretation placed term “ scientific ” context inter alia reference consistent past decisions federal constitutional court irrelevant whether question carried government-funded private institutions ethics commission wishes point – challenging though task – appropriate balance sought researchers ’ fundamental subjects ’ informational self-determination carrying weighing interests required law special priority accorded protection sensitive associated subjects patients insured parties example duty confidentiality imposed certain individuals doctors subject code professional secrecy cf section 203 german criminal code strafgesetzbuch stgb apply work institutions latter collected stored individuals question procedural precautions imposed law view protecting informational self-determination would need observed 125 e 4. improving controlled access personal 4.1.2 legal clarity certainty although law currently stands permits promotes data-based questions interpretation arise relation certain details questions require clarification supervisory authorities courts example yet definitively clarified whether processing already lawfully collected one purpose e. g. healthcare provision – basis article 5 1 b gdpr light recital 50 “ appropriate safeguards ” within meaning article 89 gdpr – automatically deemed lawful processed purposes whether requirement separate legal basis pursuant article 6 1 – 3 article 9 gdpr applies first collected example section 27 federal protection act states healthrelated processed express consent provided interests “ substantially outweigh ” subject ’ interests suggested certain quarters process invoked party collected first place similar uncertainty reigns scope term “ ” regards product enhancement even though legal framework exists data-based germany inter alia relation healthrelated special categories finer details regulatory framework lack uniformity country ’ federal structure means federal government länder hold constitutionally enshrined legislative powers perspective resulting legal uncertainty exacerbated yet ongoing lack reliable guidance particular regards criteria met order consent deemed valid order subject ’ interests “ substantially outweighed ” interests within meaning section 27 federal protection act legal uncertainty could prove stumbling data-based germany ethics commission believes recommendations action interpretative criteria therefore developed – perhaps conference independent protection authorities federal government länder involvement relevant stakeholders politics healthcare industry civil society – relevant rules applied feasible legally compliant way pseudonymisation anonymisation standards → section 4.2 view harmonisation aimed overcoming regulatory discrepancies field different regulatory approaches member states division regulatory scope federal protection act protection acts länder special regulations specific subjects ethics commission recommends federal government push synchronisation research-specific legal bases federal protection act protection acts länder subjectspecific acts b drive forward projects level aimed greater harmonisation regulatory frameworks put place member states respect protection c lobby duty notification incumbent upon member states adopting national laws area establishment clearing house cross-border projects 126 part e ata 4.1.3 consent processes sensitive voluntary informed explicit consent subject critically important means protecting individuals test subjects participating projects particularly case clinical involving health particularly sensitive categories provides test subject opportunity exercise informational self-determination since necessitates provision easy-to-understand project ensures test subject discover later date values preferences prevent participating study protective instrument enshrined law improves transparency therefore increases people ’ level confidence least among benefits fact promotes integrity researchers yet researchers act controllers face considerable challenges comes obtaining informed consent particularly project involves sensitive example researchers want embark project using health already available database subjects contacted consent obtained unless subjects originally consented reuse future provided – term preferred within ethics discourse – broad consent researchers wishing health collected course routine medical care purposes first contact patients ask grant informed consent task fraught huge practical obstacles mind ethics commission recommends appropriate model procedures obtaining consent designed developed view making easier process purposes.with explicit reference link exists consent subject ’ fundamental ethics commission calls innovative consent models sector dynamic consent models involve tailoring declarations consent individual context already trialled example connection ensured consenting party remains able control even granting consent order ensure case ethics commission recommends emphasis placed design privacy management tools pmt personal management pims → section 4.3 sector consent assistants agents consent assistants kind make significantly easier subjects keep track processing operations granted consent even operations commenced equally make possible go back ask subjects consent circumstances change provide subjects straightforward way revoking consent calls heard increasingly often – particularly connection using health – blanket consent models involve subject granting consent wide range uses field without reference specific course treatment event although sector advance compelling reasons models kind number concerns obstacles overcome adopted particular need consent informed linked specific purpose would make impossible take consenting party ’ preferences values account differentiated basis even far-reaching legal safeguards provided misuse encroachments upon privacy 127 e 4. improving controlled access personal backdrop ethics commission recommends discussion innovative model known “ meta consent ” .23 appropriately informed – without situation consent specifically required – subject decides type projects contexts wishes grant consent type consent involved specific broad consent limited basis considerations following ●research context e. g. private commercial non-commercial national international ●data sources e. g. electronic health record tissue health lifestyle wearables ●type e. g. preventive cancers neurodegenerative disorders kind health researchers later wish specific project subject informed advance given opportunity object 23 thomas ploug søren holm bioethics 30:9 pp 721 seqq.each real-life implementation model oversight trust scheme ethics commission another responsible tasked ensuring consenting party ’ preferences fact taken account possible subject amend terms meta consent time technical regulatory framework required place example 13 example 13 subject specifies electronic health record commercial specifies blood tissue samples commercial degenerative diseases consents processing electronic health record provided transferred europe company spain would like electronic health record well tissue samples dementia subject informed intention told four weeks object way 128 part e ata deliberating designing model kind care taken ensure constraints placed freedom privilege secondary equivalent scope restrictions imposed current legal preference given meta consent models emphasise ability subjects express values preferences regarding health purposes would increase confidence health governance another ethical question considered accountability – relation relation non-use since potential progress vital areas result discrimination certain groups result exclusion progress example methodological reasons mean clinical studies involving older people suffering several different chronic diseases taking several different kinds medication time necessarily limited scope highquality procedures evaluate health however key findings might obtained interactions different medications actions everyday conditions findings could productive basis extensive treatment patients going forwards mind given significance healthcare sector medical economic perspective ethics commission recommends proactive support “ healthcare ” healthcare provision continuously improved making systematic qualityoriented health generated day-today basis keeping principles evidencebased medicine healthcare imposes high requirements terms multi-level governance requires cross-disciplinary approach healthcare provision puts insured party patient front centre.4.1.4 legal protection discrimination time however ethics commission wishes emphasise parties involved developing designing health-related projects take due account significant potential discrimination opened availability sensitive e. g. subject looks job takes insurance policy technical progress made possible sequence decode genome scientists able analyse biometric behavioural collected course daily life means possible profile individual ’ risk falling ill future typically based likelihood suffer disease – genetic come play relatives affected mind federal government examine possibility including grounds action german general act equal treatment allgemeine gleichbehandlungsgesetz agg well specific bans using person ’ health way analogy corresponding provisions genetic german genetic diagnostics act gendiagnostikgesetz gendg 129 e 4. improving controlled access personal 4.2 anonymisation pseudonymisation synthetic operations involve accessing personal always comply applicable provisions protection law abide rules processing laid provisions – purpose limitation principle appropriate protective measures certain circumstances therefore vitally important businesses users know certain operations either fall outside scope protection law compliant protection law ethics commission believes lack legal certainty number different areas example concerning anonymisation pseudonymisation identification consideration link individuals allegedly anonymised sets synthetic anonymised pseudonymised anonymisation involves processing set personal way link subject broken irrevocably distinction made randomisation generalisation different ways approaching task anonymisation individually combination randomisation involves modifying way anonymised longer matched subject achieved falsifying individual sets example appropriately designed randomisation methods ensure statistical properties original set retained example swapping values rather changing generalisation involves aggregating pieces less detailed age categories instead dates birth names regions instead postcodes periods time instead time stamps accurate nearest second three main strategies identify natural persons set singling method pinpointing sets relating specific individuals larger pool example using unique characteristics make possible identify individuals b linkability method involves linking least two sets relate individual group individuals basis matching values appear sets identifiers spatial coordinates times even small amount available individual augmented using linking strategy allowing identified c inference method involves deriving highly probable value characteristic values number characteristics allowing relating individual augmented increasing likelihood identified 130 part e ata anonymised sets make impossible recreate links existed individuals relate create links first time given technological means reasonably likely available developed time processing cf recital 26 gdpr attacker wishing identify one subjects deanonymisation would find task impossible modifications set – particular addition fuzziness referred noise blurring depending context – ensure impossible pull belong specific individual linkable inferences drawn modifications typically place constraints utility user aware evaluations later carried using set anonymisation procedures optimised mind example retaining necessary level detail relevant characteristics wherever possible applies comparisons different sets interoperability user knows comparisons carried appropriate anonymisation methods designed categorising identical groups required taking account increase risk occur result incorporating sets pseudonymisation involves processing way longer assigned specific subject without additional take form mapping tables cryptographic hash methods example pseudonymisation differs anonymisation reference person legal sense term retained controller prevent unauthorised access additional whenever pseudonymised processed future since otherwise would possible map subjects gdpr refers pseudonymisation several times technical organisational measure reducing risk freedoms natural persons.both anonymisation pseudonymisation involve processing set already available distinguished pseudonyms deployed user side users choose pseudonymised identifiers e. g. user names online services e-mail addresses identifiers provided automatically technological example online id function electronic id card attribute-based authorisation certificates designed protection concerns mind vast majority cases pseudonyms provides little way protection identification subject particularly across contexts communication partners allows user-specific profile linked augmented conversely constantly changing “ transaction pseudonyms ” restricted specific context making much harder identify individual question internet-based procedures aimed concealing link subject relating subject generally regarded anonymisation strict sense term nevertheless provide level protection identification observation simple web proxies make possible surf internet using identifier i. e. ip address intermediary server multiple users whose identifiers known proxy server therefore identifier far destination web servers concerned provided avoid identifying cookies etc steps prevent identification taken arranging multiple intermediary servers one behind another example mix networks tor mix cascades jondo noise added sending artificially created “ dummy traffic ” additional obstacle path anyone attempting observe users 131 e 4. improving controlled access personal 4.2.1 procedures standards presumption rules often possible anonymise – i. e. completely break link subject belong way recreated – without losing ’ utility time however perfect anonymisation often required firstly many goals upon closer examination achieved using somewhat lower level utility secondly gdpr already contains exemptions processing operations serve good e. g. sector meaning even personal processed without obtaining consent subjects nevertheless efforts aimed developing effective anonymisation technologies procedures stepped view allowing processed wholly outside scope gdpr ultimately legal certainty achieved developing standardised technologies procedures always take due account whirlwind pace technological ethics commission therefore recommends federal government lobby – particular level – easy-to-use anonymisation standards would benefit subjects users pseudonymisation measures commensurate level risk faced subjects private lives featured agenda federal government ’ summit 24 federal office security technical guidelines bsi tr-02102 cryptographic mechanisms recommendations key lengths last updated available /www.bsi.bund.de/shareddocs/downloads/en/bsi/publications/techguidelines/tg02102/bsitr-02102-1.pdf __blob=publicationfile v=9 .in particular anonymisation standards combined rules imposing rebuttable legal presumption would provide legal certainty users could rely processing operations falling outside scope gdpr standard met context important remember restrictions need imposed presumption rules example period validity way analogy cryptographic procedures ,24 authorised methods processing example stating published made accessible unspecified number people long legal basis rebuttable presumption rules federal government support technical best practices industry-specific codes conduct view building experience fields certain fields standardisation anonymisation pseudonymisation procedures impose rules way link subject relating broken making possible compare different sets improving interoperability least areas improved interoperability sought-after outcome ethics commission recommends context-specific rules developed preferred groupings e. g. value ranges age categories postcodes ip addresses similar approach already followed germany ’ statistical offices handling example 132 part e ata anonymisation pseudonymisation procedures carried repositories known least suspected contain personal differ repositories thought contain personal could means least starting point either combination creating link purportedly anonymous subject belong ethics commission recommends binding implementation standardised methods checking whether subjects identified set methods allow user conclude reasonable degree certitude either personal non-personal 4.2.2 ban de-anonymisation presumption rules accompanied appropriate bans de-anonymisation infringement bans i. e. cases proves possible identify subject using formerly anonymous example result technological developments subject penalty bans would need designed way avoid placing roadblocks way detection removal links subjects repositories since options de-anonymisation available investigated view developing appropriate anonymisation standards verifying effectiveness addition introduction bans de-anonymisation penalties infringement misused pretext downgrading standards apply anonymisation diluting meaning term “ personal ” gdpr since companies involved vitally important efforts drive forward anonymisation using technical means would otherwise placed competitive disadvantage applies reversal pseudonymisation absence justified reasons list drawn 25 jörg drechsler nicola jentzsch synthetische daten innovationspotenzial und gesellschaftliche herausforderungen synthetic potential innovation societal challenges stiftung neue verantwortung available /www.stiftung-nv.de/sites/default/files/synthetische_ daten.pdf .4.2.3 synthetic distinction made genuine synthetic i. e. generated artificially rather collected directly real world synthetic boast several advantages real-world 25 firstly produced quantity particularly important dealing simulations real-world generated secondly steps taken synthetic created ensure entire range values mapped comprehensively possible e. g. order test technical would behave confronted unusual combinations thirdly quality synthetic measured necessary guaranteed individual cases properties set real-world reference retained alternatively distortions occurring sets real-world pinpointed removed order avoid discrimination set synthetic contains references persons anonymous fall within scope gdpr ethics commission recommends federal government support field synthetic number different issues including question whether extent contexts synthetic might replace realworld processing operations closely synthetic resemble real-world terms properties ethics commission recommends investigations creation synthetic particular emphasis topics including quality avoidance bias discrimination 133 e 4. improving controlled access personal 4.3 controlled access management trust schemes 4.3.1 privacy management tools pmt personal management pims ever complex environment one major challenges faced individuals exercising lack oversight personal – subjects typically records documenting times granted consent example sharing original controller result “ scattering ” significant decrease transparency corresponding increase protection risks subjects → section 3.3.6 regarding problem trading currently enough standards software tools subjects track control ongoing basis granted access transferred would necessary exercise effectively increasing number technical institutional measures proposed response problem privacy management tools pmt range applications make consent management easier users dashboards etc tools automatically implement individual user preferences “ agents ” much provision technical applications rather service end common term personal management pims services range single sign-on services local safes online storage offers comprehensive less third-party management user trust models designed trust models pims support selfdetermination shouldering responsibility exercising subject ’ protection law granting withdrawing consent exercising rectify erase portability object ethics commission recommends federal government promote innovation standardisation relation software tools services kind 4.3.2 need regulation pmt/pims notwithstanding privacy management tools/ personal management pose risks fail comply certain requirements go beyond scope gdpr tools fail properly designed example risk subjects empowered exercise true self-determination instead unwittingly find path external determination particular privacy management tools/ personal management designed way subjects “ write blank cheque ” handing majority decisions operators tools/systems result subjects taking decisions contrary interests influence tools/systems would ultimately inconsistent ethical value self-determination privacy management tools/personal management available aids subjects usurp power latter take self-determined decisions certainly manipulate using dark patterns → section 3.2.2. 134 part e ata given significant risks tools pose fundamental lack options subjects carry quality assurance measures ethics commission recommends federal government develop quality standards privacy management tools/personal management introduce certification monitoring latter apply particular act behalf place subject – result technical design – play major role steering channelling subject ’ decisions cases stored directly operators tools/systems i. e. stored decentralised basis simply managed possible provision made company ’ insolvency liquidation privacy management tools/personal management operate reliably cooperation part relevant controllers guaranteed possibility achieve wideranging coverage required imposing legal obligation applies appropriate conditions controllers within meaning gdpr view ensuring access personal monitored tool/system relevant terms protection reaches tool/system tool/system effectively protect subject ’ interests relation personal sector-specific approach – social networks example – might realistic option start with.in view ethics commission kind could either operated non-profit basis without involvement commercially motivated actors – charitable foundations similar independent bodies – organised private-sector enterprises provided operator derives profits managing rather using either case fiduciary duties owed subject precisely defined legislation involvement parties conflicting interests ruled appropriate opportunities oversight built whole minimise bias discrimination privatesector option chosen necessary ensure operator ’ commercial motivations undermine role plays custodian subject ’ interests operators access personal based union ethics commission recommends federal government lobby appropriate amendments gdpr form clearer legally secure framework privacy management tools/personal management steps taken addition action legal matters relating mandates etc prevent excessive centralised storage personal since arrangements kind increase level risk subjects event cyber attacks similar incidents machineinterpretable formats communication protocols standardised automated execution services 135 e 4. improving controlled access personal 4.3.3 pmt/pims potential interface economy provided appropriate regulations adopted privacy management tools/personal management could serve dual function one hand tools/systems might help individuals exercise informational self-determination effectively verify compliance limitations imposed hand however could release confines “ silos ” allow within economy particular exercising portability granted article 20 gdpr main idea underlying privacy management tools/ personal management improve individual ’ control personal promote third-party access indirect access function might however compatible principle underpinning trust schemes third parties allowed access pursue certain purposes approved subject → connection example section 4.1.3 economic exploitation served subject ’ interests took place express consent → section 3.3 discussion problems raised treating personal economic asset ethics commission believes – decided privacy management tools/personal management play dual role serve platform legally secure access companies – ensured qualified dual-function tools/systems ultimately subvert goal protecting subjects ’ strict compliance principles privacy ethics design enforced particular objective pursued broadest possible exploitation “ scattering ” ethics commission wishes emphasise fact privacy management tools/personal management continue serve dedicated custodians subjects ’ interests conflicts interest ruled 136 part e ata 4.4 access portability 4.4.1 promotion portability portability granted article 20 gdpr tool subject determine whether companies gain access personal another company already collected companies includes receive provided “ structured commonly machinereadable format ” transmitted directly another controller portability two main implications prevents unwanted lock-in effects subjects switch providers thereby protecting individual subjects ’ economic selfdetermination free competition b even subjects switch providers allows ask controller make available either companies provides companies option gaining access might otherwise available bearing mind need separate legal basis processing protection law e. g. consent contract .26 26 example debates requirement separate legal basis kind protection law article 29 protection working party guidelines portability wp 242 rev 01 last revised adopted 5 p. 7 available /ec.europa eu/newsroom/document.cfm doc_id=44099 .despite fact providing “ structured commonly machine-readable format ” basic prerequisite met order subjects exercise portability effectively date requirement subject enormous range varying interpretations practice ethics commission therefore recommends federal government protection authorities – implementation recital 68 gdpr – support industryspecific codes conduct standards level portability realised uniformly effectively practice benefit parties involved absence intermediaries → section 4.3 stimulus exercise portability often stems company gained customer companies offer convenient automated process subjects exercise portability likely particularly successful e. g. provider map service allows ported mobility service provider click button grounds assuming – view potential network effects effects – companies likely benefit portability least medium term already hold dominant market accumulated huge amounts ethics commission therefore recommends federal government observe developments closely far judges necessary lobby level measures specifically encourage facilitate porting market-dominant data-rich companies market participants including start-ups 137 e 4. improving controlled access personal 4.4.2 scope portability extended debates ongoing whether scope portability extended various ways particular expanding cover raw provided controller e. g. certain forms processed derived widening include dynamic real-time portability e. g. real-time streaming flows things currently stand recommendation ethics commission proposes federal government lobby amendments gdpr aimed extending scope current portability given gdpr force short period time “ wait ” approach instead adopted clarity gained practical application supervisory practice protection authorities interpretation courts 4.4.3 portability interoperability interconnectivity network effects e. g. case messenger services mean portability alone sufficient mitigate risks posed existing future service oligopolies lower barriers market entry competitors extent represent serious challenge market-dominant providers ethics commission therefore recommends federal government push introduction sector-specific interoperability obligations sort previously imposed postal services mobile telephony example time measures taken ensure interoperability features comply protection principles privacy-friendly default settings examples include option different changing identifiers instead single universal identifier reduction central components collect large volumes suitable examples interoperable technical interaction different levels.asymmetric interoperability obligations could imposed powerful companies market entrants respectively example market-dominant provider messenger services might obliged allow customers smaller providers send messages directly customers allow customers send messages directly customers smaller providers time however ensured interoperability requirements abused purpose increasing yet flow personal towards data-rich powerful companies risk reliably averted would useful impose certain interconnectivity obligations e. g. short messaging services social networks view counteracting concentration effects networks promoting aims portability effectively i. e. healthier competition easier access market entrants data-intensive economy model kind prerequisite building strengthening certain basic services society europe thereby promoting sovereignty germany europe 138 part e ata 4.5 crowdsensing good crowdsensing hailed way opening resources society economy order deploys users ’ technical devices form “ sensors ” collect certain locality example forward higher-level instance analyses collected ethics commission acknowledges potential inherent especially put good example crowdsensing smart city real-time analysis traffic conditions state repair infrastructure air quality time however ethics commission believes achieving ethically appropriate design significant challenge analysis carried using crowdsensing techniques typically extremely high level granularity meaning involved fall category “ sensitive ” perspective individuals generated certain circumstances perspective anyone vicinity efforts therefore stepped introduce standards anonymisation pseudonymisation → section 4.2 view preventing situations traced back non-consenting users potentially persons affected forms misuse crowdsensing-related transfers overstrain resources users ’ devices raise security issues.consideration given points even users participate voluntarily intentionally crowdsensing programmes “ participatory sensing ” thought therefore given substantive limitations consent exist connection → section 3.2 even purposes serve good always ensured requirements outlined legislation – particular protection law consumer protection law – complied full case remembered decisions measures taken government agencies based solely customarily collected using participatory sensing techniques since necessarily incomplete owing voluntary nature participation likely exhibit bias ethics commission believes discussion whether crowdsensed personal collected forwarded compiled without user ’ knowledge “ opportunistic sensing ” ignores potential measures violate fundamental principles protection believes decisions taken case-by-case basis whether legal obligation justifiably imposed force subjects make available technical devices devices collected forwarded automatically extent analysis promotes vital interests 139 summary important recommendations action improving controlled access personal 16 ethics commission identifies enormous potential purposes serve interest e. g. improve healthcare provision protection law currently stands acknowledges potential principle granting far-reaching privileges processing personal purposes uncertainty persists however particular regards scope so-called privilege secondary scope counts “ ” context product ethics commission believes appropriate clarifications law necessary rectify situation 17 fragmentation research-specific protection law within germany among member states represents potential obstacle datadriven ethics commission therefore recommends research-specific regulations harmonised federal land level different legal within introducing notification requirement research- specific national law could bring improvement could establishment clearing house cross-border projects 18 case involving particularly sensitive categories personal e. g. health guidelines produced researchers obtain consent legally compliant manner innovative consent models promoted explicitly recognised law potential options include roll-out consent assistants recognition so-called meta consent alongside endeavours clarify scope privilege secondary 19 ethics commission supports principle move towards “ healthcare ” healthcare provision continuously improved making systematic quality-oriented health generated day-to-day basis keeping principles evidence-based medicine progress made direction however greater efforts made time protect subjects significant potential discrimination exists sensitive categories might involve prohibiting exploitation beyond defined range purposes 140 part e ata 20 procedures standards anonymisation pseudonymisation central efforts improve controlled access formerly personal legal presumption compliance standard achieved longer qualify personal “ appropriate safeguards ” provided respect subject ’ would improve legal certainty long way measures accompanied rules – pain criminal penalty – prohibit de-anonymisation anonymised e. g. becomes available would allow re-identification subjects reversal pseudonymisation absence narrowly defined grounds field synthetic shows enormous promise funding funnelled area 21 fundamentally speaking ethics commission believes innovative management trust schemes hold great potential provided designed robust suited real-life applications compliant protection law broad spectrum models falls heading ranging dashboards perform purely technical function privacy management tools pmt comprehensive consent management services personal management services pims underlying aim empower individuals take control personal overburdening decisions beyond capabilities ethics commission recommends field management trust schemes identified funding priority wishes make adequate protection legitimate interests parties involved require additional regulatory measures level regulatory measures would need secure central functions without operators since scope action would otherwise limited hand necessary protect individuals parties assume acting interests reality prioritising financial aims interests others event feasible method protection found trust schemes could serve vitally important mediators protection interests economy interests 22 far portability enshrined article 20 gdpr concerned ethics commission recommends industry-specific codes conduct standards formats adopted given underlying purpose article 20 gdpr make straightforward change provider allow providers access easily important evaluate carefully market impact existing portability analyse potential mechanisms prevented small number providers increase yet market power findings evaluation available expansion scope example cover provided subject real-time porting would seem premature advisable 23 certain sectors example messenger services social networks interoperability interconnectivity obligations might help reduce market entry barriers providers obligations designed asymmetric basis i. e. stringency regulation increase step company ’ market share interoperability interconnectivity obligations would prerequisite building strengthening within europe certain basic services society 141 e 5. debates around access non -personal 5. debates around access non-personal economy play key role future competitiveness german companies growing penetration internet things iot internet services ios means collected automatically sensors potentially serve basis developing business models innovations acquiring evergreater industrial significance germany cutting edge developments far many iot/ios-related technologies concerned e. g. sensor mechanical engineering embedded plays leading role broader field industrial production services cater sector given increasingly cut-throat nature international competition build head start order safeguard country ’ future prosperity differentiated robust landscape diversified economic structure reputation global leader key technological segments industry 4.0 put germany perfect leverage potential associated economy basis creating future value 5.1 appropriate access macroeconomic asset ethics commission believes providing appropriate access german companies decreasing current level dependency small number oligarchs would go long way towards building market-oriented economy serves good towards strengthening sovereignty germany europe connection access narrower sense firstly relates extent required particular business model project de jure de facto basis order benefit access narrower sense however stakeholders sufficient degree dataawareness skills necessary make access proves disproportionately advantageous stakeholders already built largest reserves best infrastructures hand ethics commission therefore wishes stress factors referred always receive due attention discussing whether improve access keeping asisa principle awareness – skills – infrastructures – stocks – access discussions section non-personal genuinely non-personal hold enormous potential science economy society yet potential often underestimated scientific categorised non-personal include originating technical sciences e. g. engineering materials science fields physics e. g. particle accelerators biology e. g. plant animal kingdoms geology chemistry environmental weather ocean economic e. g. financial markets analysed using big methods example develop applications example non-personal hold enormous value science economy society focused support therefore provided researchers using systematic efforts undertaken make access easier task broad nature gdpr ’ definition “ personal ” means safely assumed substantial proportion repositories mixed nature i. e. contain non-personal could become personal time processing personal vital prerequisite certain activities fall heading economy provide benefits individuals general discussion access concentrates solely non-personal would therefore appear counter-productive appropriate approach would work towards general access arrangements superseded protection law cases personal processed meaning activities falling heading economy would need comply provisions gdpr equally forgotten gdpr already allows economic exploitation personal many circumstances addition consent example article 6 1 gdpr five additional justifying grounds article 6 1 b – f explicitly tailored economic interests needs 142 part e ata 5.2 creation necessary framework conditions 5.2.1 awareness raising skills create value presupposes operators whether belong private sector serve interest adequately well-informed relevant options risks skills required involve drawing technical economic ethical legal knowledge → part section 3. certain areas german economy companies still tapped potential exists make productive flows repositories cases benefit ethics commission welcomes steps taken raise awareness build skills various stakeholders e. g. chambers industry commerce associations vocational institutions value-based approach improving skills across board however required example form initial continuing training courses objective courses always raise awareness risks posed individuals society viewpoint protection law ethics government bodies slow recognise import implications huge volumes already generated statistical purposes example advantages risks entailed models share businesses government-to-business g2b sharing businesses share operating business-to-government b2g sharing current reticence part authorities utilise opportunities means large-scale shift mindset required modelled forerunners field e-governance scandinavian countries estonia ethics commission recommends federal government support work area relevant institutions.5.2.2 building infrastructures needed databased economy although germany continues occupy leading field science tech companies providing vital analysis infrastructures economy primarily hail usa increasingly china means great deal – consumer enterprise – stored outside europe analysed third countries using software belonging non-european companies makes crucially important germany develop data-based economy using home-grown infrastructures ethics commission recommends federal government support following measures level initiated commission establishment expansion support centre sharing b model contracts economy c support forums consortiums tasked developing open standards legally compliant exchanges particular formats programming interfaces apis tailored exchanges increase traceability flows promotion platforms legally compliant exchanges e establishment open science cloud eosc key precursors achievement sovereignty germany include access control sensitive option carry appropriate audits critical analysis software would require manufacturers disclose source code design criteria example given ethically problematic nature analyses wherever possible carried within geographical purview german legal 143 e 5. debates around access non -personal ethics commission expressly welcomes number initiatives federal government stakeholders aimed creating secure international spaces spearheaded germany different application domains allowing companies organisations sizes sectors industry retain sovereignty exchange securely other.the ethics commission recommends setting ombudsman ’ office federal level provide assistance support relation negotiation problematic access agreements dispute settlement competent protection authorities consulted cases involving personal decision-making power ultimately rest aforementioned authorities order avoid conflicting decisions establishment infrastructures federal government ’ initiatives aimed establishing infrastructures include following f efforts german foundation deutsche forschungsgemeinschaft establish national infrastructure aim implement science-driven process systematically opens repositories provides long-term storage backup accessibility across boundaries different disciplines länder g open international spaces consortium ids formerly industrial space promoted federal ministry education aim provide companies organisations taking part standardised interface platform exchanging based federal architecture concept h initiative develop comprehensive network big centres nodes distributed throughout germany part national generally accessible ecosystem aim network provide access large amount variety 24/7 basis time offer easy-to-use tools along entire value creation chain preparation analysis visualisation exploitation develop basis user feedback.in addition technical platforms interesting developments include platforms developed federal government collaboration associations view promoting coordinated standardisation practical implementation data-hungry applications form socially economically innovative future projects industry 4.0 smart service world level commission implementing similar projects e. g. futureoriented fiware project currently developing freely available toolbox open-source software components configure innovative internet services short space time big value public-private partnership organised commission big value association bdva developed interoperable data-driven ecosystem level launchpad business models using big already delivered impressive number flagship projects lastly institute innovation eit fostered emergence europe-wide technical economic ecosystem involving 180 companies institutions 144 part e ata 5.2.3 sustainable strategic economic policy far economy concerned biggest challenges facing europe include lack sustainable funding often problem projects paucity venture capital latter required make ideas already developed marketready inject capital appropriate points start-ups reach competitive one reasons usa successful field products services country ’ many “ angels ” willing invest billions high-risk projects many cases forfeit investments another trend worth noting innovative companies often bought foreign companies forced international investors move headquarters countries outside europe thinking outside “ path ” explicitly endorsed ethics commission → part g german start-ups given access larger pool funding better tax incentives germany continue attract brightest best remain cutting edge sectors education administration medicine characterised high level interest existence mandatory values expressed legal professional ethics time enormous potential achieve efficiency gains digitalisation sectors global platforms yet gained stranglehold market extent areas ethics commission therefore recommends funding channelled three areas particular incentivise platforms germany reflect values internationally scalable 27 solution endorsed preliminary drafts 2 3 ali-eli principles economy footnote 1 example.5.2.4 improved industrial property protection perspective economy ethics commission benefit introducing exclusive often discussed using terms “ ownership ” “ producer ” → section 3.3.2 kind would need incorporated aligned existing provisions protection law intellectual property law rules personality trade secrets ownership storage media etc. would nothing increase already significant level complexity legal uncertainty without indication kind would necessary even particularly helpful making marketable ethics commission nevertheless believe calls made industry government bodies afford limited third-party effects contractual agreements e. g. restrictions utilisation onward transfer recipient justified legal situation currently stands thirdparty effects kind afforded extreme situations unless protection intellectual property law applies including “ sui generis ” protection databases consideration given extending scope recognition third-party effects along lines model provided article 4 4 trade secrets directive directive /943 27 according approach acquisition disclosure would considered unlawful whenever person time acquisition disclosure knew ought circumstances known obtained directly indirectly another person using disclosing unlawfully approach would interests economy fit seamlessly existing primarily contract-focused model 145 e 5. debates around access non -personal 5.2.5 partnerships ethics commission believes cautious current legal framework would appropriate field anti-trust law breakneck pace developments economy poses fresh challenges field law return provisions anti-trust law pose fresh challenges companies ethics commission recommends federal government pay particularly close attention opportunities risks entailed partnerships consideration given introduction mandatory confidential procedure notifying partnerships anti-trust authorities supervisory authorities protection law case personal mention made proposals presented commission experts competition law 4.0 headings “ exchange ” “ pooling ” .5.3 access existing value creation 5.3.1 context fair efficient access plays significant role modern value creation area law suitable regulating fairly efficiently ability various stakeholders access commercial context contract law since branch legal autonomy private entities “ private autonomy ” expressed explicitly time general presumption freely negotiated agreements – except cases market failure – achieve efficient allocation resources thus increase general level prosperity unfair inefficient contractual arrangements arise however result imbalances power asymmetry example certain issues relating access typically underestimated negotiation process result skimmed omitted entirely given dynamic nature data-specific interests correspondingly dynamic assessment obligations → section 2.1 often difficult parties determine exactly access regime look like order remain fair efficient entire term contract insignificant number cases accordingly found later date – contract put test real world – balance interests shifted unpredictable ways benefit one party major impact equilibrium obligations originally agreed since one parties typically stands benefit state affairs contracts often renegotiated opportunity regulate access properly efficiently 146 part e ata particularly complex value creation frequently direct contractual relationship party requesting access party effectively controls interposing link distribution chain example interests fairness efficiency however access arrangements would desirable b2b sector incursions freedom contract form obligation contract currently result almost exclusively provisions anti-trust law well small number general provisions law case essential commodities monopoly positions generally speaking however restricted small number extreme situations 5.3.2 presence contractual relationship estimation ethics commission steps initially taken view ensuring fair efficient access arrangements include raising awareness promoting skills → section 5.2.1 practical support form model contracts provide fair distribution access infrastructures intermediaries facilitate shared ensuring protection trade secrets example → section 5.2.2 28 commission towards common space 232 final 25 p. 10 available /ec.europa.eu/ transparency/regdoc/rep/1//en/com--232-f1-en-main-part-1.pdf .in cases contractual relationship already exists principles fair access enforced primarily contract interpretation including way gap-filling courts example assuming existence appropriate contractual ancillary obligations standard contract terms control pursuant section 307 civil code “ fairness test ” however one problems inherent substantive fairness tests virtual absence default provisions benchmark tests specific abusive contractual practices could therefore spelt explicitly blacklisted contract terms → section 3.2.3 corresponding recommendations b2c contracts significant changes occur since conclusion contract possible party invoke provisions frustration contract section 313 civil code connection ethics commission wishes reiterate general basic principles governing businessto-government b2g sharing formulated commission communication entitled “ towards common space ” .28 basic principles provide following transparency regarding access purposes using b recognition several parties contributed shared value creation c respect ’ commercial interests undistorted competition e minimised lock-in particularly regard repositories potentially include personal well non-personal consideration could given expanding principles include informational selfdetermination subjects principle “ harm ” 147 e 5. debates around access non -personal 5.3.3 absence contractual relationship contractual relationship participants value creation despite support provided neither rules interpretation contracts substantive fairness tests standard contract terms apply impossible rely frustration view ethics commission however simple fact party requesting access contributed generation means special legal relationship exists party party effectively controls → section 2.1 true relationship exists within value creation primarily shaped contracts special legal relationship give rise certain duties fiduciary nature including duty enter negotiations fair efficient access arrangements future legal framework make explicit reference fact ethics commission therefore recommends amending section 311 civil code include subparagraph mentioning special relationship exists participants value creation e. g. suppliers manufacturers brokers end users would entail certain relevant duties including regard enormous significance general legal economic relations means justified grounds inserting subparagraph law rather subsuming relations general heading “ similar business contacts ” would neither constitute separate legal basis processing personal would restrict protection law way 29 discussion personal louisa specht datenrechte – eine rechts- und sozialwissenschaftliche analyse im vergleich deutschland – usa teil 1 rechtsvergleichende analyse des zivilrechtlichen umgangs mit daten den rechtsordnungen deutschlands und der usa abidagutachten analysis perspective legal social sciences based comparison germany usa part 1 comparative law analysis governance civil law within framework german us legal pp 89 seqq available /www.abida.de/sites/default/files/abida_gutachten_datenrechte.pdf discussion non-personal ali-eli principles economy footnote 1 .beyond consideration could given introducing data-specific rules law obligations based principles referred → section 2 aimed judicial “ gap-filling ” benchmark carrying substantive fairness tests standard contract terms.29 particular provisions contracts kind might define conditions parties entitled access and/or request desistance access and/or request rectification however ethics commission concerned rules specifically spelt law albeit default rules might give rise additional disputes 5.3.4 sector-specific access need identified extensive access within existing value creation priority given sector-specific solutions ethics commission therefore recommends federal government pay greater attention access issues adopting and/or revising sector-specific regulations 148 part e ata 5.4 open sector 5.4.1 preliminary considerations recently revised directive /1024 open re-use sector psi directive national level german reuse act informationsweiterverwendungsgesetz iwg german e-government act e-government-gesetz egovg additional special acts provide sound legislative basis disclosure public-sector basis ogd concepts premise underlying concept open government citizens companies already subsidised generation taxes pay therefore allowed share associated benefits rather incurring double financial burden making public-sector available reuse private sector benefits economy since open government often hold enormous potential private-sector value creation companies develop innovative products services helping increase general level prosperity process looking beyond economy access government vitally important democracy open debate involving society since increases administrative transparency facilitates participation allows oversight fact-based discussions open government many different shapes forms social initiatives innovations social ecological purposes example basic principle therefore ethics commission supports open charter adopted g8 summit defines following central principles governance administrative open default expectation administrative made without compromising privacy b quality quantity high-quality timely fully described open c usable anyone much possible many open formats possible improved governance open transparency sharing expertise regarding collection standards publication procedures e innovation user consultations support future generations creative minds ethically speaking government decided provide commercial operators free-of-charge access instead selling profit otherwise exploiting economic purposes decision would need justified approximated basis corresponding increases prosperity macrosocial level ethics commission wishes draw attention degree tension calls privacy default one hand open default – broader sense – debate protection debate open government personal made legally compliant manner basis open-data concepts guarantee security mechanisms put place protect informational self-determination form explicit implicit restrictions reuse form technical organisational protection measures continue applied general provisions protection law concerning reuse issue furthermore since article 30 gdpr requires “ categories recipients ” documented government bodies almost never monitor compliance “ appropriate safeguards ” required pursuant article 89 gdpr disclosure might point become personal regarded potentially high-risk measure subjects 149 e 5. debates around access non -personal applying ogd concepts area informational self-determination protected fundamental always weighed carefully public-good interests pursued ogd banner freedom protected fundamental freedom ogd recipients exercise trade profession ethics commission submits cases doubt priority given state ’ duty protection compliance duty important individuals able decide freely entrust government bodies particularly apt believe government bodies refrain forwarding personal third parties 5.4.2 legal framework infrastructures ethics commission welcomes federal government ’ national action plan implement g8 open charter efforts part federal government governments länder include ogd concepts digitalising administrations recommends federal government take action ensure across-theboard implementation obligation publish structured unprocessed open default allow without limitations principle free charge already applies direct federal administration section 12a 1 e-government act given aforementioned tension open government protection obligations imposed section 12a e-government act apply relation certain types particular undergone effective anonymisation procedures .the ethics commission welcomes legislator ’ attempts change governance culture within administration acknowledges task made significantly challenging highly fragmented nature current legal situation often difficult – authorities potential ogd users – forge path tangled regulatory thicket made different legal regimes set general specialised rules access reuse e-governance federal government land level complicating factor interplay regulations protection law intellectual property particular copyright law often fiendishly complex practice connection ethics commission recommends merging synchronising various legal bases exist germany well clarifying demarcation lines various legal arrangements another obstacle stands way culture change needs take place fact currently impossible verify reliably whether authorities fact complying provision obligations already force example section 12a 1 e-government act imposes obligation direct federal administrative authorities provide access explicitly states parties requesting access enforceable made publicly available companies wish access therefore deprived effective avenues forcing authorities comply statutory obligation making open default view ethics commission introduction request publication might encourage proactive approach provision open part administrative authorities within limits placed obligation e-government act reuse act quality standards achieved respect provided government bodies another question open current legal situation particular e-government act states obligation provide access met handing unprocessed reused easily manner complies ogd objectives high level quality guaranteed 150 part e ata aside legal framework establishment expansion infrastructure framework e. g. open government portals govdata essential particularly local level e. g. form municipal platforms applies investments appropriate quality assurance tools 5.4.3 state ’ duty protection keeping mind state ’ duty protect entrusted appropriate precautions taken ensure central interests private individuals e. g. relating personal operating trade secrets sensitive confidential relating procurement procedures given comprehensive level protection key interests e. g. security interests interests relating national sovereignty ethical premise underpinning ogd concept – citizens companies already paid tax contributions – places certain constraints reuse particular care taken ensure private sector develop services products ultimately restrict freedom citizens businesses and/or available unfair conditions.the ethics commission therefore recommends federal government make opportunity afforded article 8 recast psi directive developing model conditions standard licences including restricted-use agreements conditions transfer third parties alternatively lobby conditions introduced level even advisable make model conditions mandatory least sector-specific basis based number key considerations including following pursuant article 8 1 psi directive conditions objective proportionate nondiscriminatory justified grounds interest objective shall unnecessarily restrict possibilities re-use shall restrict competition b rules imposed companies contain clearly defined safeguards affected third-parties mechanisms allow compliance rules verified c intellectual property developed using disallow activities carried government bodies fulfilment remit make activities subject payment licence fee product service developed using offered government bodies preferential conditions e companies large market share subject reciprocal obligation make generated operations available identical conditions f business activities take place minimum product service processes take place 151 e 5. debates around access non -personal basic principle compliance agreed safeguards restrictions longer reliably verified transferred copies sent recipient stored infrastructure controlled latter given duty incumbent upon government bodies protect harm third parties even harm would possible de-anonymisation linking sets special consideration given model government bodies allow supervised access supervised processing infrastructures control costs incurred connection passed companies seeking access 5.5 open private sector 5.5.1 platforms operating generated companies levels german economy course everyday business enormously valuable innovation particularly combined generated participants value creation chain german economy already established sector-specific platforms express purpose linking different types examples different platform models include 1 merger several different companies gmbh limited liability company 2 in-house operation single company involvement partners 3 proprietary platform operated service third parties various sectors economy increasingly coming around idea shared platforms common regulatory approaches use.the ethics commission believes reasonable assume within value creation continue organised industrial players sector-specific basis market entrants start-ups continue find opportunities innovate within landscape since market participants stand benefit working together trailblazing start-ups develop disruptive innovations sharing end trend companies club together establish platforms modelled along various lines welcomed allows build industrial know-how already exists europe fosters higher-quality including higher standards protection security ethics commission proposes federal government lend support emergence increasing number private-sector platforms view achieving necessary market effects allowing german businesses harness shared strength compete international stage 5.5.2 additional incentives voluntary sharing already large number business models based private providers voluntarily allowing access example 14 example 14 one case point geoinformation industries take basic geodata cases official sources enrich allowing users access specialist geodata wide range purposes examples include map services openstreetmap google maps feature purely topographical administrative wide range interesting details tailored offerings weather forecasts traffic predictions 152 part e ata ethics commission recommends voluntary access arrangements kind supported addition practical support measures recommended → section 5.2 consideration therefore given additional incentives voluntary sharing example transfers releases open access strategies favourably viewed ●under tax legislation ●under procurement law ●when making grant awards either inside outside sector ●when carrying authorisation procedures voluntary sharing transfers releases open access strategies however envisaged fields referred risk infringing confidentiality requirements procurement law operating trade secrets provisions protection law result 5.5.3 statutory access way contrast debate voluntary sharing main idea underpinning discussion statutory access society “ get something back ” large repositories many members society helped build case social networks example viewed conjunction fundamental value social solidarity public-good interests relevant specific cases concept could serve basis granting extensive respect access disclosure obligation part private individuals.30 30 details viktor er-schönberger thomas ramge das english title reinventing capitalism age big pp 195 seqq 31 frand fair reasonable non-discriminatory 32 “ three-factor test ” features several international agreements basis assessing whether exemption i. e. limitation copyright represents acceptable encroachment copyright holder ’ according test exemptions kind subject three conditions apply certain special cases ii conflict normal exploitation iii unreasonably prejudice legitimate interests holder calls increasingly made test include iv mandatory consideration third-party interests general interests.one potential measure often discussed context improving general access privately held repositories introduction general portability non-personal modelled along lines article 20 gdpr would mean business supplied raw controller would request controller make available business commonly machine-readable format ask controller forward directly third party reasons essentially similar cited arguments extension scope article 20 gdpr → section 4.4.2 ethics commission recommends federal government initially adopt “ wait-and-see ” approach developments relating interpretation article 20 gdpr complexity issue exacerbated yet fact issue proper allocation portability i. e. equivalent “ subject ” regard nonpersonal would raise head range measures ultimately synonymous statutory access discussed view improving general access privately held repositories potential options respect include statutory obligation publish reports containing internal analytics access private individuals e. g. mandatory licensing complies frand31 principles and/or incorporates three-factor four-factor test copyright law32 disclosure general open access based either general model market-share model ethics commission believes least following factors taken account initial examination options 153 e 5. debates around access non -personal need protect personal operating trade secrets access given disclosed b need ensure encroachment fundamental private entities affected access disclosure obligation proportionate relates particular freedom exercise trade profession c need avoid negative impacts competition resulting access disclosure example owing strategic competitors obliged disclose return need ensure incentives still exist invest business models economy e need protect strategic interests german companies face global competition particular consideration given whether companies would still able compete effectively international stage forced provide access repositories giants – already stand head shoulders companies terms proficiency infrastructures particular volumes hold – exploit open-door policy regard ethics commission recommends preference given sector-specific approach far spatial concerned inspire directive provisions transposing national law already set sectorspecific access rules rules apply government bodies however one first privateenterprise applications sector-specific access found payment services industry ethics commission proposes steps 33 jacques crémer yves-alexandre de montjoye heike schweitzer competition policy era special advisers ’ report commission pp 87 seqq available /ec.europa.eu/competition/publications/reports/kd0419345enn.pdf 34 competition framework economy report commission ‘ competition law 4.0 ’ available /www wettbewerbsrecht-40.de/kw40/redaktion/de/downloads/a-new-competition-framework-for-the-digital-economy_.pdf __blob=publicationfile v=3 .should taken identify level demand implementation options number selected industries example media mobility energy sectors 5.5.4 role competition law although framework competition law currently place contains almost provisions relating general thrust applies economy example essential facilities doctrine efd slightly modified form necessary market-dominant company holds exclusive control resource e. g. network/infrastructure crucially important competition neighbouring market aftermarket doctrine relates cases lock-in effects mean consumers primary product unable exercise full freedom choose secondary market e. g. market repairs/spare parts third-party provider secondary market kind faces anti-competitive barriers.33 yet uncertain legal situation stringent requirements apply amount time money involved relevant procedures means supervisory efforts prevent abuse currently regarded fix-all solution access problems applicable provisions competition law either individually entirety could however act central building framework economic law one crucial components range solutions access problems findings commission experts competition law 4.0 taken account respect.34 154 part e ata 5.6 access public-sector b2g public-interest purposes thought given whether controllers subject obligation grant access specific subsets order allow either public-sector bodies certain publicgood purposes scope obligation access belonging private entities obligations disclose might particularly relevant sector easier access might lead general advances science provided access arrangements designed appropriately take due account subjects ’ corresponding access private-sector might make easier ngos media similar institutions deliver social remit thereby helping protect democratic polity particularly priority given times averting risks e. g. issuing storm warnings view ethics commission preference given sector-specific approach tailors design access disclosure obligations specific requirements constitutional law come play one hand practical circumstances characterise relevant sphere activity health sector mobility sector energy sector regarded particular priorities action respect ethics commission calls broad-based societywide debate precursor decisions general obligations provide access e. g. connection projects serve good ethics commission wishes reiterate basic principles governing business-to-government b2g sharing set commission communication 25 entitled “ towards common space ” :35 35 commission towards common space 232 final 25 pp 13 seq available /ec.europa.eu/ transparency/regdoc/rep/1//en/com--232-f1-en-main-part-1.pdf .a proportionality i. e. justified demonstrable interest proportionate terms details relevance protection b purpose limitation i. e. clearly limited one several purposes assurances obtained unrelated administrative judicial procedures c “ harm ” i. e. respect legitimate interests subjects ’ informational selfdetermination trade secrets commercially sensitive exploitation interests acknowledgement interest goal agreeing conditions reuse preferential treatment government bodies non-discriminatory conditions government bodies reduction overall burden citizens companies e quality management obligation offer reasonable proportionate support help assess quality stated purposes general obligation improve quality f transparency societal participation respect parties agreement objectives insights best practices basic principles serve good starting point drafting provisions freely negotiated contracts exchanges designing extensive sector-specific statutory measures improve access 155 summary important recommendations action debates around access non-personal 24 access companies appropriate non- personal appropriate quality key factor growth economy order benefit enhanced access however stakeholders sufficient degree data-awareness skills necessary make access proves disproportionately advantageous stakeholders already built largest reserves best infrastructures hand ethics commission therefore wishes stress factors referred always receive due attention discussing whether improve access keeping asisa principle awareness – skills – infrastructures – stocks – access 25 ethics commission therefore supports efforts already initiated level promote improve infrastructures broadest sense term e. g. platforms standards application programming interfaces elements model contracts support centre recommends federal government efforts continue matched corresponding efforts national level would advisable set ombudsman ’ office federal level provide assistance support relation negotiation access agreements dispute settlement 26 ethics commission ascribes enormous importance holistically conceived sustainable strategic economic policy outlines effective methods preventing exodus innovative companies acquisition thirdcountry companies excessive dependence third-country infrastructures e. g. server capacities balance struck context muchneeded international cooperation networking one hand resolute assumption responsibility sustainable security prosperity europe backdrop ever-evolving global power dynamic 27 perspective boosting economy ethics commission benefit introducing exclusive “ ownership ” “ producer ” instead recommends affording limited third-party effects contractual agreements e. g. restrictions utilisation onward transfer recipient third-party effects could modelled regime protection trade secrets ethics commission recommends adoption legislative solutions enabling companies cooperate example using trust schemes without running afoul anti-trust law “ partnerships ” 156 part e ata 28 accumulated existing value creation e. g. production distribution chains often enormous commercial significance inside outside value creation many cases however provisions access appear contractual agreements concluded within value creation unfair and/or inefficient lacking entirely certain cases contractual agreement efforts therefore made raise awareness among businesses sectors far outside commonly perceived “ economy ” provide practical guidance support e. g. model contracts 29 ethics commission furthermore recommends cautious adaptations current legislative framework first stage process make explicit reference section 311 german civil code bürgerliches gesetzbuch bgb special relationship exists party contributed generation value creation controller clarifying parties certain quasi-contractual duties fiduciary nature duties normally include duty enter negotiations fair efficient access arrangements consideration given whether additional steps taken could range blacklisting particular contract terms b2b transactions formulating default provisions contracts introducing sector- specific access 30 ethics commission believes open government ogd concepts hold enormous potential recommends concepts built promoted recommends series measures promote shift mindset among authorities something yet fully taken place make easier practice share basis ogd concepts measures include establishment relevant infrastructures e. g. platforms harmonisation improvement existing legal framework currently fragmented sometimes inconsistent 31 nevertheless ethics commission identifies degree tension efforts promote ogd relying principles “ open default ” “ open purposes ” efforts enhance protection protection trade secrets legally enshrined concepts “ privacy default ” ethics commission submits cases doubt priority given duty protecting individuals companies entrusted state often without given choice matter e. g. tax state deliver duty implementing range different measures include technical well legal safeguards misuse 157 e 5. debates around access non -personal 32 particular would beneficial develop standard licences model terms conditions public- sector sharing arrangements make mandatory least sector-specific basis standard licenses model terms conditions include clearly defined safeguards third parties affected access arrangement provision made way ultimately harms interests still greater accumulation market power part big players would likely undermine competition taxpayer pay twice 33 regards open-data concepts private sector priority given promoting supporting voluntary data-sharing arrangements consideration given improvement infrastructures e. g. platforms broad range potential incentives might include certain privileges context tax breaks procurement funding programmes licensing procedures statutory access corresponding obligations grant access considered fall-back options measures fail deliver desired outcomes 34 generally speaking ethics commission believes cautious approach taken introduction statutory access ideally developed sector-by-sector basis sectors level demand analysed include media mobility energy sectors case statutory access even disclosure obligation introduced full impact assessment needs carried examining weighing possible implications include implications protection protection trade secrets investment decisions distribution market power well strategic interests german companies compared companies third countries 35 ethics commission recommends considering enhanced obligations private enterprises grant access interest public-sector purposes business-to-government b2g cautious sector-specific approach however recommended respect well part f algorithmic 160 part f lgorithmic 1. characteristics algorithmic numerous products applications days voice assistants automated lending “ autonomous ” driverless cars based less “ smart ” algorithms due many different forms types technical take seemed advisable ethics commission base considerations general concept “ algorithmic ” → part c section 2.2.5 key questions presented federal government regarding topics “ algorithmic prognosis decision-making processes ” well “ ” therefore discussed together questions concerning algorithmic however following distinctions particular taken account part ethical legal assessment individual algorithmic ●from technical perspective different algorithmic different characteristics spectrum ranges operate completely deterministic basis machine develop action plans independently order achieve goal specified operator algorithmic ●where algorithmic social informatics ethically legally relevant processes established different levels i. e. level pool algorithm technical sense level individuals involved implementation assessment correction ●the purpose consequences using algorithmic vary considerably algorithmic support replace decision-making prognoses often direct impact individuals ’ interests examples include automated lending automated administrative acts however algorithmic link decision-making indirectly established case example various processes constitute “ autonomous ” driving predictive maintenance mechanical engineering ●algorithmic affect different ethical legal principles depending context externally discernible “ action ” “ autonomous ” cyber-physical example typically raises questions key aspect example debate surrounding robotics healthcare principles human-centred design essential assessment algorithmic “ physically embodied ” similar way conversely often ’ externally invisible method making “ decision ” attention discussions example centre ’ transparency principle final decision made accordance article 22 gdpr example automated credit checks however distinction “ action ” -oriented “ decision ” -oriented perspectives becomes upon closer inspection every “ action ” point preceded “ decision ” example construction every “ decision ” impact another component including base “ action ” 161 f 1. characteristics algorithmic ethics commission believes distinctions made particular algorithmic closely involved decision-making processes algorithm make decision ethically substantial sense since value-based preferences accord three different levels involvement algorithmic decision-making distinguished based specific distribution tasks humans machine ●algorithm- based decisions decisions based either whole part obtained using algorithmic calculations examples include clinical decision support provide doctor treatment recommendations using patient electronic medical records based assessment scientific literature taking recommendation consideration doctor makes decision together patient treatment option ultimately selected algorithm-based decisions nevertheless subtly yet significantly influence decisions example algorithmic collates humans/objects/procedures contain value judgment user necessarily aware ●algorithm- driven decisions decisions shaped outputs algorithmic way ’ decision-making abilities capacity self-determination effectively restricted particular decision made within algorithmically determined prescribed paths one example industry 4.0 application whereby part human-machine interaction robotic provides involved production process limited room manoeuvre ●algorithm- determined hence fully automated decisions prima facie made independently fact outputs algorithmic trigger consequences automatically provision made explicit decision examples applications range price differentiations e-commerce fully automated administrative acts known autonomous weapons decisions nevertheless involved sense decided algorithmic purpose way example 1 differences illustrated algorithmic process selecting candidates job algorithmic simply collates individual candidates employer question basis employer make decisions constitutes algorithm-based decision-making process lead algorithm-driven decisions provided employer contains evaluation individual candidates example ranking could significantly influence likelihood individual candidates selected actual restriction employer ’ ability make decisions becomes even apparent already screens candidates advance meaning employer longer even sees applications case algorithm-determined selection process notification regarding acceptance rejection application would automatically provided algorithmic without ever checking selection 162 part f algorithmic classifying algorithmic one three types often difficult hybrids possible within complex software architecture level determination humans point different depending way works example decision-making process algorithmic filters individual candidates advance rejects algorithm-determined point view candidates filtered algorithm-driven remaining candidates.there overlaps practical operation account known automation bias default effects even case algorithm-based decisions humans full decision-making authority tend simply go algorithmic ’ recommendation without carrying sufficiently critical check otherwise would feel uncomfortable need decision would get impression risk blamed wrong decision would increase nevertheless fundamental distinction relevant assigning responsibility risk assessment therefore regulation.figure 7 characteristics algorithmic design implementation adaptationalgorithm-determined algorithm-driven algorithm-based decision 163 f 2. general standards algorithmic 2. general standards algorithmic general ethical legal principles primarily dignity → part b section 3 constitute benchmark design algorithmic terms principle prospective responsibility intentional unintentional effects users individuals affected algorithmic taken consideration part assessment specific algorithmic necessary think plan social consequences depending intended purpose context especially regard network effects effects effects scope consequences range positive effects social innovations sometimes subtle negative effects example diversity culture social debate essential condition functioning democracy basis ethics commission believes following key requirements design algorithmic set terms governance perspective taken met interplay especially developers companies users state bodies 2.1 human-centred design centre requirement strive algorithmic human-centred value-oriented design takes fundamental freedoms consideration ethics commission believes human-centred approach permeate entire design process ensured means wide range different measures particular involve nclusion participation algorithmic systems.human-centred design requires particular taking account changes self-perception self-design resulting individual ’ confrontation algorithmic gains losses expertise using effects people ’ lifestyles formation opinions well physical well-being taken consideration early stage attention paid emotional state affected individuals differ directions depending whether humans conventional algorithmic significant individual affected decision user consideration given example fact direct interpersonal interaction fulfils variety functions go far beyond “ good decision-making ” example 2 medical diagnoses supported algorithmic accuracy diagnosis identified first foremost intended purpose however need care contact consultations concerning treatment corresponding significance success treatment strong disregarded need doctors able contribute medical experience conversely certain situations example case embarrassing symptoms find comfortable confide primarily another person 164 part f lgorithmic functions include example satisfaction basic need communication feeling principle able assess person ’ line thinking reactions understood person opportunity convince person one ’ point view well certain control effect arising fact directly confronted reaction individual affected decision example 3 emotional aspects play major role algorithmic human-machine interaction example intrinsically intended support employees perceived employees invasive patronising since analyses employees ’ behaviour takes certain tasks hands actually come enjoy makes think performance inferior “ robotic colleague ” well-being individuals affected including example robotics nursing central guiding value absolutely taken consideration part ethical approach design important note well-being extremely subjective change depending context time therefore needs constantly reassessed 2.2 compatibility core societal values depending area application impacts algorithmic relevant society whole example affect democratic process citizen-centred state action competition future work sovereignty germany europe.example 4 smart providers able build business model large amounts privileged starting since many applications algorithmic depend amounts analysed likely correlations findings generated taken together network effects effects effects scope typical platform markets market power companies begins strengthen monopolies formed certain threshold reached ultimately enables companies prevent players entering market interfere market-regulating forces competition depending area application companies control social opinionforming processes market behaviour order counteract create framework conditions fair competition competition law control mechanisms readjusted necessary subsequently tightened ethics commission view supra- individual consequences often handled state bodies legislative measures alone instead need taken consideration phases design algorithmic extent developers companies users shared social responsibility particular corresponding consequences seem likely example case algorithmic affect communication people relevant democracy necessary already design process thoroughly assess purposes unintended indirect consequences question examine extent affect democracy fundamental secondary law basic principles rule law far possible culture “ incorporating ” basic principles democracy rule law fundamental architecture established process designing 165 f 2. general standards algorithmic many aspects interplay society admittedly still unclear ethics commission believes therefore necessary shed light social impacts algorithmic develop corresponding strategies limit negative effects 2.3 sustainability design algorithmic assessment personal social effects algorithmic global nature limited regard time reason deciding design algorithmic sustainability skills retention particular taken consideration important remaining control functions e. g. “ human-in-the-loop ” principle failure algorithmic exceptional circumstances e. g. event disaster cyber attacks ensuring innovative prowess future generations e. g. technologies first foremost question basic advanced training well education sense lifelong ensuring future generations necessary general skills limiting training user ’ perspective teaching developing skills promotes social sustainability social framework conditions example institutions procedures organised way ensure promotion participatory inclusive design algorithmic serve interest sustainable includes ecological dimension irrespective positive contribution algorithmic make environmental protection key ethical requirement reducing need electricity certain resources “ rare earths ” using efficiently.economic sustainability requires perspective looks beyond exclusively short-term economic profits takes long-term effects consideration short-term commercial success long-term disastrous consequences demonstrated global financial crisis several years ago limit freedom economic activity attention responsibility associated economic activity within context social market economy principle prospective responsibility well considerations fairness solidarity regard sustainability specifically taken consideration design algorithmic case handling risk assessment crucial importance ecological economic social sustainability design algorithmic 2.4 high level quality performance algorithmic work well reliably order achieve goals pursued help promote ethical aims technical legal specifications designed improve develop safeguard state art take ethical quality support replace activities deemed irrespective intrinsic value activity implementing ethical principles better previously example 5 ethically sound algorithmic healthcare sector firstly requires necessary medical quality i. e. accuracy assessment findings accuracy diagnosis probability recommended treatment successful success rate medical intervention etc least good view sensitive usage context ideally better conventional humans 166 part f lgorithmic quality performance improved wide range different measures include example appropriate risk models inclusive participatory possible standards systemic management control approaches process design aimed continuous improvement entire role humans part algorithmic understood social-informatic ensemble → section 1 always taken consideration context number algorithmic still rely input critical experts perform optimally quality-oriented design therefore includes mechanisms help enhance capabilities prevent counteract reduction skills critical ability readiness reflect example connection automation bias examples productive interaction humans machines designed ensure skill retention found algorithm-supported diagnostic imaging healthcare sector.2.5 guarantee robustness security algorithmic robust secure otherwise legitimate goals pursue achieved achieved expense potential harm ethically legally protected interests ethical perspective said robust secure design appropriate usage therefore affect respective purposes need protect result robustness security requirements identical specific requirements differ based specific need protection usage context example 6 robust secure control pose immediate threat people environment example control emission pollutants industrial plants control robots steer autonomous driverless cars traffic failure could even cause harm important legally protected life limb order prevent processes put place define current state art legal rules regulations enacted make mandatory follow state art measures implemented guarantee effective enforcement standards 167 f 2. general standards algorithmic robust secure design involves securing external threats e. g. means encryption anonymisation etc protecting humans environment negative influences particular systematic risk management approach e. g. basis risk assessment incorporate phases processing technical organisational components risks arise technical design result errors caused decisions taken using algorithmic algorithmic way incorporated organisation ’ management required checks ensures effectiveness measures view changing conditions example newly discovered risks 2.6 minimising bias discrimination prerequisite fair decisions key aim regulating algorithmic ensure decision-making patterns upon algorithmic based systematic distortions bias leading discriminatory unfair decisions first noted biased discriminatory unfair decisions found conventional humans conversely prejudiced decisions individual humans algorithmic however bear danger using large broad impact individual decision-makers could never cause mind discussion surrounding bias discrimination algorithmic view ethics commission seen opportunity detect existing problems existing decision-making contexts general achieve better decision-making processes.example 7 algorithmic detect skin cancer trained predominantly patients white skin probability correctly detecting skin cancer therefore significantly higher case patients white skin case patients different coloured skin medical device would permitted patients white skin effect would admittedly noted dermatologist training practised clinical professional exclusively specific cultural environment ultimately cases steps would need taken ensure patients irrespective skin colour receive proper medical care even cases direct intention discriminate developing algorithmic discriminatory decisions still made i. e. decisions systematically put certain groups unfair disadvantage particular case machine problem rather learn models using available resulting predictions recommendations extrapolate past future whereby existing social injustices obscured incorporation seemingly neutral potentially amplified example 8 algorithmic assess applications managerial trained managers proven relevant company past decades since predominantly male managers employed past decades trained set consistently assesses male candidates better equally qualified female candidates 168 part f lgorithmic keyword bias covers range different types systematic distortions range different causes case decision-makers cognitive bias social preconceptions prejudices stereotypes negatively affect decision-making process case algorithmic bias refer technical reproduction social preconceptions prejudices stereotypes reproduction take place various points primarily within context machine often insufficient level representation low number cases social group training leads distortions whereby specific characteristics group sufficiently recognised process therefore taken account addition training technical methodological decisions e. g. regarding target variables labels lead discriminatory models therefore unfair decisions lastly problems arise actively practice example algorithmic changing social framework conditions unforeseen usage contexts algorithmic directly categories legally explicitly recognized highly sensitive gender origin particularly critical point view discrimination direct sensitive depending area application important correct processing often permissible within legal limits example 9 many diagnosing diseases know patient ’ gender age take account sensitive characteristics within context business decision implementing business strategies example business expanding specific age group occupational group region characteristics define customer segment example simplified acceptance criteria apply.the indirectly codes sensitive categories however problematic example 10 household income creditworthiness assessments germany average income varies genders result algorithmic uses household income incorrectly assess creditworthiness men women involved terms distribution fully preventing discrimination even terms legally recognised categories gender origin difficult within context algorithmic furthermore algorithmic lead totally groups thrown together based coindicing characteristics excluded socially protected due certain classification without cause confronted negative consequences light involved made aware complex conditional discriminatory effects prevent counteract far possible → section 4.2.4 however technical measures designed minimise discrimination limitations even continuous improvement processes partly different technical fairness targets achieved simultaneously criteria nondiscrimination fairness appropriate context technical social political question accordingly decisions entrusted developers alone instead part future regulation algorithmic included operational obligations controllers prerequisite criteria decided specifically based context well democratically 169 f 2. general standards algorithmic algorithmic difficult analyse precisely order able detect prevent discrimination controllers oversight bodies opportunity gain idea undesirable discrimination effects occur within algorithmic within context productive deployment effects identified processes risk assessments output analyses tension specifications limit collection storage discriminatory characteristics concern retain possibility detect discriminatory effects able prove nondiscrimination different requirements balanced case-by-case basis influence tests different phases lifecycle standard collation potentially discriminatory therefore sensitive sole purpose proving result discrimination taking place would justified greater efforts needed produce practical concordance anti-discrimination law protection law .2.7 transparent explainable comprehensible order able carry reliable ethical legal assessment algorithmic essential enough available scope functionality pool analysis truly transparent examined determine whether pursuing legitimate purpose transparency principle key functions depending type addressee possible transparency obligations regard sufficient transparency created sufficient available socio-political discourse algorithmic supervisory authorities oversight bodies able decide whether legal technical specifications met algorithmic individual citizens able take informed confident decisions regarding algorithmic event negative effects freedoms able assess whether extent wish exercise consequence ethical principle self-determination view increasing complexity demand transparency practice confronted fact even experts hardly able go individual components fully look interact comprehend everything within reasonable amount time particular case individual machine methods difficult today ’ state-of-the-art science state input led specific output fact even technically simple algorithmic often incorporated complex social informatics ecosystems i. e. worksharing processes numerous manufacturers operators involved 170 part f lgorithmic example 11 visual personalised online advert result complex processes advert delivered paid basis behaviour-based analysis segmentation particular analytics services deployed site owners across websites incorporating corresponding program code javascript code tracking components change example manufacturers provide versions adaptive and/or selflearning legal aspects limit certain forms disclosure via algorithmic source codes hardware designs often protected trade secrets operators often legitimate interest preventing manipulated algorithmic process personal protection law limit interest affected citizens however transparency requirement regarding concerns disclosure source code contain personal protection law stand way disclosure however ever-present complexity refute goal designing algorithmic transparent lack transparency like aforementioned legal grounds aspects nevertheless taken account drafting transparency obligations based legally actually possible principle transparency requires continuously developing make disclosure easier example opensource software open hardware developing approaches reduce complexity required banner “ explainable ” researchers working increasing success producing meaningful findings internal processes algorithmic systems.the demand transparency always take different levels expertise parties potentially interested transparency account example disclosure computer code supervisory authorities carrying necessary checks make much easier understand conversely laypersons often need clearly comprehensibly prepared ’ basic characteristics enables carry risk assessment suitable everyday purposes time interest seldom limited “ ” order prevent negative decisions future explanation rather required decision specifically concerning came factors weighting specific drafting specifications transparency explainability based affected individuals ’ level understanding always comprehensible sense rules transparency explainability safeguard citizens ’ capacity act self-determination 171 f 2. general standards algorithmic 2.8 accountability structures control implies obligation accountable power opportunity control algorithmic accompanied willingness answer one ’ actions i. e. liable necessary complexity algorithmic practice make difficult assign responsibility hardware software manufacturers providers algorithm developers operators individual components clients users either organisation individual employees contribute components often change without knowledge control user example result important updates required security purposes involved often located different parts world efforts required levels order prevent diffusion responsibility establish accountability structures starting technical design legal specifications example form concept protection law “ joint control ” article 26 gdpr .2.9 result responsibility-guided consideration assessing ethical aspects algorithmic practice extremely complex due large number factors need taken account well fact specific area application different individuals put “ better ” “ worse ” said social consequences sustainability aspects rarely unequivocally classified either “ positive ” “ negative ” however mean humans surrender judgment cases difficult weigh everything everyone required take particular care assessments decisions algorithmic applications potentially develop phenomenally impressive performance scope questions raised concerning future mankind weighted assessments opportunities risks increasingly reach limits fundamental anthropological ethical discussions required precisely principle prospective responsibility fundamental importance regard democratic process provides ways means balancing conflicting convictions ideally supported special deliberative processes institutions society ensure inclusive participatory way possible challenges presented algorithmic addressed 172 part f lgorithmic rarely case activity algorithmic need weighed latter ethically relevant respects achieves “ better ” result humans using conventional case however ethics commission believes algorithmic ethically commanded general ethical preference activity machines expense protection important legally protected justified view ethics commission however regard question whether machine activity preferable → part b section 1 factors routinely need taken consideration emotional well-being people skills retention sustainable ultimately requires weighing options go favour algorithmic example 12 diagnostic algorithmic specific clinical area leads 2 patients dying whereas 10 patients would die result misdiagnoses would depending circumstances specific case ethically advisable even result minor tolerable reductions patients ’ emotional well-being occurred additional measures would taken ensure skills retention.however taking circumstances account algorithmic expense important legally protected leads inferior result conventional humans example wrong decisions made increase efficiency convenience algorithmic principle rejected ethical reasons however ethically defensible exceptions could made case based economic considerations would minimal impairment exceptionally high potential saving would benefit good 173 f 3. recommendation risk -adapted regulator approach 3. recommendation risk-adapted regulatory approach regulatory point view fact algorithmic need assessed differently ethical perspective depending intended purpose performance robustness security well terms impacts suggests risk-adapted regulatory approach1 required follows principle greater potential algorithmic cause harm stringent requirements far-reaching intervention means regulatory instruments risk spectrum algorithmic therefore ranges application involves low risk could lead irreversible harm individuals society causes risks example inadequate models unsuitable pool particular case selflearning inappropriate basic assumptions weighting → sections 2.3 2.6 potential harm caused algorithmic vary nature include financial loss nonmaterial damage physical harm example individual applications cause potentially serious financial loss example lending insurance terms affect opportunities participation example discrimination hiring involve violations fundamental risks life health consumers example case robotic nurses mobility applications 1 compare particular tobias krafft katharina zweig transparenz und nachvollziehbarkeit algorithmenbasierter entscheidungsprozesse transparency traceability algorithm-based decision processes studie im auftrag des verbraucherzentrale bundesverband e. v. vzbv study commissioned federation german consumer organisations vzbv 22 pp 18 seqq available /www.vzbv.de/sites/default/files/downloads//05/02/19-01-22_zweig_krafft_transparenz_adm-neu.pdf 2 sarah fischer thomas petersen deutschland über algorithmen weiß und denkt – ergebnisse einer repräsentativen bevölkerungsumfrage germany knows thinks algorithms – results representative population survey bertelsmann stiftung available /www.bertelsmann-stiftung.de/de/publikationen/publikation/did/was-deutschland-ueber-algorithmen-weiss-und-denkt/ .the overarching objective regulating algorithmic prevent detrimental effects individual supra-individual level particular algorithmic affect matters sensitive terms fundamental legal provisions concerning design needed regulation strive intervene much necessary little possible order hamper innovation creativity time ensuring protection fundamental freedoms values efficient proper regulation help increase trust algorithmic perception self-learning particular controllable adds corresponding scepticism towards technology.2 ethics commission takes view primary addressees regulation manufacturers operators algorithmic due state ’ direct obligation uphold fundamental necessary differentiate however private state algorithmic → section 7 particular regulation drawn detail given model role model character state action federal government advised exercise particular care using algorithmic state purposes 3.1 criticality requirements risk-adapted regulatory approach made concrete orienting towards criticality model algorithmic criticality based ’ potential cause harm determined based likelihood harm occur severity harm 174 part f lgorithmic severity harm could potentially result example faulty decision depends among things significance legally protected interests affected particular example determine one ’ personal freedom expression fundamental life physical integrity well equal treatment extent potential harm resulting infringement furthermore assessment severity potential harm take account specific sensitivity level potential harm individuals groups including non-material harm loss utility hard calculate monetary terms number individuals affected total figure potential damage harm society whole go well beyond straightforward summation harm suffered individuals consequences using algorithmic based area application considered terms ecological social psychological cultural economic legal dimensions general ethical values principles → part b set standard regard assigned value likelihood harm occur influenced following properties factors ●the role algorithmic calculations decision- making process mere inspiration humans without claim accuracy algorithmdetermined decisions → section 1 ●the complexity decision made simple deterministic depiction reality probabilistic appraisal reality multifactorial non-determinate prediction future reality ●the effects decision purely abstractly conceivable context action specific context action direct implementation ●the reversibility effects full reversibility irreversibility .the likelihood potential harm severity harm depend whether state private party taking action particularly economic contexts market power party using algorithmic due fact state private nature action market power relevant terms obligation uphold fundamental potential harm society whole determine possible alternative options affected affected persons depend algorithmic example terms access markets goods services criticality increases limitation options due various different causes example network effects effects effects scope turn reflected market power lack equivalent alternatives greater criticality stricter requirements imposed regulatory perspective requirements formed particular corrective oversight mechanisms b specifications regarding transparency algorithmic explainability comprehensibility results c rules assignment responsibility liability within context algorithmic → sections 4 5 8 175 f 3. recommendation risk -adapted regulator approach variety complexity dynamics algorithmic pose major challenges regulation based limited toolbox depending ’ criticality implement different corrective control instruments different regulatory levels order achieve objectives regulation ensure risks involved manageable spectrum possible instruments ranges forgoing special legal provisions “ soft ” incentives self-regulation giving authorities monitor requiring final decision taken banning certain intended purposes contexts using algorithmic provisions regarding transparency explainability comprehensibility results → section 2.7 key components corrective control regime algorithmic extent criticality determines scope obligations provide requested comprehensibly communicated varies depending addressees hence intended purpose usage context ethical legal perspective crucial dealings algorithmic responsibility impacts clearly assigned decisionmakers times rules liability particular key importance question proper organisation liability regime certain products and/or services addressed view criticality → section 8 .in terms governance perspective adopted ethics commission relevant stakeholders state companies developers participate specifying drawing differentiated regulatory requirements ethics commission points even without special regulation algorithmic measured general legal norms include particular civil liability law fundamentally states compensation mandatory event action infringes legally protected interests provisions existing regulation unfair competition apply example event consumers misled well criminal law crimes committed help algorithmic examining conditions norms criticality resulting requirements legal significance accordance general standards algorithmic order fulfil specific functions order assess criticality ethical assessment intended purpose therefore crucial importance intended purpose ethically indefensible example infringes fundamental freedoms breaches free democratic basic order “ red lines ” “ limits ” – algorithmic humans example algorithmic political manipulation fraud collusive price-fixing seen per se ethically objectionable 176 part f lgorithmic intended purposes often multifaceted individual facets particular regarding secondary purposes need assessed differently ethical perspective identifying intended purpose decisive assessment often sense requires difficult value judgments assessing intended purpose algorithmic complicated case products market launch phases increasingly overlap intended purpose product change launched market due updates deployment usage contexts complex intended purposes case media intermediaries number media intermediaries search engines essential internet age provide access online channel flood actually enable individuals internet first place extent purposes desirable unproblematic ethical terms however media intermediaries ethically problematic terms specific design provide users personalised selection leads selection displayed however since result overwhelming majority displayed displayed lower priority individual ’ spectrum perception narrowed intermediary decides programming user ’ head user sees far business models media intermediaries driven advertising case major social networks risk operators economic interest disseminating ethically questionable even extremist promises keep users platform longer thus increasing advertising revenue due interplay sorting narrowing seen additional danger influencing user non-transparent third-party interests possibility influence non-transparently exerted example political decisionmaking process could even result political manipulation significant danger free formation opinions basic foundation democracy 177 f 3. recommendation risk-adapted regulatory approach 3.2 criticality pyramid ethics commission recommends consistently determining degree criticality algorithmic using overarching model degree criticality guide legislators society seeking suitable regulatory thresholds instruments provide developers operators guidance assessing products finally basic advanced training educate increase awareness amongst various stakeholders extent regard potential algorithmic cause harm ethics commission differentiates private state operators five levels criticality figure 8 criticality pyramid risk-adapted regulatory algorithmic level 1applications zero negligible potential harmno special measuresbeginning specific regulationlevel 2applications potential harmmeasures formal substantive requirements e. g. transparency obligations publication risk assessment monitoring procedures e. g. disclosure obligations towards supervisory bodies ex-post controls audit procedures level 3applications regular significant potential harmadditional measures ex-ante approval procedureslevel 4applications serious potential harmadditional measures live interface “ always “ oversight supervisory institutionslevel 5applications untenable potential harmcomplete partial ban algorithmic ban 178 part f lgorithmic unproblematic usage contexts normally necessary require developers clients operators go specific ethical legal oversight procedures many applications zero negligible potential harm i. e. lowest level level 1 criticality pyramid ethics commission sees need special oversight would go beyond general quality requirements apply even products without algorithmic elements example 13 algorithms drinks vending machine certain potential harm since user could example receive goods lose money however potential harm exceed threshold specific potential harm within algorithm context sufficient rely general mechanisms oblige contractual partners fulfil contractually undertaken performance obligations manufacturers produce devices function properly.in case applications potential harm i. e. level 2 criticality pyramid regulation implemented however scope necessary measures limited view low level criticality excessive burden manufacturers operators specifically avoided order excessively hinder technological social innovations market measures could offered level 2 include example ad-hoc ex-post controls example form input-output control reason suspect malfunctioning furthermore obligation produce publish appropriate risk assessment → section 4.1.3 addition sector-specific basis obligations disclose supervisory institutions including establishing interface supervisory institution carry input-output controls increased transparency obligations well access individuals affected → section 4.1 details useful codes conduct considered would developed specifically industry approved competent supervisory authorities compliance would need tested supervisory authorities using spot checks well ad-hoc basis → section 5.2 criticality case smart mobility applications provider smart mobility applications access pool generated using vehicle mobility exclusively predicting traffic jams level criticality classified negligible however flow traffic controlled using smart mobility algorithms example identify route optimum route travelling b based overall usage mobility consisting road rail water air transport determined real time using vehicle corresponding route suggested user based user ’ preference e. g. fastest/ environmentally friendly/cheapest etc route however question whether state stipulate certain routes user consideration state-prescribed criteria view changed potential harm level criticality would higher would therefore require stricter regulation appropriate 179 f 3. recommendation risk -adapted regulator approach example 14 dynamic pricing example based criteria supply demand e-commerce however involve personalised pricing potential harm generally low still exceeding threshold relevance example concerning covert discrimination case applications regular tangible potential harm level 3 criticality pyramid specific cases addition mechanisms already required level 2 ex-ante control form licensing procedure justified → section 4.2.5 account fact many algorithmic highly dynamic regular review required event licence granted.example 15 price algorithms setting personalised prices i. e. setting price based criteria tailored individual customer usually estimate maximum personal willingness pay involve appreciable potential harm example concerning discrimination particularly vulnerable groups best possible undergone licensing procedure apply applications significant potential harm level 4 applies levels 2 3. however additional oversight transparency obligations extend way publication factors influence algorithmic calculations weighting pool algorithmic decision-making model comprehensible format required even “ always-on ” oversight via live interface provided protective measures prevent harm necessary differentiated criticality case media intermediaries help algorithmic filtering media intermediaries process communicate relevant formation opinions relevant democratic decision-making process advertising purchase recommendations entertainment therefore represent perfect example situations algorithmic differing potential harm case user interaction consumer goods sector particular advertising purchase recommendations depending personalisation model low high potential harm soon balanced variety produced particular case topics relevant formation opinions account overarching interests maintaining free democratic basic order potential harm already higher outset due result regulatory requirements change simultaneously case consumption entertainment offerings depending personalisation criteria usage contexts welfare effects expected less stringent regulation ensue 180 part f lgorithmic example 16 algorithmic example players huge market share determine creditworthiness individual consumer company classified level 4. whether person receives loan decisive bearing person ’ fate high level criticality justified market concentration providers tendency lender rely judgment particular player regard criticality criteria ultimately worth considering complete partial ex-ante ban algorithmic applications untenable potential harm level 5 ex-post ban consequence breaches applicable law non-fulfilment requirements set specific criticality example 17 lethal autonomous weapons often seen “ red line ” machines allowed kill people however apply basis algorithm-determined killings lethal autonomous weapons simply provide soldiers support recognising objects merely keep missile track face crosswinds ethical “ red line ” crossed classification algorithmic criticality pyramid necessary regularly reviewed light dynamic nature systems.3.3 regulation algorithmic enshrining horizontal requirements formed sectoral instruments algorithmic infiltrating areas personal social lives purposes algorithmic areas could potentially therefore set stone example facial recognition developed private photos could state investigative authorities law enforcement purposes prevent threats suggests addressing challenges posed algorithmic following example protection law form horizontal regulation i. e. legal instrument material scope covers algorithmic general applies private players alike addition considerable symbolic power another point favour horizontal regulation fact gaps protection would eliminated dangerous situations currently foreseen would covered one main arguments favour overarching regulation sets basic principles algorithmic fact citizens would result idea expect areas legislators could complete task within reasonable period time result ethics commission recommends federal government work towards drawing horizontal basic regulation level form regulation algorithmic eu-asr addition key basic principles algorithmic developed requirements algorithmic horizontal legal instrument group together general substantive rules – informed concept criticality – admissibility design algorithmic transparency individuals affected organisational technical safeguards supervisory institutions structures 181 f 3. recommendation risk-adapted regulatory approach figure 9 regulation algorithmic enshrining horizontal requirements specified sectoral instrumentssektor 1 specifying/supplementary rules requirementssektor 2 specifying/supplementary rules requirementssektor 3 specifying/supplementary rules requirementssektor 4 specifying/supplementary rules requirementsfederal government union regulation algorithmic eu-asr key basic principles algorithmic general substantive rules admissibility design algorithmic rules transparency organisational technical safeguards supervisory institutions structures.european union time ethics commission recommends federal government advocate sectoral rules level outside competences within legislative administrative competences enact appropriate sectoral legal acts oriented towards criticality fig 9 overarching eu-asr limited basic principles otherwise legislatory powers would overburdened legislators would rules detailed particular face issue deal general legal instrument wide variety almost impossible keep track highly dynamic perspective affected general legal instruments carry risk administrative obligations apply cases sufficient potential harm horizontal legal instrument distinguish risky less risky operational aims well potential exceptional configurations level detail reality regard points supplementary recourse sector-specific legislation would limited terms scope would therefore easier form would relieve burden supplementary sector-specific approach would take consideration legislative administrative powers distributed accordance applicable law federal level states bundesländer additional fact regard official oversight supervisory institutions structures various reasons could question consolidating assigning “ overall task ” one single authority → section 5.1 therefore addition eu-asr necessary enact several legal instruments specific provisions individual sectors potentially harmful situations view ethics commission combining general basic regulation sector-specific legal instruments major advantage enabling differentiation different needs protection involved individual usage contexts line basic concept behind risk-adapted regulation according regulatory requirements algorithmic determined based specific criticality 182 part f lgorithmic even protection law sector numerous special laws supplement general provisions gdpr different sectors basic idea behind protection law case automated processing longer thing “ inconsequential ” hardly possible differentiate meaningfully personal basis worthiness protection criticality absence common basic rules nonetheless true variety special provisions ensures increased level protection wide range areas state activity similarly according need supplementary sectoral provisions algorithmic application regulation fall short result fact purpose usage context could change firstly change would especially complex inherently limited secondly issue could addressed regulatory perspective fact legal instruments would materially linked original purpose original usage context current functionality intended purpose way changes purpose context would necessary result application differentiated regulatory framework however primarily pragmatic considerations way affect requirement standardsetting bodies ensure greatest possible coherence legal instruments respective undertakings apply regulatory approaches developed i. e. particular notion criticality subjects regulatory infrastructures processes designed uniformly possible 183 36 ethics commission recommends adopting risk-adapted regulatory approach algorithmic principle underlying approach follows greater potential harm stringent requirements far-reaching intervention means regulatory instruments assessing potential harm sociotechnical whole considered words components algorithmic application including people involved phase – example training – implementation application environment evaluation adjustment measures 37 ethics commission recommends potential algorithmic harm individuals and/ society determined uniformly basis universally applicable model purpose legislator develop criteria-based assessment scheme tool determining criticality algorithmic scheme based general ethical legal principles presented ethics commission 38 among things regulatory instruments requirements apply algorithmic include corrective oversight mechanisms specifications transparency explainability comprehensibility ’ results rules allocation responsibility liability using 39 ethics commission believes useful first stage determining potential harm algorithmic distinguish five levels criticality applications fall lowest levels level 1 associated zero negligible potential harm unnecessary carry special oversight impose requirements general quality requirements apply products irrespective whether incorporate algorithmic 40 applications fall level 2 associated potential harm regulated as-needs basis regulatory instruments connection include ex-post controls obligation produce publish appropriate risk assessment obligation disclose supervisory bodies enhanced transparency obligations access individuals affected.summary important recommendations action risk-adapted regulatory approach 184 part f lgorithmic 41 addition introduction licensing procedures justified applications fall level 3 associated regular significant potential harm applications fall level 4 associated serious potential harm ethics commission believes applications subject enhanced oversight transparency obligations extend way publication factors influence algorithmic calculations weightings pool algorithmic decision-making model option “ always-on ” regulatory oversight via live interface required 42 finally complete partial ban imposed applications untenable potential harm level 5 43 ethics commission believes measures proposed implemented regulation algorithmic enshrining general horizontal requirements regulation algorithmic eu-asr horizontal regulation incorporate fundamental requirements algorithmic sytems ethics commission developed particular group together general substantive rules – informed concept criticality – admissibility design algorithmic transparency individuals affected organisational technical safeguards supervisory institutions structures horizontal instrument fleshed sectoral instruments member state level concept criticality serving guiding framework 44 process drafting eu-asr recommended incorporate debate best demarcate respective scopes regulation gdpr number factors taken account respect firstly algorithmic pose specific risks individuals groups even involve processing personal risks relate assets ownership bodily integrity discrimination secondly regulatory framework introduced future horizontal regulation algorithmic need flexible risk-adapted current protection regime 185 f 4. instruments obligations controllers subjects 4. instruments obligations controllers subjects order provide individuals groups effective protection dangers algorithmic ethics commission believes transparency requirements → section 4.1 specifications algorithmic view effective protection substantively inappropriate decisions unfair decisions → section 4.2 advisable 4.1 transparency requirements 4.1.1 mandatory labelling “ ” key tool creating transparency mandatory labelling mandatory labelling scheme requires little detailed infringements fundamental operators particular regard business secrets less serious case access ethics commission believes justifies establishing labelling case critical level 2 blanket obligation operators requestbased individuals affected due comparatively narrow scope article 22 gdpr relating decision based solely automated processing duties provide refer ethics commission believes existing labelling obligations gdpr3 insufficient particular significant impacts affected individuals arise even threshold article 22 gdpr applies algorithm-based algorithm-driven decisions i. e. situations humans taking decisions run risk accepting algorithmic proposed decisions without reflection default particular areas assessment expected following algorithmically determined prescribed paths 3 article 13 2 f article 14 2 g article 15 1 h conjunction article 22 gdpr.because ethics commission sees authenticity interpersonal communication fundamental condition trustworthy interaction within society mandatory labelling scheme always apply risk confusion machine therefore apply irrespective criticality applies example voice assistants chatbots days sometimes hard identify labelling case voice assistants example carried means regular reminder assistant ’ mechanical nature even ongoing communication mechanical-sounding voice conversely ethics commission considers risk confusion therefore need mandatory labelling scheme areas nature irrelevant recipient expects mechanical voice anyway case loudspeaker announcements railway stations 4.1.2 duties provide duties provide explanation access “ ” “ ” whilst mandatory labelling schemes require operators ensure transparency regarding whether extent algorithmic “ ” duties provide access regularly focused detailed regarding decision-making mechanism “ ” “ ” algorithmic 186 part f lgorithmic duties provide access regarding behaviour algorithmic way decisions made inside important perspective citizens able understand decisions review and/ reviewed individually help subjects exercise challenge decision informed basis following transparency requirements apply equally private state operators algorithmic special requirements regard transparency state covered detail section 7 4.1.2.1 duties provide access articles 13 14 15 gdpr already set duties provide access personal processed event automated decisionmaking within meaning article 22 gdpr gdpr grants subject “ meaningful ” “ logic involved ” well “ significance ” “ envisaged consequences ” processing.4 ethics commission takes view case mandatory labelling scheme → section 4.1.1 legal concept behind norms apply outside narrow scope article 22 1 gdpr integral part eu-asr suggested → section 3.3 extent duty provide depend criticality case applications negligible potential harm brief statements logic behind decisions suffice example pool general weighting certain factors regard result risk involves extensive duties disclose essentially 4 article 13 2 f article 14 2 g article 15 1 h gdpr.the sensitive decision terms personality detailed relating individual case needed however borne mind providing detailed regarding factors weighting could potentially ethically questionable influence private lifestyle subject furthermore subject could acquired undermine algorithmic performs important function technical organisational requirements met order able fulfil extensive duties provide incorporated design algorithmic outset possible ensure operated lawfully corresponding necessary “ meaningful ” provided defining duties provide access order increase transparency algorithmic care taken ensure special technical skills knowledge required consumers whenever access expanded borne mind perspective subjects increase transparency prepared way suitable recipient 187 f 4. instruments obligations controllers subjects 4.1.2.2 duties provide explanation least certain areas complex algorithmic appropriate addition general explanation regarding ’ logic significance require explanation specific reasons made recommendation decision specific explanation required decision concerns areas sensitive terms personality otherwise particular significance terms fundamental socioeconomics important cases subjects informed comprehensible relevant manner ethics commission therefore welcomes technical efforts improve explainability algorithmic particular self-learning explainable explicable encourages federal government promote projects ethics commission believes certain situations worth considering entitlement “ counterfactual explanations ” sometimes discussed literature.5 cases subjects informed factors decision-making process case negative decision would made positive difference i. e. would actually led desired outcome case application loan rejected based algorithmic subject would example entitled learn operator factors taken consideration would different way application positive outcome however ethics commission points approach quickly reaches limits case complex subject would provided whole host different “ counterfactual ” scenarios order given reasonably complete picture otherwise would danger misinformation questionable steering even manipulation focusing certain aspects strategic educational reasons 5 sandra wachter brent mittelstadt chris russel harvard journal law 31 pp 841 seqq.in view ethics commission given current state technical concept “ counterfactual explanation ” therefore suitable general component regulation algorithmic however could considered special processing situations 4.1.2.3 access directly affected persons addition ethics commission considers certain sectors individual social interests affected significant extent advisable even individuals directly affected granted access regarding algorithmic would apply particular relevant opinion-forming major welfare effects population would first foremost worth considering journalistic purposes would accompanied adequate protective measures affected interests operators certain circumstances particular event state ’ significant potential harm unconditional access publication requirements conceivable view ethics commission 188 part f lgorithmic 4.1.2.4 requirements defining duties particular consideration operators ’ defining duties provide explanations access always borne mind affect legally protected interests operators algorithmic well outputs includes notably protection business secrets interest preventing manipulation manipulative private operators principle invoke fact define free-will decisions contractual decisions based outputs algorithmic however release monitoring required check whether acting accordance law fundamental freedom action restricted bans discrimination particular general act equal treatment fundamental subjects third parties general provisions specific contractual provisions legal furthermore transparency always balanced provisions protection law relating protection personal third parties stored ethics commission therefore believes appropriate legislators accompany transparency obligations rules initiative operators possibly affected third parties enable conflicting interests weighed transparency interests subjects private individuals entitled claim however view ethics commission rigid rules priority example general preference protection business secrets transparency interests appropriate matter concerned despite increase legal certainty might bring operators third parties invoke conflicting interests meticulous checks carried whether interests taken account specific protective measures transparency obligation completely rejected private individuals access requirements regarding protective measures demonstration existence devised act barrier preventing vulnerable consumers and/ citizens acquiring interests third parties protected example means anonymisation 4.1.3 risk impact assessment impact assessment within meaning article 35 1 gdpr concerns impacts protection personal however include comprehensive risk analysis algorithmic case algorithmic certain level potential harm however appropriate reasonable legally require provider/user produce publish appropriate risk impact assessment order assess risk involved critical comprehensive risk impact assessment cover assessment risks relating self-determination privacy bodily integrity personal integrity well assets property nondiscrimination include methods gauging quality fairness model accuracy example bias rates statistical error overall certain sub-groups exhibited forecasting/category formation 189 f 4. instruments obligations controllers subjects case personalised prices – transparency requirements increasing pricing algorithms e-commerce presents challenges consumer protection law competition law pricing algorithms review market order adjust prices line demand competitors ’ offers real time e-commerce providers therefore apply personalised prices individual users groups directly via individual discounts algorithmic example specifically cash consumers ’ maximum willingness pay encourage users abort purchase transaction personalisation based scoring processes example using real-time analyses users ’ surfing habits collected another way underlying algorithmic usually “ black boxes ” meaning pool logic behind decisions pricing comprehensible outsiders therefore risk price discrimination example relating protected population groups within meaning general act equal treatment potential harm caused implementation higher personalised prices individual consumers vary greatly nevertheless even small price increases individual goods services added together lead significant welfare losses individuals population groups affected particular example signalling lead quasi-collusive high market prices competitors deviously collude prices conditions via algorithms negative effect competition innovative prowess economy ultimately consumers applies intentional algorithms influence prices parallel behaviour high prices tacit collusion occur means algorithms without specific intention direct price-fixing undertaken humans would suffice overall high level criticality merely trigger transparency requirements labelling obligations pricing comprehensive impact assessment could help identify discrimination risks algorithmic pricing pool calculate personalised prices known independent experts able check whether correlate protected population groups known proxies i. e. whether example women certain religious groups pay higher prices consumers made aware via labelling obligations prices and/or discounts personalised affected parties could exercise access check “ ” price accuracy potential discriminatory factors transparency regarding price-relevant factors important order observe steering effects personalised pricing behaviour individual consumers relevant freedom 190 part f lgorithmic 4.1.4 duty draw documentation keep logs complex dynamic dispersed process individual convert input output important regulatory perspective make specific causes particular decision comprehensible errors detected infringements penalised effectively one approach better understand software-based processes work record individual program steps digitally test purposes required personal processing accordance protection law order fulfil accountability requirement firstly requirement document log sets models level granularity retention periods intended purposes specified protection law provide controllers processors greater legal clarity secondly significant potential harm level 4 required document log program processes sets models described way comprehensible supervisory institutions carrying oversight measures regards origin sets way prepared example optimisation goals pursued using models .4.2 requirements algorithmic 4.2.1 general quality requirements algorithmic operators required standards guarantee minimum level quality technical mathematical-procedural perspective procedural criteria imposed ensure algorithmically derived results obtained correct lawful manner purpose quality criteria imposed particular regards mathematical model specific processing methods corrective control mechanisms quality security strike balance conflicting fundamental software operator subjects decisions requirements validity mathematical models relevance underlying become stricter potential algorithmic cause harm increases case algorithm-based algorithm-driven decisions skill sensitivity built design example deliberately mandating completion certain training modules situations decision assistants example proven particularly helpful introduce systemimposed role changes certain intervals words assign user task making initial decision sees algorithmically derived proposal attention tests another option albeit one individual user perceive onerous require detect incorrect decisions computer deliberately interspersed among correct ones – therefore require true nature proposals question identified good time anyone suffers harm 191 f 4. instruments obligations controllers subjects steps taken ensure improvement processes carried fairly regard interests everyone affected particular attention paid ensuring suitable feedback loops take interests subjects operators account regard quality would advisable specify extent estimated “ proxy ” → part c section 2.2.2 seq permitted forbidden certain areas application addition requirements placed algorithmic actual processing purpose security requirements fulfilled design stage individual requirements parties involved taken consideration order ensure appropriate design-related decisions taken part conceptualisation implementation operation although operator usually main responsibility risk assessment operator fulfil responsibility access sufficient documentation e. g. manufacturer ’ risk impact assessment needs clarity responsible area areas identified critical ethics commission recommends setting legal specifications relating ●minimum standards required security measures taken ●specific details regarding conditions manufacturers operators design conduct test procedures example identify bias and/or discriminatory distortion ●legal consequences case security gaps errors ●duties draw documentation functionality tests users receive order able assess risks 6 cf article 22 3 gdpr 7 cf article 13 2 f gdpr article 14 2 g gdpr article 15 1 h gdpr ●obligations carry updates within specified time frame report 4.2.2 special protective measures algorithmic context decision-making humans become object key principle regulation algorithmic particularly pertinent algorithmic order support decisions automate decision-making processes i. e. replace decisionmaking technical processes article 22 gdpr codifies principle applicable existing law certain algorithmic fall within scope gdpr one subject decision based solely automated processing including profiling produces legal significant effects concerning – unless necessary entering performance contract based subject ’ explicit consent authorised law fully automated decision permitted controller implement protective measures order safeguard subject ’ interests6 stricter duties provide access apply.7 192 part f lgorithmic ethics commission believes various aspects rules currently require clarification duties provide access connected article 22 gdpr “ including profiling ” refer automated profiling individual credit reference agencies example consider subject rules claiming apparently simply conduct profiling “ decisions ” made companies example request credit score ethics commission believes argument sufficiently take intention gdpr account long-term effects subjects profiling could firstly significant secondly gdpr particularly emphasises profiling protection authorities courts able apply applicable law appropriate extent means interpretation based protective purpose gdpr welcomed however time given sensitive issue terms fundamental democratically legitimised legislator called upon specify legal framework conditions soon order create legal certainty quickly possible ethics commission recommends federal government advocate part evaluation gdpr clarification specification needed regarding question decision pursuant article 22 gdpr “ based solely ” automated processing personal scope term “ similar effect ” protection article 22 3 gdpr ethics commission recommends federal government advocate evaluation gdpr scope article 22 gdpr fleshed potential harm caused algorithmdetermined decision-making original guiding principle article 22 gdpr particular categorically differ many algorithm-driven decision-making particular tendency humans involved simply accept recommendations algorithmic exercise discretion plays role.in view fact potential harm algorithm-based varies heavily detail ethics commission believe would appropriate generally broaden prohibitory principle article 22 gdpr particular principle final decision-making pursuant article 22 3 gdpr suitable algorithmic equal measure algorithmic “ decision ” taken within meaning current wording article 22 1 gdpr final decision made would often practical often desirable instead ethics commission recommends risk-adapted regulatory regime provides individuals appropriate safeguards particular profiling opportunities defend mistakes made jeopardised legal notion humans become mere object technical form central legislative anchor point within horizontal legal instrument eu-asr → section 3.3 risk-adapted regulation algorithmic ethics commission recommends within accompanying sectoral legal instruments legal instruments therefore include provisions set specifications algorithm-based decisionmaking outside scope article 22 gdpr far layer regulation covers algorithmic fall within scope article 22 gdpr modified light recommendations made regulatory precisely synchronised 193 f 4. instruments obligations controllers subjects 4.2.3 appropriate algorithmic inferences ethics commission believes processes involved data-based generation algorithmic inferences supposed interests tendencies character traits individuals particular consumers deserve maximum social political attention economy awash inferences characteristic many business models geared towards detailed personalisation certain offers services many consumers appreciate convenience offers services however lead risks inferences made based incorrect pool results inappropriate contents obtained account inadequacy components order prevent risks could posed certain algorithmic inferences many want grant subjects legal “ appropriate inferences ” .8 proposal sets comprehensive package measures would give subject effective tool monitoring inferences concerning generated operators algorithmic addition substantive subject appropriate inferences sets obligation part operator without requested inform individual concerned inferences drawn “ appropriate ” reasons case ethics commission welcomes debate proposal “ appropriate inferences ” triggered however points could affect constitutionally protected interests operators algorithmic view ethics commission regulatory proposal take protection aspects consideration example limiting scope high level criticality due relevance terms participation fundamental 8 omer tene jules polonetsky northwestern journal intellectual property 11:5 pp 279 seq sandra wachter brent mittelstadt columbia business law review 2 p. 1 seqq proposal consists material component procedural component.4.2.4 legal protection discrimination one main aims regulation algorithmbased algorithm-driven algorithm-determined decision-making prevent discrimination individual based characteristic set article 3 3 basic law federal republic germany and/or article 21 1 charter fundamental union well objectively unjustified discrimination protect personal integrity individuals concerned whilst state bodies direct obligation uphold fundamental undertaking kind state activity therefore subject comprehensive prohibition discrimination sub-constitutional basis required private actors technical legal starting point essentially german general act equal treatment serving incorporate according directives german law alongside general clauses german private law example unconscionable contracts discrimination private individuals fall general act equal treatment firstly discrimination grounds sensitive characteristic race ethnic origin gender religion disability age sexual orientation secondly situational scope open employment context access goods services including housing available 194 part f lgorithmic principle provisions general act equal treatment already cover discrimination algorithmic accordance applicable law however matters susceptible discrimination included scope general act equal treatment act cover sensitive situations algorithmically established results trigger facilitate discrimination e. g. case mortgage offer based individual risk assessment therefore worth considering example broaden situational scope general act equal treatment include automated decision-making processes additionally incorporating individual areas relating algorithmic inferences particularly sensitive terms personality.9 primarily concerns areas could long-lasting negative effect person ’ way life consumer contracts drawn based scoring high-risk procedures facial recognition methods price discrimination certain areas life healthcare contractual partner ’ general freedom action equally constitutionally protected properly taken consideration 9 mario martini juristenzeitung jz p. .it necessary discuss whether context algorithmic legislators remove restrictive reference specific grounds discrimination discriminatory effects algorithmic sometimes reflect bias exists within society regard classic grounds discrimination example far bias training model would example case select candidates trained using successful managers past overwhelmingly male however potential algorithmic discriminate extends far beyond example disadvantage systematically associated group attributes discrimination prohibited law e. g. home address specific district correlations determined means pattern recognition really random extent situations already managed form indirect discrimination respect suitable relaxation rules relating burden proof possibly required extent however entirely issues fairness arise concern distribution opportunities detriment traditionally marginalised communities exclusion groups thrown together based less coincidental attributes specific characteristics machine creating grounds discrimination however could enormous widespread impacts account fact trained algorithms areas application 195 f 4. instruments obligations controllers subjects therefore appropriate consider broadening protection include every systematic objectively unjustified type discrimination based group attribute ethics commission recommends federal government examine appropriately adjusting general act equal treatment alternatively anchoring protection future specific algorithm legislation particular regulatory problem fundamentally evergrowing plethora group attributes could lead algorithmic discrimination hence systematic nature would sole criterion differentiating prejudices relevant irrelevant terms discrimination law corresponding regulation substantive protection discrimination would therefore case accompanied one hand corresponding duties disclosure duties state reasons various internal external oversight mechanisms regulation would provide substantive examination criteria consequences regulation parties involved would case meticulously assessed weighed irrespective issue broadening definition offence thought given whether rules burden proof already sufficiently reflect characteristics algorithmic ascertaining indirect discrimination requires neither proof intent discriminate unambiguous proof causality fact injured party prove correlation decisions sensitive criteria algorithmic however proof generally difficult affected parties provide.the ethics commission therefore recommends legislators enact legislation clarifying requirements providing proof discrimination operators algorithmic lower requirements affected parties needed reason general act equal treatment always considered together access duties state reasons → section 4.1.2 without injured party would often unable exercise protection interests third parties users affected result given sufficient consideration 4.2.5 preventive official licensing procedures high-risk algorithmic case algorithmic regular appreciable level 3 even significant potential harm level 4 addition existing regulations would make sense establish licensing procedures preliminary checks carried supervisory institutions order prevent harm subjects certain sections population society whole teil f algorithmische ysteme summary important recommendations action instruments 45 ethics commission recommends introduction mandatory labelling scheme algorithmic enhanced criticality level 2 upwards mandatory scheme kind would oblige operators make whether i.e extent algorithmic regardless criticality operators always obliged comply mandatory labelling scheme risk confusion machine might prove problematic ethical point view 46 individual affected decision able exercise “ meaningful logic involved well scope intended consequences ” algorithmic cf gdpr respect fully automated situations involve kind profiling regardless whether decision taken basis later line expanded future apply algorithm-based decisions differing levels access decisions according criticality measures require clarification certain legislative provisions widening regulatory scope level 47 certain cases appropriate ask operator algorithmic provide individual explanation decision taken addition general explanation logic procedure scope main objective provide individuals affected decision comprehensible relevant concrete ethics commission therefore welcomes work carried banner “ explainable ” efforts improve explainability algorithmic particular self-learning recommends federal government fund area 48 view fact certain sectors society whole affected well individual members particular parties individually affected algorithmic entitled access certain types likely kind would granted primarily journalistic purposes order take due account operator ’ interests would need accompanied adequate protective measures ethics commission believes consideration given granting unconditional access certain circumstances particular algorithmic serious potential harm level 4 state 197 f summar important recommendations action 49 appropriate reasonable impose legal requirement operators algorithmic least potential harm level 2 upwards produce publish proper risk assessment assessment kind cover processing non-personal well risks fall heading protection particular appraise risks posed respect self- determination privacy bodily integrity personal integrity assets ownership discrimination encompass underlying logic model methods gauging quality fairness model accuracy example bias rates statistical error overall certain sub-groups exhibited forecasting/category formation 50 provide controllers processors greater legal clarity work done terms fleshing requirements document log sets models level granularity retention periods intended purposes addition operators sensitive applications obliged future document log program runs software cause lasting harm sets models described way comprehensible employees supervisory institutions carrying oversight measures regards origin sets way pre-processed example optimisation goals pursued using models 51 operators required standard- setting guarantee minimum level quality technical mathematical-procedural perspective procedural criteria imposed ensure algorithmically derived results obtained correct lawful manner purpose quality criteria could imposed particular regards corrective control mechanisms quality security example would appropriate impose quality criteria relationship algorithmic processing outcomes obtain outcomes 52 ethics commission believes necessary first step clarify flesh greater detail scope legal consequences article 22 gdpr relation algorithmic context decision-making second step ethics commission recommends introduction additional protective mechanisms algorithm-based algorithm-driven decision-making since influence real-life settings almost significant algorithm-determined applications prohibitory principle followed date article 22 gdpr replaced flexible risk-adapted regulatory framework provides adequate guarantees regards protection individuals particular profiling concerned options individuals take action mistakes made jeopardised 53 consideration given expanding scope anti-discrimination legislation cover specific situations individual discriminated basis automated analysis automated decision-making procedure addition legislator take effective steps prevent discrimination basis group characteristics qualify protected characteristics law discrimination often currently qualify indirect discrimination basis protected characteristic 54 case algorithmic regular significant level 3 even serious potential harm level 4 would useful – supplement existing regulations – covered licensing procedures preliminary checks carried supervisory institutions interests preventing harm individuals affected certain sections population society whole 198 part f lgorithmic 5. institutions ethics commission takes view burden responsibility ethically justified lawful algorithmic shared rest several sets shoulders institutions supervisory structures currently exist sufficiently prepared effectively oversee monitoring algorithmic various levels ethics commission therefore urges federal government expand reorient competences existing supervisory institutions structures set institutions structures necessary 5.1 regulatory powers specialist expertise 5.1.1 distribution supervisory tasks within sectoral network oversight authorities ethics commission recommends federal government principle entrust regulatory supervisory tasks oversight powers case authorities already sector-specific expertise view ethics commission apply matters fall within administrative competence states bundesländer specifically ethics commission believes would make sense entrust oversight algorithmic private parties sectors economy authorities sectorspecific responsibility already exist existing authorities examples authorities federal financial supervisory authority bundesanstalt für finanzdienstleistungsaufsicht bafin federal network agency bundesnetzagentur bnetza federal office security bundesamt für sicherheit der informationstechnik bsi federal motor transport authority kraftfahrtbundesamt kba come mind furthermore federal cartel office bundeskartellamt bkarta protection supervisory authorities would special status horizontal responsibilities i. e. responsibilities span various different sectors economy.the ethics commission believes national eu-level “ oversight network critical algorithmic ” set order coordinate activities authorities entrusted algorithm supervisory tasks particular rules distribution responsibilities within network exchange organisation administrative procedures carried network legal protection would appropriate purposes order prevent gaps supervision ethics commission urges federation länder identify areas currently sector-specific authority sufficient expertise oversight tasks could assigned monitoring critical algorithmic view ethics commission cases often appropriate event corresponding need oversight entrust matters one existing authorities horizontal responsibility case algorithmic process sensitive personal protection authorities example adequate expertise however ethics commission believes particular cases necessary create completely regulatory control structures light ever-changing technical developments federation länder regularly review situation authorities faced structural challenge effectively executing algorithmic oversight tasks object oversight work technically highly complex subject dynamic change ethics commission therefore believes providing authorities practical skills particularly important firmly recommends federal government provide federal authorities financial technical resources required draft salary structure modernisation act besoldungsstrukturenmodernisierungsgesetz expected increase salaries bonuses publicsector professionals establish regulations without doubt welcome first step however light difficult attract welltrained professionals sector measures soon required 199 f 5. institutions ethics commission recommends federal government set official unit form competence centre algorithmic provide sectoral authorities support monitoring algorithmic responsibility acquire analyse develop impart technical methodological knowledge required supervising critical algorithmic coordination request sector-specific authorities primarily support sector-specific supervisory authorities building expertise needed carry tasks assess criticality algorithmic extend particular centre ’ task developing criteria processes tools oversight algorithmic include standards assessing criticality checking compliance critical algorithmic centre competence important intermediary advisory role far possible advise bodies federation länder municipalities manufacturers operators users subjects regard algorithmic involved international initiatives designed build sufficient oversight expertise including standardisation procedures however competence centre supervisory powers remain sectoral supervisory authorities service unit either created autonomous federal authority attached existing cross-sectional authority federal office security ethics commission considers would make sense establish corresponding union level future example form agency federal government work towards achieving 10 example article 58 gdpr governs investigative powers relating protection supervision section 32e german act restraints competition gesetz gegen wettbewerbsbeschränkungen gwb governs sector inquiries federal cartel office oversight high-frequency trade financial supervisory authorities based section 6 4 german securities trading act gesetz über den wertpapi erhandel wphg section 3 4 4 5 german stock exchange act börsengesetz börsg amended version conjunction section 7 3 stock exchange act.in principle ethics commission sees reason state bodies able make expertise private individuals entities carrying tasks building in-house expertise involve private individuals entities execution tasks long cooperation complies general constitutional administrative specifications applicable cooperation conversely corresponding cooperation example entrustment order deal current lack qualified specialists expertise sector 5.1.2 definition oversight powers according tasks involved regulating law clearly assign relevant competent authorities powers intervention including inspection access required supervision algorithmic blueprints regulatory powers control found various areas law.10 competent supervisory authorities times able examine algorithmic sensitive areas application high potential harm audit test procedures particular cover interaction user example take place via standardised interfaces access carry known input-output tests check example whether algorithmic systematically discriminates groups particularly useful case adapt internal rules time steps taken ensure testing lead change rules whereby learns test test 200 part f lgorithmic assigning legal authority steps taken ensure supervisory authorities power event proven breach law force operators algorithmic configure compliance law example adapting pool necessary apply penalties provided commensurate case question supervisory authorities able impose official bans unlawful algorithmic components 5.1.3 criticality-adapted extent oversight elements algorithmic taken account order behaviour effectively audited audit conducted authorities potentially extend training processes final rule-based model well input output underlying decisions quality indicators regarding pool model accuracy training model final decision model taken consideration order identify ’ bias rates statistical error overall certain sub-groups methodological perspective test carried analysing large amounts reviewing weighting factors complex multidimensional analysing inputthroughput-output due complex nature subject matter amounts involved control algorithms significantly increase efficiency effectiveness audit systematically look conspicuous patterns pool results algorithmic example shed light case discrimination.the extent oversight required specific case determined based area application criticality case potential harm level 2 suffice legislators limit regulatory oversight inspection results event ’ documented failure however areas high potential harm necessary stipulate operators standardised interface view ethics commission question whether regulatory oversight affects operators ’ trade business secrets third parties ’ privacy issue level criticality pyramid supervisory authorities obliged treat obtained part oversight work confidential due professional secrecy aspects represent legal obstacle far-reaching powers full detailed audits proper interpretation test results technical perspective anything trivial particular always whether really unearth error algorithmic restricts ability provide evidence quality informative value different test procedures audits therefore need agreed – particular regard probative value court proceedings order enforce parties affected ethics commission therefore recommends federal government support initiatives develop statistical technical standards test procedures audits necessary differentiated areas application competence centre algorithmic → section 5.1.1 take leading role endeavours 201 f 5. institutions case personalised prices ii – ex-post controls supervisory institutions 11 cf gesellschaft für informatik technische und rechtliche betrachtungen algorithmischer entscheidungsverfahren gutachten der fach gruppe rechtsinformatik der gesellschaft für informatik e. v. im auftrag des sachverständigenrats für verbraucherfragen gesellschaft für informatik technical legal considerations regarding algorithmic decision-making processes report legal informatics expert group gesellschaft für informatik e. v. request advisory council consumer affairs berlin pp 63 seqq available www.svr-verbraucherfragen.de/wp-content/uploads/gi_studie_algorithmenregulierung.pdf .supervisory institutions could check whether algorithmic pricing e-commerce comply law discriminate example protected population groups within meaning general act equal treatment supervisory authorities could look conspicuous patterns pool issued prices shed light possible case discrimination carrying supervision comprehend potentially highly complex rules underlying algorithm analysing code effective oversight carried help statistical tests analyse things equal issued prices change depending input associated certain population groups example issues higher prices consumers gender changed “ male ” “ female ” input issued prices correlate attributes protected equality legislation individual population groups example via proxies mathematically statistically determined.11 5.2 corporate self-regulation co-regulation neither possible necessary legislator implement blanket regulations covering algorithmic instead various models self-regulation co-regulation could essentially provide sufficient responses certain situations co-regulation involves regulatory approaches navigate state regulation private self-regulation characterised combination public/state component private/institutional component.5.2.1 self-regulation self-certification ethics commission recommends selfregulation form internal audit conducted manufacturer operator algorithmic lowest level criticality pyramid could supported self-certification manufacturers operators basis specific standards algorithmic particular advantage would self-certification bodies would necessary know-how account close connection specific topics result experts even companies question could take legal standards monitoring compliance therewith consideration including stage necessary incorporate corporate expertise regulatory mechanisms institutionally admittedly purely internal voluntary self-regulation would constitute independent monitoring event breaches would ensure effective implementation penalties 202 part f lgorithmic self-regulation architecture could supplemented model involving regulated self-monitoring would set external standards quality risk management self-monitoring could externally monitored similar set gdpr article 40 establishes option specify general clauses gdpr make applicable specific real-life circumstances significant parties subject codes conduct well set minimum standards specific sector question order able guarantee regulation would effective intended effective monitoring ensure actual compliance approved codes conduct pursuant article 40 gdpr would codes conduct drawn procedural rules relating monitoring control implementation penalties cases non-compliance would set provider signs voluntary self-monitoring verifiably demonstrates compliance agreed procedures standard-setting grant privileges terms supervisory measures approach would based condition exercising corporate responsibility cooperation private self-monitoring providers would develop procedural standards would recognised supervisory authority involvement civil society organisations preparatory work would essential order able properly represent interests citizens consumers take consideration 12 mario martini juristenzeitung jz p. 1022 seq.5.2.2 creation code conduct concept regulated self-regulation would worth considering including algorithmic accountability code adopting “ comply explain ” approach well-established parts legal could oblige parties subject regulation state whether extent following recommendations code.12 false statements would subject sanctions code drawn could binding nature holding companies authorities responsible consequences algorithmic could example developed based corporate responsibility guidelines → part section 2 conversely help shape guidelines level granular detail codes guidelines practical and/or sector-specific ethical challenges specific code would useful become quality defined requirements framework conditions i. e. opportunities independent external parties carry checks ability impose penalties event breaches would essential ensuring code control function responsibility developing code assigned independent commission equal representation manufacturers operators scientific community civil society remains seen whether government commission german corporate governance code regierungskommission deutscher corporate governance kodex www.dcgk.de could model addition alternatively binding statements manufacturers operators algorithmic could considered 203 f 5. institutions 5.2.3 quality seals algorithmic establishing quality seals algorithmic sensible order support effective algorithm regulation could take form voluntary mandatory evidence protective measures would make extent algorithmic meets certain requirements users would important clarify would define requirements quality seal would specifically responsible fulfilling requirements connected quality seal extent breaches would subject penalties case algorithmic accountability code responsibility defining requirements quality seal entrusted independent commission equal representation operators algorithmic scientific community civil society 5.2.4 contact persons algorithmic companies authorities companies authorities work critical algorithmic level 2 least starting certain company authority appoint contact person responsible communications authorities cooperation cases ensured contact person specific expertise monitor algorithmic internally provide company ’ authority ’ management team advice functionally independent case protection officers contact person could act link supervisory authority operators algorithmic affected groups people would help ensure proper awareness problems within companies authorities increase oversight pressure inside.5.2.5 involvement civil society stakeholders order ensure interests civil society affected companies properly taken account part audits algorithmic advisory boards set within sector-specific competent authorities civil society stakeholders example involved connection code advisory boards feature balance representatives civil society organisations individuals appointed companies order ensure interests affected individuals groups interests affected companies properly taken account part audits 5.3 technical standardisation view ethics commission standardisation organisations iso/iec ieee ietf itu etsi w3c cen din set technical standards communications technologies could significantly help forming sector-specific requirements algorithmic technical standards take ethical legal requirements consideration could provide legal certainty companies develop algorithmic could easily requirements legality algorithmic specific guidelines individual sectors ethics commission believes technical standards would essentially useful tools bridge gap “ classic ” state regulation purely private self-regulation therefore recommends federal government suitably work develop adopt technical standards designed prevent risks posed algorithmic 204 part f lgorithmic however view ethics commission federal government lose sight fact technical standards limitations → part section 6 technical standards substitute defining legal requirements algorithmic regulatory supervision constitutional reasons principle citizens ’ fundamental affected detailed legal provisions upheld practice means legislators first define legal framework – technical standard-setting committees least ensure integrity decision-making protected participation representatives sectors and/or affected companies ensure addition impressive technical expertise interests companies and/or sectors course often taken consideration first hand technical standards drawn 5.4 institutional legal protection particular associations file action granting competitors competition associations consumer associations file action important feature german legal landscape many years could play key role civil society oversight algorithmic particular private kind allow civil society players legitimate mandate enforce compliance legislative provisions area contract law fair trading law without needing rely authorities take action without needing wait individuals authorise civil law approach particularly strong market characterised swift responses therefore international standards successful associations essentially politically administratively independent therefore advocate authority common interest consumers companies competition regulations consumer efficiently protected unfair business practices damaging consumers.anyone comply regulatory provisions potentially benefit unfair competitive advantage order prevent competitive edge gained breaking law competition associations consumer associations able stop legal infringements 205 summary important recommendations action institutions 55 ethics commission recommends federal government expand realign competencies existing supervisory institutions structures necessary set ones official supervisory tasks powers primarily entrusted sectoral supervisory authorities already built wealth expert knowledge relevant sector ensuring competent authorities financial technical resources need particularly important factor respect 56 ethics commission recommends federal government set national centre competence algorithmic centre act repository technical regulatory expertise assist sectoral supervisory authorities task monitoring algorithmic ensure compliance law 57 ethics commission believes initiatives involving technical statistical quality standards test procedures audits differentiated according critical application areas necessary worthy support test procedures kind – provided designed adequately meaningful reliable secure – make vital contribution future auditability algorithmic 58 opinion ethics commission particular attention paid innovative forms co- regulation self-regulation alongside complement forms state regulation recommends federal government examine various models co-regulation selfregulation potentially useful solution certain situations 59 ethics commission believes option worth considering might require operators law inspired “ comply explain ” regulatory model sign declaration confirming willingness comply algorithmic accountability code independent commission equal representation – free state influence – could set develop code kind would apply binding basis operators algorithmic appropriate involvement civil society representatives drafting code guaranteed 206 part f lgorithmic 60 voluntary mandatory evidence protective measures form specific quality seal serve guarantee consumers algorithmic question reliable time providing incentive developers operators develop reliable 61 ethics commission takes view companies authorities operating critical algorithmic obliged future appoint contact person way companies specific currently obliged appoint protection officer communications authorities routed contact person subject duty cooperation 62 ensure official audits algorithmic take due account interests civil society companies affected suitable advisory boards set within sectoral supervisory authorities 63 opinion ethics commission technical standards adopted accredited standardisation organisations generally useful measure occupying intermediate state regulation purely private self-regulation therefore recommends federal government engage appropriate efforts towards adoption standards 64 granting competitors competition associations consumer associations file action important feature german legal landscape many years could play key role civil society oversight algorithmic particular private kind could allow civil society players legitimate mandate enforce compliance legal provisions area contract law fair trading law anti-discrimination law without needing rely authorities take action without needing wait individuals authorise 207 f 6. special topic algorithmic media intermediaries 6. special topic algorithmic media intermediaries 6.1 relevance democratic process example social networks many people would impossible imagine life days without social networks search engines like enable users keep date latest news around world circle friends real time platforms people portray lifestyles communicate entertainment purposes business activity including advertising whole becoming increasingly important private opinion-forming order manage wealth available providers services algorithmic designed amongst things identify interests tendencies convictions users identify posts potential relevance present similar posts order encourage interact network filter illegal offensive posts economic aim primarily generate high advertising revenue depending reach media intermediaries profound impact democratic process people using social networks keep abreast politics world affairs social networks therefore offer users opportunities participate society sense constitute media factors exchange opinions .at time fact debate concentrated private platforms poses challenge democracy economic stakeholders private operators social networks vested interest directing traffic networks gearing activity primarily towards economic aspects rather focusing social interests multi-faceted opinion-forming process benefit good algorithmic predominantly oriented economic criteria negative consequences diversity opinions social networks services lead manipulation opinions one hand happen unintentionally due certain characteristics underlying software example recommender hand intentionally various actors manipulative purposes operators social networks sufficiently guarded activities threaten foundations democracy regulatory framework social oversight needed particular view high level criticality 208 part f lgorithmic ethics commission believes future media intermediaries gatekeeper role ultimately develop high potential harm democracy resulting need regulation ethics commission believes essential legislators create appropriate regulatory framework algorithmic media intermediaries ethics commission opinion first operators platforms providers services define implement basic rules ensure fairness opinion-forming process however “ domiciliary ” limitations particular integrity democratic process affected depending market share gatekeeper role platforms services operators fundamental-rights-based obligations account indirect third-party effect.13 view ethics commission obligations specified precisely subconstitutional law particular regard algorithmic platforms services significant market share gatekeeper role relevant eu-asr recommended ethics commission → section 3.3 regulation needed ensure regulatory fairness comparison broadcasters ethics commission recommends federal government examine risks posed providers particular power influence opinions countered whole range measures possible greater transparency ex-ante controls form licensing procedure algorithmic relevant terms democracy 13 decisions federal constitutional court 128 p. 249 fraport 148 p. 267 seqq. 32 seqq stadionverbot 14 cf decisions federal constitutional court 136 9 28 references.6.2 diversity media intermediaries example social networks wide variety roles played social networks predominantly high level criticality algorithmic present particular challenges ethics commission ’ suggested approach risk-adapted regulation algorithmic ethics commission believes positive legal provisions social networks example increase transparency range discussions held bolster users would particularly constructive case social networks dominant market share ethics commission calls measures safeguard diversity defensive measures alone suffice algorithmic operate types networks impacts freedom diversity opinion-forming constitutive democracy extremely high level criticality account reach alone ethics commission believes legislators therefore ethical constitutional obligation establish binding normative framework regulation media intermediaries order protect democracy require transforming regulatory framework governing media legislators take suitable measures ensure total range offer reflects variety opinions exist guarantees balance neutrality freedom bias society .14 applies particular media intermediaries gatekeeper role power influence opinions according federal constitutional court safeguard pluralistic diversity substantive organisational procedural regulations needed focused creating freedom communication therefore suitable producing desired effects article 5 1 basic law federal republic germany 209 f 6. special topic algorithmic media intermediaries light legislators länder responsible media law obliged implement aforementioned provisions applies legislators regulation algorithmic eu-asr → section 3.3 media intermediaries video-sharing platforms vsps already subject audiovisual media services directive15 provide user-generated general draft interstate media services agreement covers media intermediaries ethics commission welcomes respect provisions transparency social networks set draft interstate media agreement medienstaatsvertrag mstv-e initial step direction legislators länder plenty scope freedom drawing provisions however decide regulation model leave private individuals agree ethics commission view plurality obligations media intermediaries case include obligation algorithmic least additional option provide access unbiased balanced selection posts reflect diverse range different opinions.16 based considerations ethics commission recommends federal government investigate whether areas irrespective situation relevant democracy discussed corresponding obligation establish requirements neutrality provisions diversity seems necessary protecting minors influenced social networks example one consideration 15 directive /13/eu 10 coordination certain provisions laid law regulation administrative action member states concerning provision audiovisual media services audiovisual media services directive 16 rolf schwartmann maximilian hermann robin mühlenbeck multimedia und recht mmr 8 p. 498 seqq.6.3 labelling obligation social bots democratic process essence based people ’ freedom form opinions make decisions however bots i. e. software programs give impression users various platforms view ethics commission highly problematic bots manipulate individual users and/or debate guide result vote one way political decisions made firstly simulation traits falsely suggests statements made result independent thought independent formation political opinions secondly automation massively increase number frequency expressions opinion making harder even impossible assess actual majorities opinions ethics commission believes regulatory intervention required basis ethics commission recommends implementing measure enhance transparency form labelling obligation social bots social networks based general considerations ethics commission recommends labelling obligation implemented anywhere risk social bots could mistaken interlocutors → section 4.1.1 given particular potential jeopardise democratic process ethics commission furthermore believes case labelling obligation social bots impact political opinion-forming processes essential even irrespective real risk confusion 210 part f lgorithmic 6.4 measures combat fake news labelling obligation social bots could help combat automated spread fake news however ethics commission believes concept fake news suitable starting point regulation relating media legislation presentation legal definition fake news draws objective distinct line exaggerated satirical expression opinion intentional misrepresentation news impossible due complexity communications disinformation manipulation opinion-forming typically associated term “ fake news ” result true facts presented selectively ethics commission particular recommends legislators operators social networks grant users easy-to-exercise reply requiring network post correction statement proven false e. g. invented quote timeline newsfeed etc users network using available trace back shown false statement ethics commission emphasises state create incentives collateral censorship social networks provide protection “ overblocking ” ethics commission therefore believes necessary parallel obligations imposed operators grant affected individuals prompt efficient procedural protection mechanisms ethics commission believes include particular effective process reinstate deleted posts provided break laws invocation networks rules alone suffice grounds permanent deletion/blocking view ethics commission apply users respect social networks.6.5 transparency obligations news aggregators social networks algorithmic aggregate select present journalistic/editorial third parties generally accessible way allow users interested third parties enough insight technical procedure select prioritise news make recommendation arrived individual case democratic interest would essentially take precedence business secrets media intermediaries interests fair opinion-forming process fair exchange opinions duties disclose stretch economic ties reason well ethics commission welcomes current thoughts reforming interstate media agreement medienstaatsvertrag mstv-e call corresponding transparency obligations media intermediaries soon certain reach 211 summary important recommendations action special topic algorithmic media intermediaries 65 given specific risks posed media intermediaries act gatekeepers democracy ethics commission recommends options examined countering risks regard influencing legislation → recommendation 43 whole gamut risk mitigation measures considered extending ex-ante controls e.g form licensing procedure 66 national legislator constitutional obligation protect democratic dangers free democratic pluralistic formation opinions created providers act gatekeepers establishing binding normative framework media ethics commission believes small number operators concerned obliged algorithmic allow users least additional option access unbiased balanced selection posts embodies pluralism opinion 67 federal government consider measures take due account risks typically encountered media sector respect media intermediaries respect providers act gatekeepers whose associated lower potential harm measures might include mechanisms enhancing transparency example ensuring available technical procedures select rank news stories introducing labelling obligations social bots establishing post countering responses timelines 212 part f lgorithmic 7. algorithmic state bodies 7.1 opportunities risks involved algorithmic state bodies citizens rightly expect state best available carry duties depending type duties include algorithmic already exist relieve state bodies repetitive tasks thereby expediting processes freeing resources complex cases certain set-ups improve consistency quality state activity form chatbots voice assistants example facilitate citizens ’ access justice time using algorithmic state bodies uphold particularly high standards firstly direct obligation uphold fundamental authorities secondly state activity general expected set example whole society institutional capacity expertise state build order ensure sufficient oversight algorithmic private parties therefore order guide oversee work carried state bodies particular competence centre algorithmic called ethics commission likely play key role context.the algorithmic state bodies treated principle particularly sensitive within meaning criticality pyramid least level 3 therefore view ethics commission comprehensive risk impact assessment carried mandatory requirement ethically sound algorithmic furthermore depending criticality state necessary instruments discussed designed ensure citizens protected put place algorithmic state farther-reaching legal protection requirements remain unaffected constitutional administrative specifications design additionally view ethics commission certain sectors algorithmic conflicts constitutionally protected overriding importance algorithmic irrespective protective measures taken case question permitted restrictive conditions prohibited particular concerns algorithmic purposes law-making jurisprudence 7.2 algorithmic law-making algorithmic within government context law-making subject restrictions ethics commission sees democratic process sense people able form opinions make decisions freely possible essentially sacrosanct automated support law-making therefore acceptable low-level ancillary tasks e. g. detecting inconsistent terms and/ legal instruments far removed democratic decision-making process e. g. catalogues technical specifications subsequent regulations cases meet extremely strict requirements quality security 213 f 7. algorithmic state bodies context ethics commission particular opposes demand newly enacted legal instruments already formulated view possible future automated application regard follow law reverse accordance conventional criteria assessment legislation compliance fundamental higher-ranking law impact assessment etc two equivalent versions conceivable argument one version easier algorithmise tip scales favour 7.3 algorithmic dispensation justice ethics commission view algorithmic dispensation justice permissible peripheral tasks justice administered “ name people ” means least contentious proceedings well administrative court proceedings criminal proceedings always administered judges pacification effect court proceedings achieved judgment fairness finding hearing weighing conflicting interests humans particular structural processing facts legal consequences procedural fairness contrast opaque blackbox decision due often high level trust placed supposed “ infallibility ” technical automation bias well low level willingness make divergent decisions particular associated additional burden reasoning proof risk “ miscarriage justice ” default effects even legally non-binding proposals decisions judgments algorithmic generally highly problematic perspective parties concerned however algorithmic provided strict quality control high security standards place useful preparatory work directly affect judicial decision e. g. file management document control .lastly retrospectively analyse judicial decisions available voluntary judges protected access third parties high-level security measures conceivable could example work whether decisions influenced external factors ones order provide judges future ways prevent distortions thus contribute better consistent dispensation justice researchers legitimate interest access though sufficient safeguards would required individual cases purpose monitoring path judicial decision-making checking dispensation work judges external targets e. g. average processing time case however view objective judicial independence permissible pre-litigation domain example exercising air passenger dunning procedure similar view ethics commission fully automated handling legal claims permissible provided procedural individual parties concerned safeguarded result however case algorithmic create correlations follow legal provisions procedural steps set current state art based classic deterministic algorithms therefore generally considered example make decisions meeting formal criteria open assessment systemic point view impending losses expertise compensated freeing resources complex individual cases 214 part f lgorithmic 7.4 algorithmic administration potentially greater scope algorithmic administration increased automation authorities ’ routine cases included subject precisely defined conditions regarding facts legal consequences advisable interest efficiency section 10 2 administrative procedures act order carry administrative procedures appropriately swiftly possible particular relieving administrative staff routine tasks frees resources deployed handle procedures automated potential particular provision services benefits ethics commission believes algorithmic expand proactive procedure management whereby required available authorities services benefits increasingly provided without need applications educationally disadvantaged individuals needy particular could benefit cf family allowance austria provided child born without need apply however case intervention authorities algorithmic dealt carefully fundamental particularly affected judicial applies algorithmdetermined administrative decisions limits authorities ’ scope decision-making general assessing whether permit extent resulting intervention reversibility decisions need taken consideration essentially designing easily accessible oversight therefore sensitive areas administration often allowed based classic deterministic algorithms proprietary software avoided reason.in case discretionary decisions executive decisions discretion external legal effect ethics commission believes currently necessary humans make final decision decision mere beneficial impacts however forming groups cases specification conceivable discretion could reduced extent view algorithmic one option terms decision ethics commission view section 35a german administrative procedures act sufficiently reproduce range different possible types cases schematic taking account safeguards required constitutional law based article 22 gdpr legislators carefully expand scope section 35a administrative procedures act and/or set provisions differentiated terms specific legislation administrative acts supported partially fully automation regulations partial full automation administrative procedures developed part horizontal sectoral regulations algorithmic recommended ethics commission → section 3.3 7.5 algorithmic security law discussion especially critical algorithmic security authorities administrative measures area particularly profound effect fundamental algorithmic generally restricted 215 f 7. algorithmic state bodies algorithmic predict crimes threat situations predictive policing consideration given fact even personal directly effects relevant fundamental case particular reference person re- created means especially detailed location addition “ location-related risk prognoses ” lead excessive police checks certain neighbourhoods identified hotspots therefore ethnic social profiling population groups living measures trigger crime relocation displacement effects ethics commission therefore recommends making security authorities effects incorporating randomisations prediction order reduce corresponding effects system-based distortions steps taken ensure security authorities still always carry review cases risk cases selected cf section 88 fiscal code germany abgabenordnung ao security authorities allowed order discretionary intervention measures solely basis locationrelated forecasts risk forecasts relating individuals allowed law area security forecasts created fully automatically could negative legal consequences parties concerned account risk automation bias even case algorithm-based decisions support decisionmakers algorithmic profiling permissible within strict limits 17 paper part 36th conference freedom officers germany – “ transparenz der verwaltung beim einsatz von algorithmen für gelebten grundrechtsschutz unabdingbar ” “ transparency administration algorithms essential protection fundamental ” ulm 16 available /www.datenschutzzentrum.de/uploads/informationsfreiheit/_ positionspapier-transparenz-von-algorithmen.pdf .7.6 transparency requirements algorithmic state actors state decisions made using algorithmic remain transparent justifiable generally speaking even important private sector due obligation uphold fundamental need democratic accountability authority power sector therefore general transparency requirements → section 4.1 apply state bodies state bodies strive particularly hard ensure openness ethics commission points many cases algorithmic state actors already fall within scope existing freedom and/or transparency laws ethics commission welcomes paper “ transparency administration algorithms ” “ transparenz der verwaltung beim einsatz von algorithmen ” adopted 36th conference freedom officers konferenz der informationsfreiheitsbeauftragten germany according paper state bodies meaningful comprehensive generally comprehensible regarding processing legally possible publish including categories procedure ’ input output ii logic involved particular calculation formulae including weighting input underlying expertise individual configuration deployed users iii scope resulting decisions possible consequences procedures.17 216 part f lgorithmic regard specifying corresponding transparency obligations and/or duties provide access ethics commission points insufficient provisions transparency lead lack trust lead greater numbers appeals thereby counteracting efficiency gains intended algorithmic reason ethics commission ultimately believes justifiable cases rule access regarding algorithmic across board citing risk manipulation protection business secrets rule therefore particular interests weighed disclosure ’ general functionality sufficient every case algorithmic authorities often decisions made authorities justified parties affected i. e. “ main factual legal reasons ” led decision particular case provided cf section 39 1 2 administrative procedures act individual explanation required constitutional subconstitutional law due technical complexity possible possible way course official complaint procedure court enables effective review viability reasoning algorithmic prohibited apart ethics commission believes state required build sufficient expertise within administration courts able ensure necessary oversight system-internal decision-making processes.the ethics commission points transparency state activity negatively affected state uses proprietary software closedsource software private providers carrying duties generally speaking proprietary software makes difficult users make changes adaptations results dependent relationship addition proprietary software leads lack transparency therefore threaten acceptance especially areas sensitive terms fundamental security law proprietary software therefore avoided possible instead state bodies rely opensource solutions develop ideally interdisciplinary teams developers practical ethics commission recommends federal government consider amending procurement law minimise aforementioned negative effects proprietary software need fear effectiveness suffer result transparency i. e. exploitation effects ruled software developed open consultative process inclusion civil society stakeholders 217 f 7. algorithmic state bodies 7.7 risk involved automated total enforcement ethics commission refuses ethical point view acknowledge general non-compliance rules regulations however automated total enforcement law raises number ethical concerns example citizens might feel full enforcement practice places everyone suspicion turn reduces general willingness obey rules regulations furthermore automated enforcement danger complexity real-life situations sufficiently portrayed particular unforeseen exceptional situations example speeding private vehicle taking seriously injured individual hospital sufficiently taken consideration finally many laws originally enacted total enforcement general rule therefore designed way override technical enforcement specific case addition law enforcement measure constitutes state intervention based principle proportionality part f lgorithmic summary important recommendations action algorithmic state bodies 68 state interests citizens make best available technologies including algorithmic exercise particular prudence actions view obligation preserve fundamental act role model general rule therefore algorithmic authorities assessed basis criticality model particularly sensitive entailing least comprehensive risk assessment 69 areas law-making dispensation justice algorithmic peripheral tasks particular algorithmic undermine functional independence courts democratic process way contrast enormous potential exists algorithmic connection administrative tasks particular relating provision services benefits legislator take due account fact giving green light greater number partially fully automated administrative procedures cautious consideration therefore given expanding scope section 35a german administrative procedures act verwaltungsverfahrensgesetz vwvfg couched overly restrictive terms corresponding provisions statutory law measures accompanied adequate steps protect citizens 70 decisions taken state basis algorithmic still transparent still possible provide justifications necessary clarify expand existing legislation freedom transparency order achieve goals furthermore algorithmic negate principle decisions made authorities generally justified individually contrary principle impose limits overly complex algorithmic finally greater priority accorded opensource solutions since latter significantly enhance transparency government actions 71 ethical point view general non-compliance rules regulations time however automated “ total ” enforcement law raises number different ethical concerns general rule therefore designed way override technical enforcement specific case balance struck potential transgression automated perhaps preventive enforcement measure times meet requirements proportionality principle 219 f 8. liabilit algorithmic 8. liability algorithmic 8.1 significance criminal responsibility administrative sanctions liability damages vital components ethically sound regulatory framework especially algorithmic technologies ethical perspective ethics commission highlights particular role tort law serves compensation prevention damage therefore significantly contributes protection legally protected interests line fundamental ethical perspective following requirements inter alia set liability needs keep technologies sufficient compensation victims particular case legally protected interests highly relevant terms fundamental compensation comparable situation involving humans conventional would owed b provision behavioural incentives whereby damage paid actors caused damage avoidable undesirable behaviour whose sphere risk question resulted c fairness whereby actors liable pay damages example placed market exercise control benefit efficiency whereby costs covered internalised actors avoid insure costs least amount effort.8.2 harm caused algorithmic 8.2.1 liability “ electronic person ” ethics commission expressly advises granting robots autonomous legal personality often discussed using keyword “ e-person ” intention making liable e. g. self-driving car registered owner “ operates ” mobility service measure would achieve allocation responsibility liability harm responsible ultimately benefit economically fact measure could conversely evade responsibility legal personality machines type legal entity would enable desirable outcome achieved could achieved freely easily another way example help company law treating autonomous machines even analogy natural persons would dangerous mistake 8.2.2 vicarious liability “ autonomous ” ethics commission believes however harm caused autonomous attributed operating according rules vicarious liability would apply case auxiliaries cf particular section 278 german civil code actor uses order broaden range activities example hospital uses surgical robot event malfunction able release liability actor uses vicarious agent example surgeon liable culpable misconduct vicarious agent treated behaviour part actor becomes particularly important case liability algorithmic otherwise liability loopholes easily occur breach duty care person behind proven monitoring algorithmic 220 part f lgorithmic example 18 surgical robot hospital makes operational incision long causes complications algorithmic incorrectly derives score creditworthiness bank ’ customer customer take one-off attractive offer relating property occasionally difficult establish adequate equivalent “ standard care ” autonomous particular soon abilities machine exceed majority cases however malfunctions distinguishable normal functions therefore general cited operator ’ liability standard defined based comparable available market whereby question could expected operator decided based general principles e. g. respect question quality surgical robot differ question quality x-ray device 8.2.3 strict liability essentially well-known fact rules relating classic fault-based liability always sufficient resolving legal issues arise case dangerous products legal far come range different answers challenge particular include ●modification fault-based liability example adaptations standard care various ways easing burden proof reversal burden proof ●various bases strict liability i. e. facilities activities typically cause harm account benefit society whole prohibited ●product liability accordance german act liability defective products gesetz über die haftung für fehlerhafte produkte prodhaftg acts special form liability regardless fault differs strict liability account fact requires inter alia product defect therefore comes fairly close fault-based liability steps taken ensure answers lead legally watertight solutions terms compensation harm caused dangerous applications operation applications currently involves legal uncertainties liability loopholes primarily result unpredictability harmful events including applications placed market hence possibly failure classic fault-based liability result fact various different actors applications interact generally speaking almost impossible prove error occurred and/or cause error open dynamic nature ecosystems close functional interplay products contents services present challenge legal uncertainties perspective companies consumers obstacles innovation acceptance technologies harmful events routinely assigned terms liability compensated impact market intended achieved liability provisions achieved order create appropriate balance interests legislator provide transparency responsibility responsibilities clarified possible insure harm damage practice 221 f 8. liabilit algorithmic ethics commission solve point complex technical legal questions arise pin solutions terms liability law especially instances chances finding solution level explored first ethical perspective crucial legal clarity legal certainty particular regard liability principles described created however debate currently stands appears highly likely addition appropriate amendments product liability directive → section 8.2.4 certain changes need made rules relating fault-based liability and/or bases strict liability need introduced legislative process firstly necessary determine liability regime appropriate particular types products services exact shape regime take depending criticality → section 3.1 relevant criteria specifically relevant within context liability strict liability example based model involving car owner ’ liability could appropriate cases regarding devices operational risk similarly uncontrollable could end leading harm life limb part question insurability and/or possible compulsory insurance always play role decision always taken type harm subject liability e. g. personal injury damage property loss pure financial losses non-material damage ultimately case decision need taken taking consideration liability principles described party liability assigned particular three possible parties liability could assigned two could possibly jointly severally liable 18 liability concept differentiated liability operator ecosystems report entitled “ liability emerging technologies ” commission ’ expert group liability technologies technologies formation 11 p. 40 seqq ●the individual registered owner i. e. owner person similar uses purposes ●the manufacturer ●the operator i. e. whoever exercises greater control ’ operation individual registered owner front-end operator back-end operator manufacturer .18 determination party type liability always depend specific type networked autonomous identification specific spheres liability 8.2.4 product security product liability overall currently important highlight paradigm shift situation whereby products simply placed market situation whereby products placed market additional services continue provided products thereafter ongoing product monitoring product maintenance becoming important security protection standards fulfilled product leaves production plant continue met part subsequent software updates conversely event security gaps subsequently appear manufacturer accordance provisions directives services trade goods subject duty provide security updates line consumers ’ reasonable expectations regarding service life 222 part f lgorithmic example 19 security updates provided smart home result following cyber-attack house broken product liability directive 1980s longer able cover features networked hybrid autonomous products ethics commission recommends part evaluation revision product liability directive level federal government push watertight legal provisions particular following aspects inclusion services including algorithmic term “ product ” b liability product defects appear product placed market result self-modifying software provision updates failure provide productspecific feeds c liability breaches product monitoring obligation inclusion legally protected interests typically affected product safety particular informational self-determination compensation regimes e adaptation risk defence.8.3 need reassessment liability law ecosystems throw variety issues connection liability responsibility example extent liability loophole current tort law cases damage products provided neither recognised ‘ ’ infringed e. g. ownership storage medium statute intended protect another person breached e. g. provisions criminal law conditions intentional damage contrary policy met technologies often involve opportunistic people ’ infrastructures e. g. systematic collation third parties sensor generated private iot devices direct computing capacity transmission functions create complicated liability issues contexts stronger contract law major harm damage particular expense consumers caused account fact usability high-value goods real property machines cars etc becoming increasingly dependent long-term provision services software updates user accounts etc provision services guaranteed and/ even specifically suspended order put individuals pressure electronic repossession 223 f 8. liabilit algorithmic ecosystems extent characterised interaction numerous components operators whereby often disproportionately difficult injured party prove several potential tortfeasors e. g. hardware supplier suppliers various software components feed provider network operator caused harm hand technologies create lack transparency regard cause harm damage conversely help documenting course causal events unprecedented way question therefore arises actor obliged contribute providing clarification cause harm already logging ex-ante actually recorded via logging disclosed event harm ethics commission therefore recommends overall federal government investigate extent current liability law kept challenges ecosystems needs reworked priority given striving achieve solution level ethics commission advises context tendency towards one-sided specific technological features particular feature machine whilst machine creates certain additional dangers involves certain additional issues regarding assignment liability challenges liability law attributable factors e. g. intangibility interaction numerous components networking decentralisation part f lgorithmic summary important recommendations action liability algorithmic 72 liability damages alongside criminal responsibility administrative sanctions vital component ethically sound regulatory framework algorithmic already apparent today algorithmic pose challenges liability law currently stands inter alia complexity dynamism growing “ autonomy ” ethics commission therefore recommends current provisions liability law undergo in-depth checks necessary revisions scope checks revisions restricted basis narrowly defined technological features machine 73 proposal future legal personality would granted high-autonomy algorithmic would liable damages “ electronic person ” pursued far concept protagonists based purported equivalence machine ethically indefensible far boils introducing type company company law fact solve pertinent problems 74 way contrast harm caused autonomous way functionally equivalent employment auxiliaries operator ’ liability making correspond otherwise existing vicarious liability regime principal auxiliaries cf particular section 278 german civil code example bank uses autonomous check creditworthiness customers liable towards least extent would employee perform task 75 debate currently stands appears highly likely appropriate amendments need made product liability directive dates back 1980s connection established product safety standards addition certain changes need made rules relating fault-based liability and/ bases strict liability need introduced case necessary determine liability regime appropriate particular types products services exact shape regime take depending criticality relevant algorithmic consideration given innovative liability concepts currently developed level pathpart g 226 part g e uropean path ethics commission examined great many different questions discussions questions raised ones turn alone indicate opinion serve one many building blocks larger edifice broad-based debate future ethics law return debate interdisciplinary outset encompass broad range sciences diverse mix representatives worlds economy civil society politics view immense economic pressure fast-paced nature technological change findings emerge debate integrated ongoing basis activities parties involved levels shape technological future founded values transfers algorithmic transcend national boundaries means forward-looking discussion ethical legal issues arising connection algorithmic restricted national level need view problems global perspective accordingly strive present findings perspectives pan-european debate well lessons learned implementing gdpr shown economic clout economic area significance market operators providers algorithmic ultimately mean latter prompted economic interests comply ’ basic requirements developing implementing products services requirements ever non-european governments reference point drafting regulatory frameworks.the debate needs take place therefore priority topic agendas international forums oecd council europe united nations g7 g20 mind ethics commission recommends federal government make voice heard within international bodies particular german presidency council second half utilised opportunity promote measures deal governance algorithmic proposed opinion level ethics commission believes federal government actively involved early stages process ongoing basis establishment international panel ipai initiated level g7 global contest future technologies germany europe confronted value models society cultures differ widely prompted debate whether germany europe adapt one non-european models order remain competitive ethics commission supports “ path ” followed date often referred debates “ third way ” strikes balance us chinese positions asserts defining feature technologies consistent alignment values fundamental particular enshrined union ’ charter fundamental council europe ’ convention protection fundamental freedoms order remain actively involved future debate interplay ethics law sovereignty germany europe preserved greatest extent possible reference nation states organisations term “ sovereignty ” encompasses every aspect processing i.e control storage transfer sensitive held bodies autonomous decisions access 227 part g e uropean path globalised world people states companies co-exist side side requires cross-border flows internet – serves conduit flows – global “ network networks ” distributed global structure embraces different legal societal renders complete sovereignty impossible task debate sovereignty therefore tackle vital questions relating technical infrastructure including hardware networks control components routers address servers centres view preserving sovereignty germany europe given huge extent reliant foreign products ethics commission believes urgent need take action german level investments developing safeguarding appropriate technologies infrastructures virtually important basic internet infrastructure components germany indeed europe whole procured continents present efforts preserve sovereignty restricted two main avenues open us first critical analysis assessment basic components second application highest possible security standards operating order minimise risk misuse foreign states organisations looking future however ethics commission believes important germany europe whole develop higher level sovereignty level technical infrastructure support available r work comply highest possible standards security work kind would include design components replace previous attempts engineer integrated solutions existing components achieve required level protection spite known suspected inadequacies security risks.the sovereignty nation state viewed relation nation states relation non-state actors wield significant amounts power economy grows trend economic power concentrated hands emergence power imbalances apparent ever greater extent r work algorithmic technologies carried within framework established small group giants companies often act important source funding therefore say past decades intermediaries played increasingly important role forming opinions therefore influencing sociopolitical discourse means associated risk abuse increased given importance ethical legal fundamental values freedoms preserve sovereignty germany europe ethics commission believes urgent need closely monitor shifts power structures vital functioning democratic state social market economy efficiently regulate according areas wherever needed excessive dependence others turns nation rule taker rather rule maker resulting citizens nation subject requirements imposed players elsewhere world embarking efforts safeguard sovereignty long term therefore politically far-sighted necessity expression ethical responsibility appendix 230 appendi x 1. federal government ’ key questions ethics commission coalition agreement “ set ethics commission within next year provide government parliament proposals develop policy deal algorithms innovation clarification ethics questions add impetus process help define approach towards resolving social conflicts within area policy. ” key questions ethics commission digitisation fundamentally changing society data-based technologies beneficial people ’ everyday lives well industry environment science society whole potential enor mous time digitisation clearly brings certain risks numerous ethical legal questions raised particularly concerning effects develop ments desired role technologies change benefit whole society need examine possible consequences technologies establish ethical safeguards one challenge develop 21st-century law way protects dignity “ become mere object ” guarantees fundamental general personality privacy informational self-determi nation freedom discrimination freedom science freedom conduct business freedom expres sion – bringing equilibrium one another complex tensions principles common good progress innovation solidarity task commission – identified current state discussion legislation euro pean international level ascertained possibilities positive action national level given special consideration sensitive areas – develop ethical standards guidelines protection individuals preservation social cohesion safeguarding promotion prosperity age commission tasked providing federal government recommendations regulatory proposals ethical guidelines developed respected implemented monitored propos als include description underlying concepts well assessments possible consequences side effects appropriately involved work commission order help ethics commission carry work federal government provided following key questions three areas 231 1. federal government ’ key questions ethics commission i. algorithmic decision-making adm advanced automation increasingly shaping economic social realities people ’ everyday lives collection analysis enable develop ment innovative interpretation models make prepare algorithm-based decisions algorithms make possible example recognise patterns differences behaviour different groups whether matter setting individual prices e-commerce assessing creditworthiness selecting candidates recruitment procedures people evaluated technical processes areas life evaluation predictions individual behaviour offer opportunities e.g aiding strengthening innovation within industry increasing efficiency processing processes harbour risks e.g individual freedom self-determination participation equal opportunities among certain individuals social groups social inequality discrimination individuals groups individuals perpetuated biases incorporated programming algorithm training risks particularly acute participation-relevant personality-sensitive adm processes following questions arise especially regard consumer protection ●what ethical limits using adm processes ethical limits ●can ethically necessary adm processes ●are characteristics criteria certain kinds incorporated adm pro cesses – due age origin example ●how determine prejudices distor tions areas ethically undesirable effects adm processes social groups ●what regulatory approaches could prevent manipulation unequal treatment discrimination ●is advisable graduated regulatory frame work based risk social participation potential discrimination ●how reliability reproducibility scrutiny adm guaranteed ●are limits adm crite ria explained people affected ●are test methods make self-learning adm open scrutiny ii industrial administra tive environments deploying highly automated methods ability “ learn ” training addition work done simulating cognitive functions brain developments field raise question dignity autonomy self-determination individual safeguarded fostered leads questions following ●what fundamental ethical principles observed developing programming using ●where ethical boundaries lie using robots especially special areas life care/ assistance dealing particularly vulnerable groups children elderly people disabilities ethically necessary ●is “ ethics design ” possible could implemented monitored ●how ensured machines working basis controlled 232 appendi x ●to creations/inventions generated ascribed bear responsibility malfunctioning responsibility actors involved programmers scientists clients etc made transparent ●what else necessary future sustainably guarantee freedoms fundamental upon society based iii digitisation characterised increase volume big vast accumulation individual actors high speed processing real time connectivity internet complex networks actors internet things increasing ubiquity permanence various methods analysis amount available increases ability un dertake granular analyses develop business models change value-added chains work processes regarded commodi ty enables value creation “ economy ” national level current laws e.g general protection regulation open legislation numerous legislative initiatives concern handling e.g eprivacy regula tion legislative proposals regarding free flow one hand intended safeguard funda mental informational self-de termination hand intended enable useful innovative processing proposals discussed whether access trade could regulated first time better regulated.in process following questions arise regard ing handling general access ●what ethical limits economization ●who permitted derive economic benefit ●should obligation offer payment models ●is advisable uniform rules apply equally preference given rules apply specific areas e.g brain connecting factor rules apply specific areas ●what consequences existing access exclusivity competition innovation consequences would additional access exclusivity ●is need state offer support part provision general services citizens navigate internet social networks responsible competent confident manner learn handle provision particular open become part provision services state ●how much transparency necessary appropriate safeguard informational self-determina tion enable citizens participate economic life self-determined manner ●do particular life circumstances require special protec tion concepts specific user groups ●are existing institutions sensitive areas sufficient ensure ethically adequate stakeholder representation ensured long term 233 1. federal government ’ key questions ethics commission ●what effects extensive collections functioning market economy e.g compet itiveness asymmetry suppliers consumers possibility developing inno vative products democracy e.g recording analysing behaviour social networks necessary action taken power/data silos especially intermediaries ●should access declared good certain cases cases ethical criteria ●the non-personal collective effects example individuals certain population groups placed disadvantage analysis shows payment habits worse par ticular neighbourhood regulatory instruments would needed sectors ●are statutory regulations improving access possible necessary advisable ●should processing prohibited certain cases ethical reasons example cases involving certain types e.g political views brain certain areas e.g profiling political purposes elections ●under circumstances ethical obligation ●does legal sufficiently recognise possible benefits processing common good achieved ●is possible advisable create experimentation clauses testing applications regulatory instruments ●does make sense invest infrastructures ones ●how constitutionally protected interests individuals enterprises science art reconciled interest last revised 5 234 appendi x 2. members ethics commission co-spokespersons prof. dr christiane wendehorst ●professor civil law university vienna ●co-head department innovation digitalisation law university vienna ●president law institute eli prof. dr christiane woopen ●professor ethics theory medicine head unit ethics university clinic cologne ●executive director cologne ethics economics social sciences health ceres university cologne ●chair group ethics science technologies ege members prof. dr johanna haberer ●professor christian media studies friedrich alexander university erlangen nuremberg fau ●director institute practical theology friedrich alexander university erlangen nuremberg fau marit hansen ●data protection commissioner land schleswig-holstein ●head unabhängiges landeszentrum für datenschutz schleswig-holstein independent centre privacy protection schleswig-holstein prof. dr dirk heckmann ●full professor law security digitization technical university munich tum ●director bavarian institute transformation ●judge bavarian constitutional court prof. ulrich kelber ●federal commissioner protection freedom ●honorary professor bonn-rhein-sieg university applied sciences h-brs 235 2. members ethics commission prof. dieter kempf ●president federation german industries bdi ●honorary professor friedrich alexander university erlangen nuremberg fau prof. dr mario martini ●professor administration law administrative law law german university administrative sciences speyer duv speyer ●head programme area “ transfor mation state age ” deputy director german institute administration föv klaus müller ●executive director federation german consumer organisations vzbv ●lecturer heinrich heine university düsseldorf hhu paul nemitz ●principle advisor commis sion directorate-general justice consumers prof. dr sabine sachweh ●professor applied software engineering dortmund university applied sciences arts fh dortmund ●spokesperson board member institute transformation application living domains idial dortmund university applied sciences arts fh dortmund ●co-spokesperson “ digitalisation education elderly ” advisory council federal ministry family affairs senior citizens women youthchristin schäfer ●founder managing director company acs plus science boutique ●advisor big analytics group german economic institute cologne iw köln prof. dr rolf schwartmann ●professor civil law economic law cologne university applied sciences th köln ●head centre media law cologne university applied sciences th köln ●chairman german association protection security gdd prof. dr judith simon ●professor ethics technol ogy university hamburg uhh prof. dr wolfgang wahlster ●professor computer science chair saarland university ●ceo/cea german dfki ●head steering committee standardisation roadmap german institute standardization din prof. dr thomas wischmeyer ●assistant professor tenure track law law university bielefeld current 10 imprint berlin opinion ethics commissionpublisher ethics commission federal governmentfederal ministry interior building communityalt-moabit 140 10557 berlinfederal ministry justice consumer protectionmohrenstraße 37 10117 berlin e-mail datenethikkommission_gs bmi.bund.dedatenethikkommission_gs bmjv.bund.de website www.datenethikkommission.de design atelier hauer dörfler gmbh berlin photo credits p. 53 shutterstock.com p. 234 bmi group photo studio wilke christiane wendehorst reiner zensen christiane woopen bpa/kugler ulrich kelber p. 235 christian kruppa dieter kempf vzbv/gert baumbach klaus müller markus mielek sabine sachweh th köln/schmülgen rolf schwartmann uhh/nicolai judith simon jim rakete wolfgang wahlster printingbrandenburgische universitätsdruckerei und verlags gesellschaft potsdam mbh bud © dek']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_representative_docs(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "No prediction data was generated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[214], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m topic_model\u001b[38;5;241m.\u001b[39mreduce_outliers(documents, topics\u001b[38;5;241m=\u001b[39mtopics)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Obtention des nouveaux topics\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m new_topics, new_probs \u001b[38;5;241m=\u001b[39m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Code_Telecom/projet_NLP/.env_projet_NLP/lib/python3.12/site-packages/bertopic/_bertopic.py:603\u001b[0m, in \u001b[0;36mBERTopic.transform\u001b[0;34m(self, documents, embeddings, images)\u001b[0m\n\u001b[1;32m    601\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClustering - Approximating new points with `hdbscan_model`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_supported_hdbscan(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhdbscan_model):\n\u001b[0;32m--> 603\u001b[0m     predictions, probabilities \u001b[38;5;241m=\u001b[39m \u001b[43mhdbscan_delegator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhdbscan_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapproximate_predict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumap_embeddings\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;66;03m# Calculate probabilities\u001b[39;00m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_probabilities:\n",
      "File \u001b[0;32m~/Documents/Code_Telecom/projet_NLP/.env_projet_NLP/lib/python3.12/site-packages/bertopic/cluster/_utils.py:21\u001b[0m, in \u001b[0;36mhdbscan_delegator\u001b[0;34m(model, func, embeddings)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapproximate_predict\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, hdbscan\u001b[38;5;241m.\u001b[39mHDBSCAN):\n\u001b[0;32m---> 21\u001b[0m         predictions, probabilities \u001b[38;5;241m=\u001b[39m \u001b[43mhdbscan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapproximate_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m predictions, probabilities\n\u001b[1;32m     24\u001b[0m     str_type_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(model))\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[0;32m~/Documents/Code_Telecom/projet_NLP/.env_projet_NLP/lib/python3.12/site-packages/hdbscan/prediction.py:379\u001b[0m, in \u001b[0;36mapproximate_predict\u001b[0;34m(clusterer, points_to_predict, return_connecting_points)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapproximate_predict\u001b[39m(clusterer, points_to_predict, return_connecting_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    332\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict the cluster label of new points. The returned labels\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m    will be those of the original clustering found by ``clusterer``,\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    and therefore are not (necessarily) the cluster labels that would\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m \n\u001b[1;32m    378\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mclusterer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_data_\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClusterer does not have prediction data!\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    381\u001b[0m                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Try fitting with prediction_data=True set,\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    382\u001b[0m                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or run generate_prediction_data on the clusterer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    384\u001b[0m     points_to_predict \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(points_to_predict)\n",
      "File \u001b[0;32m~/Documents/Code_Telecom/projet_NLP/.env_projet_NLP/lib/python3.12/site-packages/hdbscan/hdbscan_.py:1464\u001b[0m, in \u001b[0;36mHDBSCAN.prediction_data_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1461\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprediction_data_\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prediction_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1464\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo prediction data was generated\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1465\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1466\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prediction_data\n",
      "\u001b[0;31mAttributeError\u001b[0m: No prediction data was generated"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reclassification des outliers\n",
    "topic_model.reduce_outliers(documents, topics=topics)\n",
    "\n",
    "# Obtention des nouveaux topics\n",
    "new_topics, new_probs = topic_model.transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topic_model.get_topic_info())\n",
    "\n",
    "# Visualisation\n",
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>Name of the document</th>\n",
       "      <th>Institution</th>\n",
       "      <th>URL</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Affiliates</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 28</th>\n",
       "      <th>Unnamed: 29</th>\n",
       "      <th>text</th>\n",
       "      <th>langue</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>categorie Institution</th>\n",
       "      <th>theme</th>\n",
       "      <th>topic</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Intel Recommends Public Policy Principles for ...</td>\n",
       "      <td>Intel</td>\n",
       "      <td>https://community.intel.com/t5/Blogs/Intel/Pol...</td>\n",
       "      <td>Naveen Rao</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\n\\n\\tIntel Recommends Public Policy Princip...</td>\n",
       "      <td>en</td>\n",
       "      <td>intel recommends public policy principles arti...</td>\n",
       "      <td>[0.01722362 0.         0.         ... 0.      ...</td>\n",
       "      <td>Entreprises technologiques et multinationales</td>\n",
       "      <td>Privacy</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>The Toronto Declaration: Protecting the right ...</td>\n",
       "      <td>Access Now</td>\n",
       "      <td>https://www.torontodeclaration.org/declaration...</td>\n",
       "      <td>Anna Bacciarelli, Joe Westby, Fanny Hidvegi, E...</td>\n",
       "      <td>Access Now, AI Now Institute at New York Unive...</td>\n",
       "      <td>civil society</td>\n",
       "      <td>UK</td>\n",
       "      <td>2018-05-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\n\\n\\n\\nThe Toronto Declaration\\n\\n\\n\\n\\n\\n\\...</td>\n",
       "      <td>en</td>\n",
       "      <td>toronto declaration skip main content toronto ...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>ONG et initiatives de droits humains</td>\n",
       "      <td>Justice and fairness</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>39</td>\n",
       "      <td>AI and Human Rights</td>\n",
       "      <td>All Tech is Human</td>\n",
       "      <td>https://alltechishuman.org/ai-human-rights-report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nAI and Human Rights: Building a ...</td>\n",
       "      <td>en</td>\n",
       "      <td>ai human rights building tech future aligned p...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>Associations professionnelles et groupes de ré...</td>\n",
       "      <td>Sustainable</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>46</td>\n",
       "      <td>Safety First for Automated Driving – Proposed ...</td>\n",
       "      <td>Aptiv</td>\n",
       "      <td>https://www.heise.de/downloads/18/2/7/0/8/1/7/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Germany</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019 SAFETY FIRST FOR  AUTOMATED DRIVING \\nI \\...</td>\n",
       "      <td>en</td>\n",
       "      <td>2019 safety first automated driving ii iii aut...</td>\n",
       "      <td>[0.         0.00153116 0.         ... 0.      ...</td>\n",
       "      <td>Entreprises technologiques et multinationales</td>\n",
       "      <td>Non-maleficence</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>49</td>\n",
       "      <td>It’s Time to Do Something: Mitigating the Nega...</td>\n",
       "      <td>Association for Computing Machinery - Future o...</td>\n",
       "      <td>https://perma.cc/K22T-5DFU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\nPerma | It’s Time to Do Something: Mitigat...</td>\n",
       "      <td>en</td>\n",
       "      <td>perma ’ time something mitigating negative imp...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>Associations professionnelles et groupes de ré...</td>\n",
       "      <td>Transparency</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>702</td>\n",
       "      <td>Recommendations on Updating the National Artif...</td>\n",
       "      <td>University of Stanford</td>\n",
       "      <td>https://hai.stanford.edu/sites/default/files/2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommendations on  Updating the National  Art...</td>\n",
       "      <td>en</td>\n",
       "      <td>recommendations updating national artificial i...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>Instituts de recherche et universités</td>\n",
       "      <td>Non-maleficence</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>706</td>\n",
       "      <td>AI UX: 7 principles of designing Good AI Products</td>\n",
       "      <td>UX Studio Team</td>\n",
       "      <td>https://uxstudioteam.com/ux-blog/ai-ux/</td>\n",
       "      <td>Dávid Pásztor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>civil society</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>2018-04-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AI UX: 7 Principles of Designing Good AI Produ...</td>\n",
       "      <td>en</td>\n",
       "      <td>ai ux 7 principles designing good ai products ...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>Associations professionnelles et groupes de ré...</td>\n",
       "      <td>Trust</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>710</td>\n",
       "      <td>Global competition and convergence of AI Law</td>\n",
       "      <td>Vrije Universiteit Brussel</td>\n",
       "      <td>https://osf.io/preprints/socarxiv/j36ke/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\n\\n\\nOSF\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\...</td>\n",
       "      <td>en</td>\n",
       "      <td>osf full functionality site necessary enable j...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>Instituts de recherche et universités</td>\n",
       "      <td>Transparency</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>715</td>\n",
       "      <td>Guidance for Regulation of Artificial Intellig...</td>\n",
       "      <td>White House (US)</td>\n",
       "      <td>https://www.whitehouse.gov/wp-content/uploads/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EXECUTIVE OFFICE OF THE PRESIDENT  OFFICE OF M...</td>\n",
       "      <td>en</td>\n",
       "      <td>executive office president office management b...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>Gouvernements et organismes publics nationaux</td>\n",
       "      <td>Non-maleficence</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>717</td>\n",
       "      <td>4 Steps to developing Responsible AI</td>\n",
       "      <td>World Economic Forum (WEF)</td>\n",
       "      <td>https://www.weforum.org/agenda/2019/06/4-steps...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>international</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\n\\n4 steps to developing responsible AI | W...</td>\n",
       "      <td>en</td>\n",
       "      <td>4 steps developing responsible ai world econom...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>Associations professionnelles et groupes de ré...</td>\n",
       "      <td>Responsibility</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc_id                               Name of the document  \\\n",
       "0         3  Intel Recommends Public Policy Principles for ...   \n",
       "3        13  The Toronto Declaration: Protecting the right ...   \n",
       "24       39                                AI and Human Rights   \n",
       "28       46  Safety First for Automated Driving – Proposed ...   \n",
       "31       49  It’s Time to Do Something: Mitigating the Nega...   \n",
       "..      ...                                                ...   \n",
       "438     702  Recommendations on Updating the National Artif...   \n",
       "440     706  AI UX: 7 principles of designing Good AI Products   \n",
       "441     710       Global competition and convergence of AI Law   \n",
       "445     715  Guidance for Regulation of Artificial Intellig...   \n",
       "447     717               4 Steps to developing Responsible AI   \n",
       "\n",
       "                                           Institution  \\\n",
       "0                                                Intel   \n",
       "3                                           Access Now   \n",
       "24                                   All Tech is Human   \n",
       "28                                               Aptiv   \n",
       "31   Association for Computing Machinery - Future o...   \n",
       "..                                                 ...   \n",
       "438                             University of Stanford   \n",
       "440                                     UX Studio Team   \n",
       "441                         Vrije Universiteit Brussel   \n",
       "445                                   White House (US)   \n",
       "447                         World Economic Forum (WEF)   \n",
       "\n",
       "                                                   URL  \\\n",
       "0    https://community.intel.com/t5/Blogs/Intel/Pol...   \n",
       "3    https://www.torontodeclaration.org/declaration...   \n",
       "24   https://alltechishuman.org/ai-human-rights-report   \n",
       "28   https://www.heise.de/downloads/18/2/7/0/8/1/7/...   \n",
       "31                          https://perma.cc/K22T-5DFU   \n",
       "..                                                 ...   \n",
       "438  https://hai.stanford.edu/sites/default/files/2...   \n",
       "440            https://uxstudioteam.com/ux-blog/ai-ux/   \n",
       "441           https://osf.io/preprints/socarxiv/j36ke/   \n",
       "445  https://www.whitehouse.gov/wp-content/uploads/...   \n",
       "447  https://www.weforum.org/agenda/2019/06/4-steps...   \n",
       "\n",
       "                                               Authors  \\\n",
       "0                                           Naveen Rao   \n",
       "3    Anna Bacciarelli, Joe Westby, Fanny Hidvegi, E...   \n",
       "24                                                 NaN   \n",
       "28                                                 NaN   \n",
       "31                                                 NaN   \n",
       "..                                                 ...   \n",
       "438                                                NaN   \n",
       "440                                      Dávid Pásztor   \n",
       "441                                                NaN   \n",
       "445                                                NaN   \n",
       "447                                                NaN   \n",
       "\n",
       "                                            Affiliates         Sector  \\\n",
       "0                                                  NaN            NaN   \n",
       "3    Access Now, AI Now Institute at New York Unive...  civil society   \n",
       "24                                                 NaN            NaN   \n",
       "28                                                 NaN            NaN   \n",
       "31                                                 NaN            NaN   \n",
       "..                                                 ...            ...   \n",
       "438                                                NaN            NaN   \n",
       "440                                                NaN  civil society   \n",
       "441                                                NaN            NaN   \n",
       "445                                                NaN            NaN   \n",
       "447                                                NaN            NaN   \n",
       "\n",
       "           Country        Date Keywords  ...  Unnamed: 28 Unnamed: 29  \\\n",
       "0              NaN         NaN      NaN  ...          NaN         NaN   \n",
       "3               UK  2018-05-16      NaN  ...          NaN         NaN   \n",
       "24             USA         NaN      NaN  ...          NaN         NaN   \n",
       "28         Germany         NaN      NaN  ...          NaN         NaN   \n",
       "31             USA         NaN      NaN  ...          NaN         NaN   \n",
       "..             ...         ...      ...  ...          ...         ...   \n",
       "438            USA         NaN      NaN  ...          NaN         NaN   \n",
       "440        Hungary  2018-04-17      NaN  ...          NaN         NaN   \n",
       "441        Belgium         NaN      NaN  ...          NaN         NaN   \n",
       "445            USA         NaN      NaN  ...          NaN         NaN   \n",
       "447  international         NaN      NaN  ...          NaN         NaN   \n",
       "\n",
       "                                                  text  langue  \\\n",
       "0    \\n\\n\\n\\tIntel Recommends Public Policy Princip...      en   \n",
       "3    \\n\\n\\n\\n\\nThe Toronto Declaration\\n\\n\\n\\n\\n\\n\\...      en   \n",
       "24   \\n\\n\\n\\n\\n\\n\\nAI and Human Rights: Building a ...      en   \n",
       "28   2019 SAFETY FIRST FOR  AUTOMATED DRIVING \\nI \\...      en   \n",
       "31   \\n\\nPerma | It’s Time to Do Something: Mitigat...      en   \n",
       "..                                                 ...     ...   \n",
       "438  Recommendations on  Updating the National  Art...      en   \n",
       "440  AI UX: 7 Principles of Designing Good AI Produ...      en   \n",
       "441  \\n\\n\\n\\nOSF\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\...      en   \n",
       "445  EXECUTIVE OFFICE OF THE PRESIDENT  OFFICE OF M...      en   \n",
       "447  \\n\\n\\n4 steps to developing responsible AI | W...      en   \n",
       "\n",
       "                                        text_processed  \\\n",
       "0    intel recommends public policy principles arti...   \n",
       "3    toronto declaration skip main content toronto ...   \n",
       "24   ai human rights building tech future aligned p...   \n",
       "28   2019 safety first automated driving ii iii aut...   \n",
       "31   perma ’ time something mitigating negative imp...   \n",
       "..                                                 ...   \n",
       "438  recommendations updating national artificial i...   \n",
       "440  ai ux 7 principles designing good ai products ...   \n",
       "441  osf full functionality site necessary enable j...   \n",
       "445  executive office president office management b...   \n",
       "447  4 steps developing responsible ai world econom...   \n",
       "\n",
       "                                                 tfidf  \\\n",
       "0    [0.01722362 0.         0.         ... 0.      ...   \n",
       "3                              [0. 0. 0. ... 0. 0. 0.]   \n",
       "24                             [0. 0. 0. ... 0. 0. 0.]   \n",
       "28   [0.         0.00153116 0.         ... 0.      ...   \n",
       "31                             [0. 0. 0. ... 0. 0. 0.]   \n",
       "..                                                 ...   \n",
       "438                            [0. 0. 0. ... 0. 0. 0.]   \n",
       "440                            [0. 0. 0. ... 0. 0. 0.]   \n",
       "441                            [0. 0. 0. ... 0. 0. 0.]   \n",
       "445                            [0. 0. 0. ... 0. 0. 0.]   \n",
       "447                            [0. 0. 0. ... 0. 0. 0.]   \n",
       "\n",
       "                                 categorie Institution                 theme  \\\n",
       "0        Entreprises technologiques et multinationales               Privacy   \n",
       "3                 ONG et initiatives de droits humains  Justice and fairness   \n",
       "24   Associations professionnelles et groupes de ré...           Sustainable   \n",
       "28       Entreprises technologiques et multinationales       Non-maleficence   \n",
       "31   Associations professionnelles et groupes de ré...          Transparency   \n",
       "..                                                 ...                   ...   \n",
       "438              Instituts de recherche et universités       Non-maleficence   \n",
       "440  Associations professionnelles et groupes de ré...                 Trust   \n",
       "441              Instituts de recherche et universités          Transparency   \n",
       "445      Gouvernements et organismes publics nationaux       Non-maleficence   \n",
       "447  Associations professionnelles et groupes de ré...        Responsibility   \n",
       "\n",
       "     topic  probs  \n",
       "0       -1    0.0  \n",
       "3       -1    0.0  \n",
       "24      -1    0.0  \n",
       "28      -1    0.0  \n",
       "31      -1    0.0  \n",
       "..     ...    ...  \n",
       "438     -1    0.0  \n",
       "440     -1    0.0  \n",
       "441     -1    0.0  \n",
       "445     -1    0.0  \n",
       "447     -1    0.0  \n",
       "\n",
       "[126 rows x 39 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"topic\"] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>Name of the document</th>\n",
       "      <th>Institution</th>\n",
       "      <th>URL</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Affiliates</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 28</th>\n",
       "      <th>Unnamed: 29</th>\n",
       "      <th>text</th>\n",
       "      <th>langue</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>categorie Institution</th>\n",
       "      <th>theme</th>\n",
       "      <th>topic</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Intel Recommends Public Policy Principles for ...</td>\n",
       "      <td>Intel</td>\n",
       "      <td>https://community.intel.com/t5/Blogs/Intel/Pol...</td>\n",
       "      <td>Naveen Rao</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\n\\n\\tIntel Recommends Public Policy Princip...</td>\n",
       "      <td>en</td>\n",
       "      <td>intel recommends public policy principles arti...</td>\n",
       "      <td>[0.01722362 0.         0.         ... 0.      ...</td>\n",
       "      <td>Entreprises technologiques et multinationales</td>\n",
       "      <td>Privacy</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>Artificial intelligence in Healthcare</td>\n",
       "      <td>Academy of Medical Royal Colleges</td>\n",
       "      <td>https://www.aomrc.org.uk/wp-content/uploads/20...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Artificial Intelligence in HealthcareJanuary /...</td>\n",
       "      <td>en</td>\n",
       "      <td>artificial intelligence healthcarejanuary 2019...</td>\n",
       "      <td>[0.         0.00872152 0.         ... 0.      ...</td>\n",
       "      <td>Instituts de recherche et universités</td>\n",
       "      <td>Trust</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>Human rights in the age of Artificial Intellig...</td>\n",
       "      <td>Access Now</td>\n",
       "      <td>https://www.accessnow.org/cms/assets/uploads/2...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HUMAN RIGHTS  IN THE AGE OF ARTIFICIAL INTELLI...</td>\n",
       "      <td>en</td>\n",
       "      <td>human rights age artificial intelligence repor...</td>\n",
       "      <td>[0.        0.0087539 0.        ... 0.        0...</td>\n",
       "      <td>ONG et initiatives de droits humains</td>\n",
       "      <td>Justice and fairness</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>The Toronto Declaration: Protecting the right ...</td>\n",
       "      <td>Access Now</td>\n",
       "      <td>https://www.torontodeclaration.org/declaration...</td>\n",
       "      <td>Anna Bacciarelli, Joe Westby, Fanny Hidvegi, E...</td>\n",
       "      <td>Access Now, AI Now Institute at New York Unive...</td>\n",
       "      <td>civil society</td>\n",
       "      <td>UK</td>\n",
       "      <td>2018-05-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\n\\n\\n\\nThe Toronto Declaration\\n\\n\\n\\n\\n\\n\\...</td>\n",
       "      <td>en</td>\n",
       "      <td>toronto declaration skip main content toronto ...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>ONG et initiatives de droits humains</td>\n",
       "      <td>Justice and fairness</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>Europe’s approach to artificial intelligence: ...</td>\n",
       "      <td>AccessNow</td>\n",
       "      <td>https://www.accessnow.org/wp-content/uploads/2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accessnow.org EUROPE’S APPROACH TO ARTIFICIAL ...</td>\n",
       "      <td>en</td>\n",
       "      <td>accessnow.org europe ’ approach artificial int...</td>\n",
       "      <td>[0.        0.0035214 0.        ... 0.        0...</td>\n",
       "      <td>ONG et initiatives de droits humains</td>\n",
       "      <td>Transparency</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                               Name of the document  \\\n",
       "0       3  Intel Recommends Public Policy Principles for ...   \n",
       "1       9              Artificial intelligence in Healthcare   \n",
       "2      12  Human rights in the age of Artificial Intellig...   \n",
       "3      13  The Toronto Declaration: Protecting the right ...   \n",
       "4      14  Europe’s approach to artificial intelligence: ...   \n",
       "\n",
       "                         Institution  \\\n",
       "0                              Intel   \n",
       "1  Academy of Medical Royal Colleges   \n",
       "2                         Access Now   \n",
       "3                         Access Now   \n",
       "4                          AccessNow   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://community.intel.com/t5/Blogs/Intel/Pol...   \n",
       "1  https://www.aomrc.org.uk/wp-content/uploads/20...   \n",
       "2  https://www.accessnow.org/cms/assets/uploads/2...   \n",
       "3  https://www.torontodeclaration.org/declaration...   \n",
       "4  https://www.accessnow.org/wp-content/uploads/2...   \n",
       "\n",
       "                                             Authors  \\\n",
       "0                                         Naveen Rao   \n",
       "1                                                NaN   \n",
       "2                                                  .   \n",
       "3  Anna Bacciarelli, Joe Westby, Fanny Hidvegi, E...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                          Affiliates         Sector Country  \\\n",
       "0                                                NaN            NaN     NaN   \n",
       "1                                                NaN            NaN      UK   \n",
       "2                                                  .            NaN     NaN   \n",
       "3  Access Now, AI Now Institute at New York Unive...  civil society      UK   \n",
       "4                                                NaN            NaN     USA   \n",
       "\n",
       "         Date Keywords  ...  Unnamed: 28 Unnamed: 29  \\\n",
       "0         NaN      NaN  ...          NaN         NaN   \n",
       "1         NaN      NaN  ...          NaN         NaN   \n",
       "2         NaN      NaN  ...          NaN         NaN   \n",
       "3  2018-05-16      NaN  ...          NaN         NaN   \n",
       "4     2020-12      NaN  ...          NaN         NaN   \n",
       "\n",
       "                                                text  langue  \\\n",
       "0  \\n\\n\\n\\tIntel Recommends Public Policy Princip...      en   \n",
       "1  Artificial Intelligence in HealthcareJanuary /...      en   \n",
       "2  HUMAN RIGHTS  IN THE AGE OF ARTIFICIAL INTELLI...      en   \n",
       "3  \\n\\n\\n\\n\\nThe Toronto Declaration\\n\\n\\n\\n\\n\\n\\...      en   \n",
       "4  accessnow.org EUROPE’S APPROACH TO ARTIFICIAL ...      en   \n",
       "\n",
       "                                      text_processed  \\\n",
       "0  intel recommends public policy principles arti...   \n",
       "1  artificial intelligence healthcarejanuary 2019...   \n",
       "2  human rights age artificial intelligence repor...   \n",
       "3  toronto declaration skip main content toronto ...   \n",
       "4  accessnow.org europe ’ approach artificial int...   \n",
       "\n",
       "                                               tfidf  \\\n",
       "0  [0.01722362 0.         0.         ... 0.      ...   \n",
       "1  [0.         0.00872152 0.         ... 0.      ...   \n",
       "2  [0.        0.0087539 0.        ... 0.        0...   \n",
       "3                            [0. 0. 0. ... 0. 0. 0.]   \n",
       "4  [0.        0.0035214 0.        ... 0.        0...   \n",
       "\n",
       "                           categorie Institution                 theme  topic  \\\n",
       "0  Entreprises technologiques et multinationales               Privacy     -1   \n",
       "1          Instituts de recherche et universités                 Trust      0   \n",
       "2           ONG et initiatives de droits humains  Justice and fairness      6   \n",
       "3           ONG et initiatives de droits humains  Justice and fairness     -1   \n",
       "4           ONG et initiatives de droits humains          Transparency      7   \n",
       "\n",
       "   probs  \n",
       "0    0.0  \n",
       "1    1.0  \n",
       "2    1.0  \n",
       "3    0.0  \n",
       "4    1.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTopic avec N-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_gram_range = (2, 3)\n",
    "\n",
    "hdbscan_model = hdbscan.HDBSCAN(min_cluster_size=20, min_samples=1, cluster_selection_epsilon=0.1)\n",
    "topic_model = BERTopic(hdbscan_model=hdbscan_model, language=\"english\", nr_topics=10, n_gram_range=n_gram_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 0\n",
    "while n_topics < 8:\n",
    "    topics, probs = topic_model.fit_transform(documents)\n",
    "    n_topics = len(set(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topic'] = topics\n",
    "df['probs'] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Topic  Count                                               Name  \\\n",
      "0     -1    139  -1_facial recognition_decision making_member s...   \n",
      "1      0     35  0_ethics commission_decision making_related te...   \n",
      "2      1     33  1_industrial strategy_strategy white_industria...   \n",
      "3      2     32  2_climate change_united nations_discussion pap...   \n",
      "4      3     91  3_member states_industrial revolution_third in...   \n",
      "5      4     31  4_algorithmic decisionmaking_centre ethics_bia...   \n",
      "6      5     67  5_united states_index report_autonomous intell...   \n",
      "7      6     29  6_computers learn_promise computers learn_prom...   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [facial recognition, decision making, member s...   \n",
      "1  [ethics commission, decision making, related t...   \n",
      "2  [industrial strategy, strategy white, industri...   \n",
      "3  [climate change, united nations, discussion pa...   \n",
      "4  [member states, industrial revolution, third i...   \n",
      "5  [algorithmic decisionmaking, centre ethics, bi...   \n",
      "6  [united states, index report, autonomous intel...   \n",
      "7  [computers learn, promise computers learn, pro...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [study panel future science eprs parliamentary...  \n",
      "1  [rr\\1215422en.docx pe650.508v02-00 enunited di...  \n",
      "2  [government canada strategic plan management c...  \n",
      "3  [climate change recommendations government act...  \n",
      "4  [strasbourg 17 cahai 23 ad hoc committee cahai...  \n",
      "5  [policy briefing algorithmic impact assessment...  \n",
      "6  [index report 2 index report introduction inde...  \n",
      "7  [future computed role society microsoft publis...  \n"
     ]
    }
   ],
   "source": [
    "# Afficher les topics les plus fréquents\n",
    "print(topic_model.get_topic_info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('facial recognition', 0.002628323241856115), ('decision making', 0.002132439657376694), ('member states', 0.0017168516264077832), ('council europe', 0.00166487076085066), ('covid 19', 0.0013953907143980596), ('private sector', 0.001280593061468446), ('social media', 0.001197988508807949), ('law enforcement', 0.001191830092961012), ('freedom expression', 0.0011648321361954108), ('united states', 0.0011479970307570636)]\n"
     ]
    }
   ],
   "source": [
    "print(topic_model.get_topic(-1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           0,
           "ethics commission | decision making | related technologies | copyright design | robotics related",
           35
          ],
          [
           1,
           "industrial strategy | strategy white | industrial strategy white | health care | intelligent society",
           33
          ],
          [
           2,
           "climate change | united nations | discussion paper national | per cent | paper national strategy",
           32
          ],
          [
           3,
           "member states | industrial revolution | third industrial | third industrial revolution | council europe",
           91
          ],
          [
           4,
           "algorithmic decisionmaking | centre ethics | bias algorithmic | bias algorithmic decisionmaking | impact assessments",
           31
          ],
          [
           5,
           "united states | index report | autonomous intelligent | global initiative | ieee global initiative",
           67
          ],
          [
           6,
           "computers learn | promise computers learn | promise computers | power promise | power promise computers",
           29
          ]
         ],
         "hovertemplate": "<b>Topic %{customdata[0]}</b><br>%{customdata[1]}<br>Size: %{customdata[2]}",
         "legendgroup": "",
         "marker": {
          "color": "#B0BEC5",
          "line": {
           "color": "DarkSlateGrey",
           "width": 2
          },
          "size": [
           35,
           33,
           32,
           91,
           31,
           67,
           29
          ],
          "sizemode": "area",
          "sizeref": 0.056875,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          13.78499698638916,
          15.221529960632324,
          14.78002643585205,
          13.881237030029297,
          -18.011377334594727,
          -18.83285903930664,
          -18.395212173461914
         ],
         "xaxis": "x",
         "y": [
          7.409037113189697,
          6.871676921844482,
          6.748307228088379,
          6.857135772705078,
          -15.447729110717773,
          -16.26936149597168,
          -15.831598281860352
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "D1",
          "x": -21.657787895202638,
          "y": -5.09468652009964,
          "yshift": 10
         },
         {
          "showarrow": false,
          "text": "D2",
          "x": -2.0765142202377334,
          "xshift": 10,
          "y": 8.520392680168152
         }
        ],
        "height": 650,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "legend": {
         "itemsizing": "constant",
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "shapes": [
         {
          "line": {
           "color": "#CFD8DC",
           "width": 2
          },
          "type": "line",
          "x0": -2.0765142202377334,
          "x1": -2.0765142202377334,
          "y0": -18.709765720367432,
          "y1": 8.520392680168152
         },
         {
          "line": {
           "color": "#9E9E9E",
           "width": 2
          },
          "type": "line",
          "x0": -21.657787895202638,
          "x1": 17.50475945472717,
          "y0": -5.09468652009964,
          "y1": -5.09468652009964
         }
        ],
        "sliders": [
         {
          "active": 0,
          "pad": {
           "t": 50
          },
          "steps": [
           {
            "args": [
             {
              "marker.color": [
               [
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 0",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 1",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 2",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 3",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 4",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 5",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red"
               ]
              ]
             }
            ],
            "label": "Topic 6",
            "method": "update"
           }
          ]
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Intertopic Distance Map</b>",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 650,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "range": [
          -21.657787895202638,
          17.50475945472717
         ],
         "title": {
          "text": ""
         },
         "visible": false
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          -18.709765720367432,
          8.520392680168152
         ],
         "title": {
          "text": ""
         },
         "visible": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualisation des topics\n",
    "topic_model.visualize_topics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.732013391962925,
          0.732013391962925,
          0
         ],
         "xaxis": "x",
         "y": [
          -25,
          -25,
          -35,
          -35
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.732013391962925,
          0.8856047303988347,
          0.8856047303988347,
          0
         ],
         "xaxis": "x",
         "y": [
          -30,
          -30,
          -45,
          -45
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.8981182741041953,
          0.8981182741041953,
          0.8856047303988347
         ],
         "xaxis": "x",
         "y": [
          -15,
          -15,
          -37.5,
          -37.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.8774382371355237,
          0.8774382371355237,
          0
         ],
         "xaxis": "x",
         "y": [
          -55,
          -55,
          -65,
          -65
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.8981182741041953,
          0.952705677072372,
          0.952705677072372,
          0.8774382371355237
         ],
         "xaxis": "x",
         "y": [
          -26.25,
          -26.25,
          -60,
          -60
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.96567843805415,
          0.96567843805415,
          0.952705677072372
         ],
         "xaxis": "x",
         "y": [
          -5,
          -5,
          -43.125,
          -43.125
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "autosize": false,
        "height": 305,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "hovermode": "closest",
        "plot_bgcolor": "#ECEFF1",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Hierarchical Clustering</b>",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "mirror": "allticks",
         "rangemode": "tozero",
         "showgrid": false,
         "showline": true,
         "showticklabels": true,
         "ticks": "outside",
         "type": "linear",
         "zeroline": false
        },
        "yaxis": {
         "mirror": "allticks",
         "range": [
          -70,
          0
         ],
         "rangemode": "tozero",
         "showgrid": false,
         "showline": true,
         "showticklabels": true,
         "tickmode": "array",
         "ticks": "outside",
         "ticktext": [
          "6_computers learn_promise c...",
          "4_algorithmic decisionmakin...",
          "0_ethics commission_decisio...",
          "3_member states_industrial ...",
          "5_united states_index repor...",
          "2_climate change_united nat...",
          "1_industrial strategy_strat..."
         ],
         "tickvals": [
          -5,
          -15,
          -25,
          -35,
          -45,
          -55,
          -65
         ],
         "type": "linear",
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Visualisation des hiérarchies entre les topics\n",
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "#D55E00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.001757682407110317,
          0.0018341203650804692,
          0.0018377858957563452,
          0.0018721593221593539,
          0.001883093476626757,
          0.0018934209574252632,
          0.002066318300891254,
          0.0021439536057334388,
          0.002446533567303499,
          0.003595666010497497
         ],
         "xaxis": "x",
         "y": [
          "member states  ",
          "infringement enforcement  ",
          "part part  ",
          "robotics related technologies  ",
          "council europe  ",
          "robotics related  ",
          "copyright design  ",
          "related technologies  ",
          "decision making  ",
          "ethics commission  "
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "#0072B2"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.0020232492339731173,
          0.002110054173249762,
          0.0021570801264733284,
          0.002228448987592664,
          0.002251426498946114,
          0.0023097910470484453,
          0.002675496500709401,
          0.0027361049813051973,
          0.0027907267572872606,
          0.005398066730178353
         ],
         "xaxis": "x2",
         "y": [
          "fourth industrial revolution  ",
          "per cent  ",
          "fourth industrial  ",
          "national strategy  ",
          "yes tbs  ",
          "intelligent society  ",
          "health care  ",
          "industrial strategy white  ",
          "strategy white  ",
          "industrial strategy  "
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "#CC79A7"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.0024922108185515047,
          0.0025558620495066036,
          0.002645695291364252,
          0.0026975452343961023,
          0.0027693629682747013,
          0.002781831529604552,
          0.002796937339214125,
          0.002805620609115905,
          0.002938665619249454,
          0.0049684907462685364
         ],
         "xaxis": "x3",
         "y": [
          "change recommendations  ",
          "discussion paper  ",
          "civil society  ",
          "national strategy  ",
          "paper national  ",
          "paper national strategy  ",
          "per cent  ",
          "discussion paper national  ",
          "united nations  ",
          "climate change  "
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "#E69F00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.0018786894665402283,
          0.0018786894665402283,
          0.0018786894665402283,
          0.0019589300177955786,
          0.002055514749773571,
          0.002225649471128212,
          0.0023133180929309667,
          0.002332168555855177,
          0.002600121878255902,
          0.0034822155561383453
         ],
         "xaxis": "x4",
         "y": [
          "revolution consulting  ",
          "industrial revolution consulting  ",
          "revolution consulting group  ",
          "impact assessment  ",
          "consulting group  ",
          "council europe  ",
          "third industrial revolution  ",
          "third industrial  ",
          "industrial revolution  ",
          "member states  "
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "#56B4E9"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.00244265453697718,
          0.002443514904007684,
          0.0026305538237960903,
          0.0028274015709117348,
          0.0034137770558074414,
          0.0034904077228271047,
          0.0046812952349100335,
          0.0047402186487708895,
          0.004746945466790189,
          0.008034238343596857
         ],
         "xaxis": "x5",
         "y": [
          "equality act  ",
          "algorithmic bias  ",
          "decision making  ",
          "algorithmic impact  ",
          "impact assessment  ",
          "impact assessments  ",
          "bias algorithmic decisionmaking  ",
          "bias algorithmic  ",
          "centre ethics  ",
          "algorithmic decisionmaking  "
         ],
         "yaxis": "y5"
        },
        {
         "marker": {
          "color": "#009E73"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.0022499574869956846,
          0.002264858786647264,
          0.0023434083466960906,
          0.0024602178384651916,
          0.0024851446672374904,
          0.0024877267955334442,
          0.0024907232732183163,
          0.0028105446776974935,
          0.0028170310792898245,
          0.003026388096975063
         ],
         "xaxis": "x6",
         "y": [
          "initiative ethics autonomous  ",
          "ethics autonomous intelligent  ",
          "ethics autonomous  ",
          "creative commons  ",
          "ieee global  ",
          "ieee global initiative  ",
          "global initiative  ",
          "autonomous intelligent  ",
          "index report  ",
          "united states  "
         ],
         "yaxis": "y6"
        },
        {
         "marker": {
          "color": "#F0E442"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.005213022829349123,
          0.005213022829349123,
          0.0055044626278763975,
          0.005523999959157618,
          0.0059031538790489295,
          0.007904950220109848,
          0.007904950220109848,
          0.007904950220109848,
          0.007904950220109848,
          0.007985450543501055
         ],
         "xaxis": "x7",
         "y": [
          "computers learn example  ",
          "learn example  ",
          "machine power  ",
          "machine power promise  ",
          "accessed 22  ",
          "power promise computers  ",
          "power promise  ",
          "promise computers  ",
          "promise computers learn  ",
          "computers learn  "
         ],
         "yaxis": "y7"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 0",
          "x": 0.0875,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 1",
          "x": 0.36250000000000004,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 2",
          "x": 0.6375000000000001,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 3",
          "x": 0.9125,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 4",
          "x": 0.0875,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 5",
          "x": 0.36250000000000004,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 6",
          "x": 0.6375000000000001,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 800,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "Topic Word Scores",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1600,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.175
         ],
         "showgrid": true
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.275,
          0.45
         ],
         "showgrid": true
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.55,
          0.7250000000000001
         ],
         "showgrid": true
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.825,
          1
         ],
         "showgrid": true
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0,
          0.175
         ],
         "showgrid": true
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.275,
          0.45
         ],
         "showgrid": true
        },
        "xaxis7": {
         "anchor": "y7",
         "domain": [
          0.55,
          0.7250000000000001
         ],
         "showgrid": true
        },
        "xaxis8": {
         "anchor": "y8",
         "domain": [
          0.825,
          1
         ],
         "showgrid": true
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis7": {
         "anchor": "x7",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis8": {
         "anchor": "x8",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Visualisation des relations entre les topics\n",
    "topic_model.visualize_barchart(n_words=10, height=400, width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Make sure to set `n_clusters` lower than the total number of unique topics.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[238], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualize_heatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Code_Telecom/projet_NLP/.env_projet_NLP/lib/python3.12/site-packages/bertopic/_bertopic.py:3173\u001b[0m, in \u001b[0;36mBERTopic.visualize_heatmap\u001b[0;34m(self, topics, top_n_topics, n_clusters, use_ctfidf, custom_labels, title, width, height)\u001b[0m\n\u001b[1;32m   3136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Visualize a heatmap of the topic's similarity matrix.\u001b[39;00m\n\u001b[1;32m   3137\u001b[0m \n\u001b[1;32m   3138\u001b[0m \u001b[38;5;124;03mBased on the cosine similarity matrix between c-TF-IDFs or semantic embeddings of the topics,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3170\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[1;32m   3171\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3172\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 3173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mplotting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualize_heatmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtopics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtopics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_n_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_n_topics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3178\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_ctfidf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_ctfidf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Code_Telecom/projet_NLP/.env_projet_NLP/lib/python3.12/site-packages/bertopic/plotting/_heatmap.py:80\u001b[0m, in \u001b[0;36mvisualize_heatmap\u001b[0;34m(topic_model, topics, top_n_topics, n_clusters, use_ctfidf, custom_labels, title, width, height)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_clusters:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_clusters \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(topics)):\n\u001b[0;32m---> 80\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure to set `n_clusters` lower than \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe total number of unique topics.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m     distance_matrix \u001b[38;5;241m=\u001b[39m cosine_similarity(embeddings[topics])\n\u001b[1;32m     83\u001b[0m     Z \u001b[38;5;241m=\u001b[39m linkage(distance_matrix, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mward\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Make sure to set `n_clusters` lower than the total number of unique topics."
     ]
    }
   ],
   "source": [
    "topic_model.visualize_heatmap(n_clusters=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env_projet_NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
